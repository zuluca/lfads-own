{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PYTHONPATH=$PYTHONPATH:/path/to/your/directory/lfads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data\n",
      "Generating chaotic rnn data with no input pulses (g=1.5) with spiking noise\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with no input pulses (g=1.5) with Gaussian noise\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with input pulses (g=1.5)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with input pulses (g=2.5)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generate the multi-session RNN data (no multi-session synth example in paper)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  5\n",
      "2  of  5\n",
      "3  of  5\n",
      "4  of  5\n",
      "5  of  5\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data/synthetic_data_utils.py:320: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  np.linalg.lstsq(all_data_zm_chxtc.T, all_data_pca_pxtc.T)\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating Integration-to-bound RNN data\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-04-18 11:24:53.243626: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Model restored from /Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data/trained_itb/model-65000\n",
      "Saving variable with name:  train_outputs_u\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_inputs_u\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  max_firing_rate\n",
      "Saving variable with name:  valid_outputs_u\n",
      "Saving variable with name:  u_std\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  train_inputs_u\n",
      "Saving variable with name:  train_data\n",
      "Saved to  /tmp/rnn_synth_data_v1.0/itb_rnn_dataset_N50\n",
      "Generating chaotic rnn data with external input labels (no external input labels example in paper)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  train_ext_input\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  valid_ext_input\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saved to  /tmp/rnn_synth_data_v1.0/chaotic_rnns_labeled_dataset_N50\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "% cd synth_data\n",
    "! ./run_generate_synth_data.sh\n",
    "% cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md        distributions.py \u001b[31mrun_lfads.py\u001b[m\u001b[m     utils.pyc\r\n",
      "Untitled.ipynb   lfads.py         \u001b[34msynth_data\u001b[m\u001b[m\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m      plot_lfads.py    utils.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading data from  /tmp/rnn_synth_data_v1.0/\n",
      "loading data from /tmp/rnn_synth_data_v1.0/ with stem chaotic_rnn_no_inputs\n",
      "1 datasets loaded\n",
      "Found training set with number examples:  3200\n",
      "Found validation set with number examples:  800\n",
      "2018-04-18 11:28:58.919253: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Building graph...\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/lfads.py:322: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  datasets[hps.dataset_names[0]]['train_data'].dtype, int), \\\n",
      "done.\n",
      "Model Variables (to be optimized): \n",
      "     0 LFADS/glm/fac_2_logrates_dataset_N50_S50/W:0 [20, 50]\n",
      "     1 LFADS/glm/fac_2_logrates_dataset_N50_S50/b:0 [1, 50]\n",
      "     2 LFADS/ic_enc_fwd/ic_enc_t0_fwd:0 [1, 128]\n",
      "     3 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     4 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     5 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     6 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     7 LFADS/ic_enc_rev/ic_enc_t0_rev:0 [1, 128]\n",
      "     8 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     9 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     10 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     11 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     12 LFADS/z/prior_g0/mean:0 [1, 64]\n",
      "     13 LFADS/z/ic_enc_2_post_g0/mean/W:0 [256, 64]\n",
      "     14 LFADS/z/ic_enc_2_post_g0/mean/b:0 [1, 64]\n",
      "     15 LFADS/z/ic_enc_2_post_g0/logvar/W:0 [256, 64]\n",
      "     16 LFADS/z/ic_enc_2_post_g0/logvar/b:0 [1, 64]\n",
      "     17 LFADS/gen/g0_2_gen_ic/W:0 [64, 200]\n",
      "     18 LFADS/gen/g0_2_gen_ic/b:0 [1, 200]\n",
      "     19 LFADS/gen/gen_2_fac/W:0 [200, 20]\n",
      "     20 LFADS/gen/GenGRU/Gates/h_2_ru/W:0 [200, 400]\n",
      "     21 LFADS/gen/GenGRU/Gates/h_2_ru/b:0 [1, 400]\n",
      "     22 LFADS/gen/GenGRU/Candidate/rh_2_c/W:0 [200, 200]\n",
      "     23 LFADS/gen/GenGRU/Candidate/rh_2_c/b:0 [1, 200]\n",
      "Total model parameters:  309338\n",
      "Loading latest training checkpoint in:  /tmp/lfads_chaotic_rnn_no_inputs\n",
      "ckpt:  None\n",
      "Created model with fresh parameters.\n",
      "Epoch:0, step:25 (TRAIN, VALID): total: 3095.96, 2249.63      recon: 3094.61, 2246.99,     kl: 217.76, 206.17,     l2: 5.07264,      kl weight: 0.01, l2 weight: 0.01\n",
      "Epoch:1, step:50 (TRAIN, VALID): total: 2238.07, 2233.54      recon: 2234.98, 2230.76,     kl: 167.89, 106.19,     l2: 5.09913,      kl weight: 0.02, l2 weight: 0.02\n",
      "Epoch:2, step:75 (TRAIN, VALID): total: 2231.44, 2229.74      recon: 2229.76, 2229.09,     kl: 52.53, 12.34,     l2: 5.10052,      kl weight: 0.04, l2 weight: 0.04\n",
      "Epoch:3, step:100 (TRAIN, VALID): total: 2229.44, 2229.85      recon: 2228.79, 2229.36,     kl: 10.00, 4.64,     l2: 5.09838,      kl weight: 0.05, l2 weight: 0.05\n",
      "Epoch:4, step:125 (TRAIN, VALID): total: 2229.12, 2228.42      recon: 2228.43, 2227.88,     kl: 7.15, 3.56,     l2: 5.09428,      kl weight: 0.06, l2 weight: 0.06\n",
      "Epoch:5, step:150 (TRAIN, VALID): total: 2228.75, 2228.49      recon: 2227.94, 2227.77,     kl: 6.66, 4.57,     l2: 5.08973,      kl weight: 0.07, l2 weight: 0.07\n",
      "Epoch:6, step:175 (TRAIN, VALID): total: 2227.34, 2229.03      recon: 2226.18, 2227.42,     kl: 9.11, 13.24,     l2: 5.09079,      kl weight: 0.09, l2 weight: 0.09\n",
      "Epoch:7, step:200 (TRAIN, VALID): total: 2209.90, 2190.88      recon: 2207.18, 2187.27,     kl: 23.71, 30.96,     l2: 5.16023,      kl weight: 0.10, l2 weight: 0.10\n",
      "Epoch:8, step:225 (TRAIN, VALID): total: 2148.43, 2113.94      recon: 2143.74, 2107.81,     kl: 38.95, 49.24,     l2: 5.29357,      kl weight: 0.11, l2 weight: 0.11\n",
      "Epoch:9, step:250 (TRAIN, VALID): total: 2138.82, 2120.30      recon: 2132.34, 2112.93,     kl: 49.27, 53.56,     l2: 5.39855,      kl weight: 0.12, l2 weight: 0.12\n",
      "Epoch:10, step:275 (TRAIN, VALID): total: 2114.79, 2111.89      recon: 2108.60, 2106.34,     kl: 41.95, 34.81,     l2: 5.49142,      kl weight: 0.14, l2 weight: 0.14\n",
      "Epoch:11, step:300 (TRAIN, VALID): total: 2103.53, 2107.91      recon: 2098.13, 2102.09,     kl: 32.14, 33.24,     l2: 5.56440,      kl weight: 0.15, l2 weight: 0.15\n",
      "Epoch:12, step:325 (TRAIN, VALID): total: 2091.43, 2079.81      recon: 2085.78, 2074.67,     kl: 30.67, 26.01,     l2: 5.62404,      kl weight: 0.16, l2 weight: 0.16\n",
      "Epoch:13, step:350 (TRAIN, VALID): total: 2091.12, 2095.20      recon: 2085.34, 2088.50,     kl: 28.67, 32.62,     l2: 5.65990,      kl weight: 0.17, l2 weight: 0.17\n",
      "Epoch:14, step:375 (TRAIN, VALID): total: 2086.75, 2084.03      recon: 2080.57, 2078.36,     kl: 28.48, 24.53,     l2: 5.70120,      kl weight: 0.19, l2 weight: 0.19\n",
      "Epoch:15, step:400 (TRAIN, VALID): total: 2081.13, 2075.45      recon: 2075.10, 2069.49,     kl: 25.43, 24.04,     l2: 5.73352,      kl weight: 0.20, l2 weight: 0.20\n",
      "Epoch:16, step:425 (TRAIN, VALID): total: 2077.59, 2073.01      recon: 2071.39, 2066.91,     kl: 24.35, 22.93,     l2: 5.75308,      kl weight: 0.21, l2 weight: 0.21\n",
      "Epoch:17, step:450 (TRAIN, VALID): total: 2075.75, 2070.16      recon: 2069.26, 2063.68,     kl: 23.98, 23.03,     l2: 5.76931,      kl weight: 0.22, l2 weight: 0.22\n",
      "Epoch:18, step:475 (TRAIN, VALID): total: 2073.73, 2068.37      recon: 2067.09, 2061.82,     kl: 22.97, 21.78,     l2: 5.78526,      kl weight: 0.24, l2 weight: 0.24\n",
      "Epoch:19, step:500 (TRAIN, VALID): total: 2081.51, 2084.96      recon: 2074.28, 2077.75,     kl: 23.90, 23.04,     l2: 5.78542,      kl weight: 0.25, l2 weight: 0.25\n",
      "Epoch:20, step:525 (TRAIN, VALID): total: 2078.62, 2071.33      recon: 2070.93, 2064.27,     kl: 24.26, 21.10,     l2: 5.81213,      kl weight: 0.26, l2 weight: 0.26\n",
      "Epoch:21, step:550 (TRAIN, VALID): total: 2072.90, 2073.95      recon: 2065.28, 2066.31,     kl: 22.55, 21.95,     l2: 5.82941,      kl weight: 0.27, l2 weight: 0.27\n",
      "Epoch:22, step:575 (TRAIN, VALID): total: 2077.06, 2082.11      recon: 2069.08, 2073.83,     kl: 22.56, 22.97,     l2: 5.84416,      kl weight: 0.29, l2 weight: 0.29\n",
      "Epoch:23, step:600 (TRAIN, VALID): total: 2072.84, 2066.35      recon: 2064.35, 2058.24,     kl: 23.07, 21.20,     l2: 5.86310,      kl weight: 0.30, l2 weight: 0.30\n",
      "Epoch:24, step:625 (TRAIN, VALID): total: 2074.02, 2069.23      recon: 2065.37, 2060.66,     kl: 22.40, 21.56,     l2: 5.86637,      kl weight: 0.31, l2 weight: 0.31\n",
      "Epoch:25, step:650 (TRAIN, VALID): total: 2069.48, 2067.61      recon: 2060.53, 2058.86,     kl: 22.24, 21.05,     l2: 5.86558,      kl weight: 0.32, l2 weight: 0.32\n",
      "Epoch:26, step:675 (TRAIN, VALID): total: 2066.69, 2068.88      recon: 2057.64, 2059.87,     kl: 21.47, 20.85,     l2: 5.85530,      kl weight: 0.34, l2 weight: 0.34\n",
      "Epoch:27, step:700 (TRAIN, VALID): total: 2068.00, 2067.47      recon: 2058.48, 2058.37,     kl: 21.88, 20.16,     l2: 5.84209,      kl weight: 0.35, l2 weight: 0.35\n",
      "Epoch:28, step:725 (TRAIN, VALID): total: 2067.28, 2072.19      recon: 2057.70, 2062.99,     kl: 21.07, 19.56,     l2: 5.81976,      kl weight: 0.36, l2 weight: 0.36\n",
      "Epoch:29, step:750 (TRAIN, VALID): total: 2074.96, 2072.46      recon: 2064.99, 2062.43,     kl: 21.23, 20.93,     l2: 5.81489,      kl weight: 0.37, l2 weight: 0.37\n",
      "     Decreasing learning rate to 0.009500.\n",
      "Epoch:30, step:775 (TRAIN, VALID): total: 2069.49, 2062.38      recon: 2059.46, 2052.26,     kl: 20.52, 20.32,     l2: 5.81330,      kl weight: 0.39, l2 weight: 0.39\n",
      "Epoch:31, step:800 (TRAIN, VALID): total: 2068.36, 2062.49      recon: 2058.08, 2052.29,     kl: 20.31, 19.72,     l2: 5.80162,      kl weight: 0.40, l2 weight: 0.40\n",
      "Epoch:32, step:825 (TRAIN, VALID): total: 2067.32, 2066.64      recon: 2056.85, 2056.22,     kl: 19.99, 19.46,     l2: 5.78689,      kl weight: 0.41, l2 weight: 0.41\n",
      "Epoch:33, step:850 (TRAIN, VALID): total: 2068.66, 2072.85      recon: 2057.86, 2062.12,     kl: 20.04, 19.51,     l2: 5.75317,      kl weight: 0.42, l2 weight: 0.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34, step:875 (TRAIN, VALID): total: 2077.38, 2072.91      recon: 2066.44, 2062.14,     kl: 19.64, 18.88,     l2: 5.75241,      kl weight: 0.44, l2 weight: 0.44\n",
      "Epoch:35, step:900 (TRAIN, VALID): total: 2067.09, 2061.96      recon: 2056.11, 2051.12,     kl: 19.01, 18.34,     l2: 5.75435,      kl weight: 0.45, l2 weight: 0.45\n",
      "Epoch:36, step:925 (TRAIN, VALID): total: 2063.47, 2059.20      recon: 2052.41, 2048.32,     kl: 18.51, 17.78,     l2: 5.72781,      kl weight: 0.46, l2 weight: 0.46\n",
      "Epoch:37, step:950 (TRAIN, VALID): total: 2062.77, 2071.00      recon: 2051.71, 2060.26,     kl: 17.91, 16.92,     l2: 5.68824,      kl weight: 0.47, l2 weight: 0.47\n",
      "Epoch:38, step:975 (TRAIN, VALID): total: 2067.48, 2063.98      recon: 2056.11, 2052.71,     kl: 17.97, 17.45,     l2: 5.65768,      kl weight: 0.49, l2 weight: 0.49\n",
      "Epoch:39, step:1000 (TRAIN, VALID): total: 2064.62, 2060.91      recon: 2053.01, 2049.60,     kl: 17.90, 17.01,     l2: 5.62637,      kl weight: 0.50, l2 weight: 0.50\n",
      "Epoch:40, step:1025 (TRAIN, VALID): total: 2061.60, 2060.96      recon: 2050.06, 2049.57,     kl: 17.21, 16.64,     l2: 5.59589,      kl weight: 0.51, l2 weight: 0.51\n",
      "Epoch:41, step:1050 (TRAIN, VALID): total: 2065.78, 2063.03      recon: 2053.93, 2051.23,     kl: 17.29, 16.92,     l2: 5.55344,      kl weight: 0.52, l2 weight: 0.52\n",
      "Epoch:42, step:1075 (TRAIN, VALID): total: 2064.12, 2059.61      recon: 2051.93, 2047.71,     kl: 17.42, 16.61,     l2: 5.52678,      kl weight: 0.54, l2 weight: 0.54\n",
      "Epoch:43, step:1100 (TRAIN, VALID): total: 2062.65, 2068.17      recon: 2050.39, 2056.26,     kl: 17.04, 16.16,     l2: 5.49397,      kl weight: 0.55, l2 weight: 0.55\n",
      "Epoch:44, step:1125 (TRAIN, VALID): total: 2066.16, 2066.32      recon: 2053.56, 2053.66,     kl: 17.18, 17.04,     l2: 5.46573,      kl weight: 0.56, l2 weight: 0.56\n",
      "Epoch:45, step:1150 (TRAIN, VALID): total: 2063.29, 2059.72      recon: 2050.48, 2047.23,     kl: 17.09, 16.28,     l2: 5.43976,      kl weight: 0.57, l2 weight: 0.57\n",
      "Epoch:46, step:1175 (TRAIN, VALID): total: 2060.36, 2059.03      recon: 2047.49, 2046.51,     kl: 16.73, 15.91,     l2: 5.39751,      kl weight: 0.59, l2 weight: 0.59\n",
      "Epoch:47, step:1200 (TRAIN, VALID): total: 2058.77, 2058.36      recon: 2045.90, 2046.03,     kl: 16.31, 15.21,     l2: 5.34456,      kl weight: 0.60, l2 weight: 0.60\n",
      "Epoch:48, step:1225 (TRAIN, VALID): total: 2059.65, 2055.47      recon: 2046.65, 2042.78,     kl: 16.13, 15.42,     l2: 5.29663,      kl weight: 0.61, l2 weight: 0.61\n",
      "Epoch:49, step:1250 (TRAIN, VALID): total: 2064.48, 2066.10      recon: 2051.34, 2053.22,     kl: 15.97, 15.35,     l2: 5.25171,      kl weight: 0.62, l2 weight: 0.62\n",
      "Epoch:50, step:1275 (TRAIN, VALID): total: 2061.24, 2057.32      recon: 2047.94, 2044.11,     kl: 15.86, 15.52,     l2: 5.20359,      kl weight: 0.64, l2 weight: 0.64\n",
      "Epoch:51, step:1300 (TRAIN, VALID): total: 2062.16, 2058.18      recon: 2048.65, 2044.96,     kl: 15.82, 15.19,     l2: 5.15673,      kl weight: 0.65, l2 weight: 0.65\n",
      "Epoch:52, step:1325 (TRAIN, VALID): total: 2063.52, 2064.78      recon: 2049.85, 2051.36,     kl: 15.70, 15.14,     l2: 5.12194,      kl weight: 0.66, l2 weight: 0.66\n",
      "Epoch:53, step:1350 (TRAIN, VALID): total: 2062.86, 2059.46      recon: 2049.00, 2045.92,     kl: 15.63, 14.98,     l2: 5.08773,      kl weight: 0.67, l2 weight: 0.67\n",
      "Epoch:54, step:1375 (TRAIN, VALID): total: 2063.98, 2068.28      recon: 2049.96, 2054.62,     kl: 15.51, 14.81,     l2: 5.05976,      kl weight: 0.69, l2 weight: 0.69\n",
      "Epoch:55, step:1400 (TRAIN, VALID): total: 2060.58, 2057.55      recon: 2046.62, 2043.82,     kl: 15.09, 14.60,     l2: 5.02010,      kl weight: 0.70, l2 weight: 0.70\n",
      "Epoch:56, step:1425 (TRAIN, VALID): total: 2061.93, 2064.85      recon: 2047.88, 2051.07,     kl: 14.92, 14.37,     l2: 4.96274,      kl weight: 0.71, l2 weight: 0.71\n",
      "Epoch:57, step:1450 (TRAIN, VALID): total: 2063.67, 2057.04      recon: 2049.39, 2043.18,     kl: 14.92, 14.18,     l2: 4.92979,      kl weight: 0.72, l2 weight: 0.72\n",
      "Epoch:58, step:1475 (TRAIN, VALID): total: 2060.21, 2062.41      recon: 2046.03, 2048.47,     kl: 14.49, 14.03,     l2: 4.88291,      kl weight: 0.74, l2 weight: 0.74\n",
      "Epoch:59, step:1500 (TRAIN, VALID): total: 2064.39, 2071.53      recon: 2049.97, 2057.57,     kl: 14.53, 13.77,     l2: 4.84437,      kl weight: 0.75, l2 weight: 0.75\n",
      "     Decreasing learning rate to 0.009025.\n",
      "Epoch:60, step:1525 (TRAIN, VALID): total: 2060.18, 2057.40      recon: 2045.79, 2043.43,     kl: 14.20, 13.51,     l2: 4.81312,      kl weight: 0.76, l2 weight: 0.76\n",
      "Epoch:61, step:1550 (TRAIN, VALID): total: 2057.16, 2058.65      recon: 2042.70, 2044.55,     kl: 14.04, 13.44,     l2: 4.74859,      kl weight: 0.77, l2 weight: 0.77\n",
      "Epoch:62, step:1575 (TRAIN, VALID): total: 2058.11, 2058.97      recon: 2043.52, 2044.55,     kl: 13.97, 13.64,     l2: 4.67810,      kl weight: 0.79, l2 weight: 0.79\n",
      "Epoch:63, step:1600 (TRAIN, VALID): total: 2057.30, 2055.72      recon: 2042.71, 2041.07,     kl: 13.74, 13.71,     l2: 4.61305,      kl weight: 0.80, l2 weight: 0.80\n",
      "Epoch:64, step:1625 (TRAIN, VALID): total: 2059.21, 2060.10      recon: 2044.49, 2046.03,     kl: 13.67, 12.77,     l2: 4.54900,      kl weight: 0.81, l2 weight: 0.81\n",
      "Epoch:65, step:1650 (TRAIN, VALID): total: 2059.04, 2068.27      recon: 2044.36, 2053.85,     kl: 13.41, 12.98,     l2: 4.50111,      kl weight: 0.82, l2 weight: 0.82\n",
      "Epoch:66, step:1675 (TRAIN, VALID): total: 2060.05, 2057.72      recon: 2045.12, 2043.50,     kl: 13.50, 12.53,     l2: 4.45217,      kl weight: 0.84, l2 weight: 0.84\n",
      "Epoch:67, step:1700 (TRAIN, VALID): total: 2059.84, 2060.64      recon: 2044.89, 2045.83,     kl: 13.30, 13.04,     l2: 4.39620,      kl weight: 0.85, l2 weight: 0.85\n",
      "Epoch:68, step:1725 (TRAIN, VALID): total: 2061.57, 2060.95      recon: 2046.33, 2046.26,     kl: 13.43, 12.68,     l2: 4.35239,      kl weight: 0.86, l2 weight: 0.86\n",
      "     Decreasing learning rate to 0.008574.\n",
      "Epoch:69, step:1750 (TRAIN, VALID): total: 2058.66, 2058.38      recon: 2043.50, 2043.49,     kl: 13.12, 12.71,     l2: 4.30953,      kl weight: 0.87, l2 weight: 0.87\n",
      "Epoch:70, step:1775 (TRAIN, VALID): total: 2060.80, 2057.98      recon: 2045.48, 2042.75,     kl: 13.11, 12.92,     l2: 4.24990,      kl weight: 0.89, l2 weight: 0.89\n",
      "Epoch:71, step:1800 (TRAIN, VALID): total: 2059.91, 2057.64      recon: 2044.60, 2042.65,     kl: 12.90, 12.45,     l2: 4.21127,      kl weight: 0.90, l2 weight: 0.90\n",
      "Epoch:72, step:1825 (TRAIN, VALID): total: 2058.68, 2058.32      recon: 2043.23, 2043.30,     kl: 12.86, 12.29,     l2: 4.16684,      kl weight: 0.91, l2 weight: 0.91\n",
      "Epoch:73, step:1850 (TRAIN, VALID): total: 2059.11, 2057.66      recon: 2043.68, 2042.62,     kl: 12.66, 12.14,     l2: 4.11554,      kl weight: 0.92, l2 weight: 0.92\n",
      "Epoch:74, step:1875 (TRAIN, VALID): total: 2059.73, 2063.34      recon: 2044.16, 2048.13,     kl: 12.64, 12.15,     l2: 4.06953,      kl weight: 0.94, l2 weight: 0.94\n",
      "Epoch:75, step:1900 (TRAIN, VALID): total: 2062.26, 2059.07      recon: 2046.62, 2043.63,     kl: 12.52, 12.21,     l2: 4.03312,      kl weight: 0.95, l2 weight: 0.95\n",
      "     Decreasing learning rate to 0.008145.\n",
      "Epoch:76, step:1925 (TRAIN, VALID): total: 2059.97, 2057.96      recon: 2044.34, 2042.60,     kl: 12.34, 11.97,     l2: 3.99563,      kl weight: 0.96, l2 weight: 0.96\n",
      "Epoch:77, step:1950 (TRAIN, VALID): total: 2058.20, 2056.88      recon: 2042.43, 2041.41,     kl: 12.32, 11.92,     l2: 3.94954,      kl weight: 0.97, l2 weight: 0.97\n",
      "Epoch:78, step:1975 (TRAIN, VALID): total: 2057.59, 2058.07      recon: 2041.69, 2042.63,     kl: 12.29, 11.74,     l2: 3.89665,      kl weight: 0.99, l2 weight: 0.99\n",
      "Epoch:79, step:2000 (TRAIN, VALID): total: 2059.52, 2063.14      recon: 2043.54, 2047.55,     kl: 12.22, 11.74,     l2: 3.83992,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:80, step:2025 (TRAIN, VALID): total: 2059.31, 2062.51      recon: 2043.45, 2047.10,     kl: 12.04, 11.61,     l2: 3.80007,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:81, step:2050 (TRAIN, VALID): total: 2060.48, 2059.68      recon: 2044.68, 2044.28,     kl: 12.02, 11.65,     l2: 3.75176,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:82, step:2075 (TRAIN, VALID): total: 2060.42, 2055.23      recon: 2044.71, 2039.92,     kl: 11.97, 11.59,     l2: 3.72675,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:83, step:2100 (TRAIN, VALID): total: 2058.89, 2057.69      recon: 2043.17, 2042.31,     kl: 12.01, 11.69,     l2: 3.68817,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:84, step:2125 (TRAIN, VALID): total: 2058.16, 2055.83      recon: 2042.48, 2040.44,     kl: 12.02, 11.75,     l2: 3.64491,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:85, step:2150 (TRAIN, VALID): total: 2060.17, 2058.63      recon: 2044.57, 2043.56,     kl: 11.97, 11.46,     l2: 3.60792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:86, step:2175 (TRAIN, VALID): total: 2058.83, 2060.48      recon: 2043.33, 2045.26,     kl: 11.91, 11.64,     l2: 3.57758,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:87, step:2200 (TRAIN, VALID): total: 2059.81, 2058.00      recon: 2044.31, 2043.08,     kl: 11.94, 11.37,     l2: 3.54835,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:88, step:2225 (TRAIN, VALID): total: 2058.21, 2055.98      recon: 2042.76, 2041.15,     kl: 11.92, 11.32,     l2: 3.52072,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:89, step:2250 (TRAIN, VALID): total: 2056.12, 2055.74      recon: 2040.78, 2040.72,     kl: 11.83, 11.53,     l2: 3.48342,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:90, step:2275 (TRAIN, VALID): total: 2060.74, 2066.04      recon: 2045.43, 2050.78,     kl: 11.85, 11.82,     l2: 3.44509,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007738.\n",
      "Epoch:91, step:2300 (TRAIN, VALID): total: 2061.01, 2058.76      recon: 2045.59, 2043.59,     kl: 11.99, 11.74,     l2: 3.43025,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:92, step:2325 (TRAIN, VALID): total: 2056.95, 2055.24      recon: 2041.50, 2040.17,     kl: 12.04, 11.67,     l2: 3.40550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:93, step:2350 (TRAIN, VALID): total: 2056.26, 2055.82      recon: 2040.97, 2040.80,     kl: 11.90, 11.64,     l2: 3.37651,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:94, step:2375 (TRAIN, VALID): total: 2056.87, 2056.25      recon: 2041.73, 2041.42,     kl: 11.78, 11.48,     l2: 3.34612,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:95, step:2400 (TRAIN, VALID): total: 2056.36, 2056.27      recon: 2041.24, 2041.34,     kl: 11.79, 11.61,     l2: 3.32086,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:96, step:2425 (TRAIN, VALID): total: 2057.04, 2055.55      recon: 2041.89, 2040.79,     kl: 11.85, 11.47,     l2: 3.29316,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:97, step:2450 (TRAIN, VALID): total: 2057.31, 2056.90      recon: 2042.29, 2042.07,     kl: 11.75, 11.56,     l2: 3.26688,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:98, step:2475 (TRAIN, VALID): total: 2059.43, 2059.55      recon: 2044.22, 2044.40,     kl: 11.95, 11.90,     l2: 3.25370,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007351.\n",
      "Epoch:99, step:2500 (TRAIN, VALID): total: 2056.09, 2055.91      recon: 2041.00, 2041.30,     kl: 11.83, 11.36,     l2: 3.24569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:100, step:2525 (TRAIN, VALID): total: 2055.89, 2056.98      recon: 2040.80, 2042.25,     kl: 11.86, 11.51,     l2: 3.22089,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:101, step:2550 (TRAIN, VALID): total: 2056.45, 2058.00      recon: 2041.49, 2043.38,     kl: 11.75, 11.42,     l2: 3.19695,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:102, step:2575 (TRAIN, VALID): total: 2054.78, 2056.50      recon: 2039.76, 2041.68,     kl: 11.83, 11.65,     l2: 3.17729,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:103, step:2600 (TRAIN, VALID): total: 2054.49, 2054.20      recon: 2039.49, 2039.60,     kl: 11.84, 11.45,     l2: 3.14582,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:104, step:2625 (TRAIN, VALID): total: 2058.95, 2062.86      recon: 2043.82, 2048.13,     kl: 12.00, 11.61,     l2: 3.12341,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:105, step:2650 (TRAIN, VALID): total: 2060.02, 2060.72      recon: 2045.05, 2046.11,     kl: 11.85, 11.49,     l2: 3.11748,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006983.\n",
      "Epoch:106, step:2675 (TRAIN, VALID): total: 2057.60, 2057.78      recon: 2042.79, 2043.45,     kl: 11.69, 11.21,     l2: 3.11778,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:107, step:2700 (TRAIN, VALID): total: 2056.80, 2059.53      recon: 2041.91, 2044.84,     kl: 11.77, 11.58,     l2: 3.10667,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:108, step:2725 (TRAIN, VALID): total: 2056.21, 2054.12      recon: 2041.23, 2039.50,     kl: 11.88, 11.52,     l2: 3.09383,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:109, step:2750 (TRAIN, VALID): total: 2054.33, 2055.83      recon: 2039.39, 2041.37,     kl: 11.86, 11.39,     l2: 3.07543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:110, step:2775 (TRAIN, VALID): total: 2055.43, 2055.58      recon: 2040.55, 2041.30,     kl: 11.82, 11.23,     l2: 3.05564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:111, step:2800 (TRAIN, VALID): total: 2055.01, 2056.47      recon: 2040.14, 2041.86,     kl: 11.82, 11.57,     l2: 3.03769,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:112, step:2825 (TRAIN, VALID): total: 2055.20, 2054.57      recon: 2040.40, 2040.13,     kl: 11.77, 11.42,     l2: 3.02538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:113, step:2850 (TRAIN, VALID): total: 2053.67, 2058.88      recon: 2038.91, 2044.21,     kl: 11.74, 11.66,     l2: 3.01265,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:114, step:2875 (TRAIN, VALID): total: 2055.86, 2054.55      recon: 2041.04, 2040.06,     kl: 11.82, 11.50,     l2: 2.99204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:115, step:2900 (TRAIN, VALID): total: 2054.67, 2054.00      recon: 2039.74, 2039.54,     kl: 11.94, 11.48,     l2: 2.97770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:116, step:2925 (TRAIN, VALID): total: 2053.83, 2058.09      recon: 2039.07, 2043.52,     kl: 11.79, 11.60,     l2: 2.96507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:117, step:2950 (TRAIN, VALID): total: 2058.94, 2056.14      recon: 2044.23, 2041.59,     kl: 11.76, 11.60,     l2: 2.95057,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006634.\n",
      "Epoch:118, step:2975 (TRAIN, VALID): total: 2054.01, 2055.44      recon: 2039.26, 2041.19,     kl: 11.80, 11.30,     l2: 2.95095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:119, step:3000 (TRAIN, VALID): total: 2054.66, 2054.35      recon: 2040.01, 2039.82,     kl: 11.71, 11.60,     l2: 2.94072,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:120, step:3025 (TRAIN, VALID): total: 2056.70, 2057.13      recon: 2041.92, 2041.99,     kl: 11.85, 12.21,     l2: 2.92625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:121, step:3050 (TRAIN, VALID): total: 2055.48, 2053.70      recon: 2040.59, 2039.47,     kl: 11.96, 11.30,     l2: 2.92115,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:122, step:3075 (TRAIN, VALID): total: 2053.69, 2054.55      recon: 2039.07, 2040.07,     kl: 11.71, 11.57,     l2: 2.91500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:123, step:3100 (TRAIN, VALID): total: 2053.55, 2054.72      recon: 2038.80, 2040.33,     kl: 11.84, 11.49,     l2: 2.90037,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:124, step:3125 (TRAIN, VALID): total: 2054.09, 2054.38      recon: 2039.43, 2039.90,     kl: 11.78, 11.60,     l2: 2.88348,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:125, step:3150 (TRAIN, VALID): total: 2054.72, 2056.30      recon: 2039.75, 2041.68,     kl: 12.09, 11.75,     l2: 2.87293,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:126, step:3175 (TRAIN, VALID): total: 2055.52, 2055.53      recon: 2040.50, 2041.07,     kl: 12.15, 11.59,     l2: 2.86021,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:127, step:3200 (TRAIN, VALID): total: 2053.38, 2054.10      recon: 2038.73, 2039.63,     kl: 11.80, 11.62,     l2: 2.85462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:128, step:3225 (TRAIN, VALID): total: 2054.05, 2053.54      recon: 2039.33, 2038.96,     kl: 11.87, 11.74,     l2: 2.83984,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:129, step:3250 (TRAIN, VALID): total: 2053.36, 2054.77      recon: 2038.72, 2040.58,     kl: 11.80, 11.36,     l2: 2.83730,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:130, step:3275 (TRAIN, VALID): total: 2053.93, 2056.03      recon: 2039.44, 2041.37,     kl: 11.67, 11.83,     l2: 2.82472,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:131, step:3300 (TRAIN, VALID): total: 2054.16, 2056.97      recon: 2039.51, 2042.54,     kl: 11.83, 11.61,     l2: 2.81782,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:132, step:3325 (TRAIN, VALID): total: 2054.51, 2054.25      recon: 2039.72, 2039.79,     kl: 11.97, 11.65,     l2: 2.81227,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:133, step:3350 (TRAIN, VALID): total: 2052.74, 2052.40      recon: 2037.96, 2037.60,     kl: 11.98, 11.99,     l2: 2.80640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:134, step:3375 (TRAIN, VALID): total: 2054.59, 2054.34      recon: 2039.94, 2039.81,     kl: 11.85, 11.74,     l2: 2.79479,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006302.\n",
      "Epoch:135, step:3400 (TRAIN, VALID): total: 2052.21, 2052.13      recon: 2037.65, 2037.79,     kl: 11.76, 11.56,     l2: 2.78861,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:136, step:3425 (TRAIN, VALID): total: 2051.63, 2051.34      recon: 2037.07, 2036.81,     kl: 11.77, 11.75,     l2: 2.77933,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:137, step:3450 (TRAIN, VALID): total: 2053.57, 2052.39      recon: 2038.86, 2037.91,     kl: 11.93, 11.71,     l2: 2.76560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:138, step:3475 (TRAIN, VALID): total: 2054.74, 2052.43      recon: 2040.23, 2038.17,     kl: 11.74, 11.50,     l2: 2.76191,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:139, step:3500 (TRAIN, VALID): total: 2052.52, 2055.04      recon: 2037.92, 2040.89,     kl: 11.84, 11.38,     l2: 2.76285,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:140, step:3525 (TRAIN, VALID): total: 2054.92, 2054.65      recon: 2040.31, 2040.18,     kl: 11.84, 11.70,     l2: 2.75827,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:141, step:3550 (TRAIN, VALID): total: 2054.91, 2052.28      recon: 2040.15, 2037.70,     kl: 12.00, 11.83,     l2: 2.75164,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:142, step:3575 (TRAIN, VALID): total: 2052.35, 2053.45      recon: 2037.67, 2038.99,     kl: 11.93, 11.72,     l2: 2.74462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:143, step:3600 (TRAIN, VALID): total: 2052.08, 2052.21      recon: 2037.66, 2038.02,     kl: 11.67, 11.46,     l2: 2.73819,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:144, step:3625 (TRAIN, VALID): total: 2053.37, 2056.20      recon: 2038.85, 2042.19,     kl: 11.78, 11.27,     l2: 2.73196,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:145, step:3650 (TRAIN, VALID): total: 2054.25, 2063.03      recon: 2039.61, 2048.35,     kl: 11.91, 11.95,     l2: 2.72935,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:146, step:3675 (TRAIN, VALID): total: 2058.09, 2057.67      recon: 2043.27, 2043.63,     kl: 12.09, 11.32,     l2: 2.72442,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005987.\n",
      "Epoch:147, step:3700 (TRAIN, VALID): total: 2053.68, 2054.08      recon: 2039.29, 2039.86,     kl: 11.66, 11.48,     l2: 2.73763,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:148, step:3725 (TRAIN, VALID): total: 2052.00, 2052.51      recon: 2037.54, 2038.21,     kl: 11.72, 11.56,     l2: 2.73960,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:149, step:3750 (TRAIN, VALID): total: 2051.04, 2051.04      recon: 2036.44, 2036.53,     kl: 11.87, 11.77,     l2: 2.73348,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:150, step:3775 (TRAIN, VALID): total: 2051.62, 2051.15      recon: 2037.09, 2036.99,     kl: 11.81, 11.43,     l2: 2.72511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:151, step:3800 (TRAIN, VALID): total: 2054.35, 2054.20      recon: 2039.87, 2040.19,     kl: 11.76, 11.29,     l2: 2.71477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:152, step:3825 (TRAIN, VALID): total: 2052.33, 2051.71      recon: 2037.89, 2037.24,     kl: 11.73, 11.75,     l2: 2.72109,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:153, step:3850 (TRAIN, VALID): total: 2051.33, 2052.45      recon: 2036.78, 2038.18,     kl: 11.83, 11.55,     l2: 2.71156,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:154, step:3875 (TRAIN, VALID): total: 2051.95, 2054.16      recon: 2037.53, 2039.81,     kl: 11.71, 11.65,     l2: 2.70672,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:155, step:3900 (TRAIN, VALID): total: 2052.76, 2054.26      recon: 2038.23, 2040.05,     kl: 11.82, 11.51,     l2: 2.69504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:156, step:3925 (TRAIN, VALID): total: 2052.62, 2051.78      recon: 2038.01, 2037.75,     kl: 11.91, 11.34,     l2: 2.69677,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:157, step:3950 (TRAIN, VALID): total: 2051.32, 2053.77      recon: 2036.70, 2039.38,     kl: 11.92, 11.69,     l2: 2.69690,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:158, step:3975 (TRAIN, VALID): total: 2054.03, 2053.30      recon: 2039.58, 2039.13,     kl: 11.76, 11.48,     l2: 2.69002,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005688.\n",
      "Epoch:159, step:4000 (TRAIN, VALID): total: 2052.07, 2051.60      recon: 2037.62, 2037.34,     kl: 11.75, 11.56,     l2: 2.69514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:160, step:4025 (TRAIN, VALID): total: 2052.46, 2051.77      recon: 2037.82, 2037.53,     kl: 11.95, 11.55,     l2: 2.69183,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:161, step:4050 (TRAIN, VALID): total: 2052.49, 2053.59      recon: 2037.95, 2039.18,     kl: 11.85, 11.72,     l2: 2.68795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:162, step:4075 (TRAIN, VALID): total: 2051.76, 2051.80      recon: 2037.31, 2037.64,     kl: 11.76, 11.47,     l2: 2.68910,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:163, step:4100 (TRAIN, VALID): total: 2051.83, 2053.87      recon: 2037.20, 2039.21,     kl: 11.94, 11.97,     l2: 2.68632,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:164, step:4125 (TRAIN, VALID): total: 2052.76, 2052.23      recon: 2037.98, 2037.87,     kl: 12.10, 11.68,     l2: 2.67591,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:165, step:4150 (TRAIN, VALID): total: 2051.15, 2052.67      recon: 2036.63, 2038.45,     kl: 11.84, 11.55,     l2: 2.67402,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:166, step:4175 (TRAIN, VALID): total: 2051.22, 2051.29      recon: 2036.62, 2036.91,     kl: 11.93, 11.71,     l2: 2.66948,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:167, step:4200 (TRAIN, VALID): total: 2050.36, 2050.52      recon: 2035.78, 2036.03,     kl: 11.91, 11.82,     l2: 2.66500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:168, step:4225 (TRAIN, VALID): total: 2050.39, 2052.23      recon: 2035.95, 2037.90,     kl: 11.78, 11.67,     l2: 2.65828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:169, step:4250 (TRAIN, VALID): total: 2050.61, 2052.40      recon: 2036.10, 2038.21,     kl: 11.86, 11.54,     l2: 2.64770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:170, step:4275 (TRAIN, VALID): total: 2050.67, 2050.85      recon: 2036.22, 2036.69,     kl: 11.80, 11.52,     l2: 2.64208,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:171, step:4300 (TRAIN, VALID): total: 2050.60, 2051.53      recon: 2036.14, 2037.38,     kl: 11.82, 11.52,     l2: 2.63238,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:172, step:4325 (TRAIN, VALID): total: 2050.46, 2050.79      recon: 2036.18, 2036.50,     kl: 11.65, 11.66,     l2: 2.63272,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:173, step:4350 (TRAIN, VALID): total: 2050.00, 2050.42      recon: 2035.51, 2036.23,     kl: 11.86, 11.56,     l2: 2.62988,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:174, step:4375 (TRAIN, VALID): total: 2050.39, 2051.29      recon: 2036.01, 2037.18,     kl: 11.75, 11.49,     l2: 2.61635,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:175, step:4400 (TRAIN, VALID): total: 2050.28, 2052.65      recon: 2035.90, 2038.57,     kl: 11.77, 11.46,     l2: 2.61693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:176, step:4425 (TRAIN, VALID): total: 2050.60, 2050.91      recon: 2036.23, 2036.85,     kl: 11.75, 11.45,     l2: 2.61273,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:177, step:4450 (TRAIN, VALID): total: 2050.12, 2050.79      recon: 2035.75, 2036.69,     kl: 11.77, 11.49,     l2: 2.60852,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:178, step:4475 (TRAIN, VALID): total: 2050.15, 2050.31      recon: 2035.61, 2036.20,     kl: 11.94, 11.51,     l2: 2.60152,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:179, step:4500 (TRAIN, VALID): total: 2052.16, 2054.23      recon: 2037.73, 2040.37,     kl: 11.83, 11.27,     l2: 2.59194,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005404.\n",
      "Epoch:180, step:4525 (TRAIN, VALID): total: 2050.49, 2052.55      recon: 2036.13, 2038.10,     kl: 11.77, 11.86,     l2: 2.59580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:181, step:4550 (TRAIN, VALID): total: 2051.20, 2051.27      recon: 2036.71, 2037.12,     kl: 11.89, 11.56,     l2: 2.59095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:182, step:4575 (TRAIN, VALID): total: 2049.24, 2050.58      recon: 2034.82, 2036.49,     kl: 11.84, 11.50,     l2: 2.59037,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:183, step:4600 (TRAIN, VALID): total: 2050.31, 2054.97      recon: 2035.91, 2040.76,     kl: 11.82, 11.63,     l2: 2.58286,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:184, step:4625 (TRAIN, VALID): total: 2051.23, 2053.01      recon: 2036.85, 2038.75,     kl: 11.80, 11.68,     l2: 2.57927,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:185, step:4650 (TRAIN, VALID): total: 2050.41, 2050.91      recon: 2035.98, 2036.63,     kl: 11.85, 11.70,     l2: 2.58204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:186, step:4675 (TRAIN, VALID): total: 2049.84, 2050.02      recon: 2035.38, 2035.80,     kl: 11.88, 11.65,     l2: 2.57878,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:187, step:4700 (TRAIN, VALID): total: 2050.45, 2051.74      recon: 2035.95, 2037.45,     kl: 11.92, 11.71,     l2: 2.57658,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:188, step:4725 (TRAIN, VALID): total: 2050.73, 2052.26      recon: 2036.07, 2037.99,     kl: 12.08, 11.70,     l2: 2.57274,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:189, step:4750 (TRAIN, VALID): total: 2050.40, 2051.58      recon: 2035.98, 2037.41,     kl: 11.85, 11.60,     l2: 2.57008,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:190, step:4775 (TRAIN, VALID): total: 2050.11, 2052.36      recon: 2035.73, 2038.23,     kl: 11.81, 11.56,     l2: 2.56992,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:191, step:4800 (TRAIN, VALID): total: 2049.99, 2051.03      recon: 2035.69, 2036.96,     kl: 11.73, 11.50,     l2: 2.56444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:192, step:4825 (TRAIN, VALID): total: 2050.28, 2051.12      recon: 2035.90, 2036.84,     kl: 11.82, 11.72,     l2: 2.56023,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:193, step:4850 (TRAIN, VALID): total: 2050.51, 2051.57      recon: 2036.06, 2036.85,     kl: 11.88, 12.16,     l2: 2.56074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:194, step:4875 (TRAIN, VALID): total: 2051.23, 2050.98      recon: 2036.52, 2036.57,     kl: 12.15, 11.85,     l2: 2.55901,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005133.\n",
      "Epoch:195, step:4900 (TRAIN, VALID): total: 2050.22, 2053.81      recon: 2035.80, 2039.55,     kl: 11.86, 11.70,     l2: 2.56318,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:196, step:4925 (TRAIN, VALID): total: 2050.57, 2052.27      recon: 2036.11, 2038.03,     kl: 11.89, 11.68,     l2: 2.56492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:197, step:4950 (TRAIN, VALID): total: 2050.78, 2051.08      recon: 2036.43, 2037.05,     kl: 11.79, 11.47,     l2: 2.55921,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:198, step:4975 (TRAIN, VALID): total: 2050.05, 2051.98      recon: 2035.67, 2037.96,     kl: 11.82, 11.45,     l2: 2.56636,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:199, step:5000 (TRAIN, VALID): total: 2049.63, 2049.49      recon: 2035.18, 2035.29,     kl: 11.89, 11.63,     l2: 2.56983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:200, step:5025 (TRAIN, VALID): total: 2049.14, 2049.82      recon: 2034.83, 2035.79,     kl: 11.74, 11.47,     l2: 2.56349,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:201, step:5050 (TRAIN, VALID): total: 2049.75, 2053.86      recon: 2035.31, 2039.58,     kl: 11.88, 11.72,     l2: 2.56313,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:202, step:5075 (TRAIN, VALID): total: 2050.89, 2050.44      recon: 2036.42, 2036.09,     kl: 11.91, 11.79,     l2: 2.55586,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004877.\n",
      "Epoch:203, step:5100 (TRAIN, VALID): total: 2050.22, 2051.06      recon: 2035.76, 2036.95,     kl: 11.90, 11.55,     l2: 2.55668,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:204, step:5125 (TRAIN, VALID): total: 2049.17, 2051.83      recon: 2034.73, 2037.13,     kl: 11.88, 12.14,     l2: 2.55815,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:205, step:5150 (TRAIN, VALID): total: 2049.84, 2050.37      recon: 2035.44, 2036.25,     kl: 11.85, 11.56,     l2: 2.55397,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:206, step:5175 (TRAIN, VALID): total: 2050.31, 2054.44      recon: 2035.98, 2040.59,     kl: 11.78, 11.30,     l2: 2.55542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:207, step:5200 (TRAIN, VALID): total: 2050.50, 2051.05      recon: 2036.17, 2036.88,     kl: 11.77, 11.61,     l2: 2.55657,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:208, step:5225 (TRAIN, VALID): total: 2049.41, 2049.54      recon: 2034.95, 2035.42,     kl: 11.90, 11.57,     l2: 2.55818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:209, step:5250 (TRAIN, VALID): total: 2048.70, 2050.63      recon: 2034.30, 2036.31,     kl: 11.85, 11.77,     l2: 2.55320,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:210, step:5275 (TRAIN, VALID): total: 2051.54, 2051.37      recon: 2036.82, 2037.20,     kl: 12.17, 11.63,     l2: 2.54596,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004633.\n",
      "Epoch:211, step:5300 (TRAIN, VALID): total: 2049.76, 2051.04      recon: 2035.39, 2036.66,     kl: 11.82, 11.83,     l2: 2.54856,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:212, step:5325 (TRAIN, VALID): total: 2049.15, 2049.56      recon: 2034.74, 2035.26,     kl: 11.86, 11.75,     l2: 2.55053,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:213, step:5350 (TRAIN, VALID): total: 2048.65, 2051.05      recon: 2034.27, 2036.70,     kl: 11.83, 11.81,     l2: 2.54751,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:214, step:5375 (TRAIN, VALID): total: 2048.57, 2049.24      recon: 2034.15, 2035.06,     kl: 11.87, 11.63,     l2: 2.54608,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:215, step:5400 (TRAIN, VALID): total: 2049.10, 2050.90      recon: 2034.72, 2036.74,     kl: 11.84, 11.62,     l2: 2.54335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:216, step:5425 (TRAIN, VALID): total: 2049.18, 2050.88      recon: 2034.76, 2036.74,     kl: 11.88, 11.60,     l2: 2.54483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:217, step:5450 (TRAIN, VALID): total: 2048.76, 2049.97      recon: 2034.49, 2036.02,     kl: 11.73, 11.42,     l2: 2.54345,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:218, step:5475 (TRAIN, VALID): total: 2048.82, 2050.25      recon: 2034.44, 2035.97,     kl: 11.84, 11.75,     l2: 2.53977,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:219, step:5500 (TRAIN, VALID): total: 2048.82, 2051.28      recon: 2034.32, 2036.64,     kl: 11.96, 12.10,     l2: 2.53825,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:220, step:5525 (TRAIN, VALID): total: 2049.34, 2051.06      recon: 2034.87, 2036.80,     kl: 11.93, 11.73,     l2: 2.53603,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004401.\n",
      "Epoch:221, step:5550 (TRAIN, VALID): total: 2049.02, 2050.33      recon: 2034.51, 2036.15,     kl: 11.97, 11.65,     l2: 2.53731,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:222, step:5575 (TRAIN, VALID): total: 2049.22, 2054.29      recon: 2034.77, 2039.91,     kl: 11.91, 11.85,     l2: 2.53559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:223, step:5600 (TRAIN, VALID): total: 2048.90, 2049.33      recon: 2034.47, 2035.09,     kl: 11.89, 11.71,     l2: 2.53458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:224, step:5625 (TRAIN, VALID): total: 2048.07, 2049.75      recon: 2033.80, 2035.42,     kl: 11.73, 11.79,     l2: 2.53526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:225, step:5650 (TRAIN, VALID): total: 2049.21, 2049.29      recon: 2034.57, 2035.00,     kl: 12.11, 11.75,     l2: 2.53508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:226, step:5675 (TRAIN, VALID): total: 2048.60, 2051.12      recon: 2034.17, 2036.62,     kl: 11.90, 11.97,     l2: 2.52885,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:227, step:5700 (TRAIN, VALID): total: 2048.22, 2050.29      recon: 2033.75, 2035.82,     kl: 11.94, 11.94,     l2: 2.52764,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:228, step:5725 (TRAIN, VALID): total: 2047.82, 2048.77      recon: 2033.45, 2034.63,     kl: 11.85, 11.62,     l2: 2.52634,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:229, step:5750 (TRAIN, VALID): total: 2048.09, 2051.98      recon: 2033.68, 2037.57,     kl: 11.88, 11.88,     l2: 2.52185,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:230, step:5775 (TRAIN, VALID): total: 2048.99, 2049.22      recon: 2034.52, 2035.03,     kl: 11.95, 11.67,     l2: 2.51953,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:231, step:5800 (TRAIN, VALID): total: 2048.70, 2050.78      recon: 2034.23, 2036.66,     kl: 11.95, 11.61,     l2: 2.51792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:232, step:5825 (TRAIN, VALID): total: 2048.18, 2050.93      recon: 2033.77, 2036.71,     kl: 11.90, 11.70,     l2: 2.51919,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:233, step:5850 (TRAIN, VALID): total: 2048.64, 2049.97      recon: 2034.29, 2036.00,     kl: 11.83, 11.46,     l2: 2.51642,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:234, step:5875 (TRAIN, VALID): total: 2048.81, 2050.35      recon: 2034.52, 2036.35,     kl: 11.77, 11.48,     l2: 2.51438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:235, step:5900 (TRAIN, VALID): total: 2048.12, 2049.58      recon: 2033.84, 2035.52,     kl: 11.77, 11.55,     l2: 2.51240,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:236, step:5925 (TRAIN, VALID): total: 2048.20, 2049.71      recon: 2033.88, 2035.64,     kl: 11.80, 11.56,     l2: 2.51301,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:237, step:5950 (TRAIN, VALID): total: 2048.93, 2052.77      recon: 2034.56, 2038.62,     kl: 11.86, 11.64,     l2: 2.51059,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004181.\n",
      "Epoch:238, step:5975 (TRAIN, VALID): total: 2049.69, 2051.02      recon: 2035.40, 2037.14,     kl: 11.78, 11.36,     l2: 2.51160,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:239, step:6000 (TRAIN, VALID): total: 2048.28, 2050.62      recon: 2033.96, 2036.25,     kl: 11.80, 11.85,     l2: 2.51636,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:240, step:6025 (TRAIN, VALID): total: 2048.35, 2051.13      recon: 2033.96, 2037.13,     kl: 11.88, 11.48,     l2: 2.51483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:241, step:6050 (TRAIN, VALID): total: 2048.04, 2049.46      recon: 2033.62, 2035.36,     kl: 11.90, 11.59,     l2: 2.51770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:242, step:6075 (TRAIN, VALID): total: 2048.52, 2051.28      recon: 2034.26, 2037.29,     kl: 11.75, 11.47,     l2: 2.51455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:243, step:6100 (TRAIN, VALID): total: 2048.60, 2049.00      recon: 2034.18, 2034.98,     kl: 11.90, 11.51,     l2: 2.51532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:244, step:6125 (TRAIN, VALID): total: 2047.95, 2049.94      recon: 2033.55, 2035.66,     kl: 11.88, 11.77,     l2: 2.51430,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:245, step:6150 (TRAIN, VALID): total: 2047.70, 2050.13      recon: 2033.29, 2036.14,     kl: 11.90, 11.48,     l2: 2.51294,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:246, step:6175 (TRAIN, VALID): total: 2047.46, 2049.35      recon: 2033.09, 2035.19,     kl: 11.86, 11.65,     l2: 2.51235,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:247, step:6200 (TRAIN, VALID): total: 2047.80, 2049.61      recon: 2033.45, 2035.54,     kl: 11.84, 11.57,     l2: 2.50576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:248, step:6225 (TRAIN, VALID): total: 2048.08, 2050.42      recon: 2033.80, 2036.35,     kl: 11.77, 11.57,     l2: 2.50647,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:249, step:6250 (TRAIN, VALID): total: 2047.98, 2049.23      recon: 2033.58, 2035.06,     kl: 11.90, 11.66,     l2: 2.50570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:250, step:6275 (TRAIN, VALID): total: 2047.44, 2050.66      recon: 2033.04, 2036.30,     kl: 11.89, 11.85,     l2: 2.50618,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:251, step:6300 (TRAIN, VALID): total: 2047.83, 2049.68      recon: 2033.40, 2035.50,     kl: 11.93, 11.68,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:252, step:6325 (TRAIN, VALID): total: 2047.88, 2050.59      recon: 2033.57, 2036.48,     kl: 11.81, 11.61,     l2: 2.50304,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:253, step:6350 (TRAIN, VALID): total: 2047.92, 2051.01      recon: 2033.50, 2036.85,     kl: 11.91, 11.66,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:254, step:6375 (TRAIN, VALID): total: 2049.30, 2051.79      recon: 2034.75, 2037.22,     kl: 12.05, 12.07,     l2: 2.50061,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003972.\n",
      "Epoch:255, step:6400 (TRAIN, VALID): total: 2049.15, 2051.76      recon: 2034.54, 2037.21,     kl: 12.11, 12.05,     l2: 2.50052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:256, step:6425 (TRAIN, VALID): total: 2049.50, 2055.74      recon: 2034.97, 2041.50,     kl: 12.03, 11.74,     l2: 2.49890,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:257, step:6450 (TRAIN, VALID): total: 2051.54, 2049.95      recon: 2037.14, 2035.61,     kl: 11.90, 11.83,     l2: 2.50043,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:258, step:6475 (TRAIN, VALID): total: 2048.29, 2050.26      recon: 2033.89, 2036.05,     kl: 11.89, 11.71,     l2: 2.50865,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:259, step:6500 (TRAIN, VALID): total: 2048.13, 2050.63      recon: 2033.68, 2036.22,     kl: 11.94, 11.90,     l2: 2.51186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:260, step:6525 (TRAIN, VALID): total: 2047.80, 2050.28      recon: 2033.32, 2035.90,     kl: 11.97, 11.87,     l2: 2.51188,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:261, step:6550 (TRAIN, VALID): total: 2047.38, 2048.39      recon: 2032.95, 2034.28,     kl: 11.92, 11.60,     l2: 2.51125,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:262, step:6575 (TRAIN, VALID): total: 2047.43, 2049.52      recon: 2033.04, 2035.25,     kl: 11.88, 11.76,     l2: 2.51090,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:263, step:6600 (TRAIN, VALID): total: 2047.74, 2050.23      recon: 2033.07, 2036.16,     kl: 12.17, 11.55,     l2: 2.51018,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:264, step:6625 (TRAIN, VALID): total: 2048.07, 2048.76      recon: 2033.67, 2034.55,     kl: 11.90, 11.70,     l2: 2.50776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:265, step:6650 (TRAIN, VALID): total: 2048.24, 2051.42      recon: 2033.71, 2037.16,     kl: 12.02, 11.76,     l2: 2.50451,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003774.\n",
      "Epoch:266, step:6675 (TRAIN, VALID): total: 2047.94, 2050.67      recon: 2033.53, 2036.13,     kl: 11.91, 12.04,     l2: 2.50510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:267, step:6700 (TRAIN, VALID): total: 2049.05, 2049.66      recon: 2034.58, 2035.42,     kl: 11.96, 11.74,     l2: 2.50390,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:268, step:6725 (TRAIN, VALID): total: 2048.73, 2050.87      recon: 2034.05, 2036.51,     kl: 12.17, 11.86,     l2: 2.50944,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:269, step:6750 (TRAIN, VALID): total: 2048.16, 2049.58      recon: 2033.76, 2035.33,     kl: 11.89, 11.74,     l2: 2.50939,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:270, step:6775 (TRAIN, VALID): total: 2049.02, 2050.21      recon: 2034.32, 2035.77,     kl: 12.18, 11.93,     l2: 2.51130,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:271, step:6800 (TRAIN, VALID): total: 2048.63, 2050.82      recon: 2034.19, 2036.54,     kl: 11.93, 11.77,     l2: 2.50963,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:272, step:6825 (TRAIN, VALID): total: 2047.50, 2048.91      recon: 2033.03, 2034.84,     kl: 11.96, 11.56,     l2: 2.51249,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:273, step:6850 (TRAIN, VALID): total: 2047.61, 2049.83      recon: 2033.12, 2035.62,     kl: 11.97, 11.70,     l2: 2.51427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:274, step:6875 (TRAIN, VALID): total: 2047.24, 2048.76      recon: 2032.76, 2034.55,     kl: 11.96, 11.70,     l2: 2.51340,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:275, step:6900 (TRAIN, VALID): total: 2047.72, 2050.43      recon: 2033.22, 2036.16,     kl: 11.99, 11.75,     l2: 2.51394,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:276, step:6925 (TRAIN, VALID): total: 2047.39, 2049.80      recon: 2032.87, 2035.48,     kl: 12.00, 11.82,     l2: 2.50920,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:277, step:6950 (TRAIN, VALID): total: 2047.46, 2050.43      recon: 2033.01, 2036.10,     kl: 11.94, 11.82,     l2: 2.51225,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:278, step:6975 (TRAIN, VALID): total: 2048.17, 2049.82      recon: 2033.67, 2035.52,     kl: 11.99, 11.79,     l2: 2.50795,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003585.\n",
      "Epoch:279, step:7000 (TRAIN, VALID): total: 2047.24, 2047.63      recon: 2032.73, 2033.38,     kl: 12.00, 11.75,     l2: 2.51031,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:280, step:7025 (TRAIN, VALID): total: 2048.18, 2050.62      recon: 2033.65, 2036.30,     kl: 12.02, 11.82,     l2: 2.50647,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:281, step:7050 (TRAIN, VALID): total: 2047.79, 2048.72      recon: 2033.21, 2034.37,     kl: 12.07, 11.84,     l2: 2.50903,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:282, step:7075 (TRAIN, VALID): total: 2047.12, 2050.29      recon: 2032.70, 2035.96,     kl: 11.92, 11.82,     l2: 2.50923,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:283, step:7100 (TRAIN, VALID): total: 2047.03, 2049.93      recon: 2032.62, 2035.61,     kl: 11.90, 11.82,     l2: 2.50669,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:284, step:7125 (TRAIN, VALID): total: 2047.73, 2048.98      recon: 2033.18, 2034.70,     kl: 12.04, 11.77,     l2: 2.50629,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:285, step:7150 (TRAIN, VALID): total: 2046.96, 2049.17      recon: 2032.46, 2034.91,     kl: 11.99, 11.76,     l2: 2.50479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:286, step:7175 (TRAIN, VALID): total: 2047.39, 2050.34      recon: 2032.83, 2036.00,     kl: 12.06, 11.83,     l2: 2.50354,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:287, step:7200 (TRAIN, VALID): total: 2047.13, 2048.67      recon: 2032.64, 2034.54,     kl: 11.99, 11.63,     l2: 2.50359,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:288, step:7225 (TRAIN, VALID): total: 2047.33, 2048.75      recon: 2032.90, 2034.53,     kl: 11.92, 11.71,     l2: 2.50254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:289, step:7250 (TRAIN, VALID): total: 2047.54, 2048.82      recon: 2033.12, 2034.08,     kl: 11.92, 12.24,     l2: 2.50101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:290, step:7275 (TRAIN, VALID): total: 2048.09, 2049.34      recon: 2033.37, 2035.09,     kl: 12.22, 11.76,     l2: 2.49885,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003406.\n",
      "Epoch:291, step:7300 (TRAIN, VALID): total: 2047.15, 2049.11      recon: 2032.80, 2035.05,     kl: 11.86, 11.55,     l2: 2.50147,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:292, step:7325 (TRAIN, VALID): total: 2046.90, 2048.83      recon: 2032.55, 2034.62,     kl: 11.85, 11.71,     l2: 2.50088,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:293, step:7350 (TRAIN, VALID): total: 2047.08, 2047.40      recon: 2032.63, 2033.15,     kl: 11.94, 11.75,     l2: 2.50131,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:294, step:7375 (TRAIN, VALID): total: 2046.75, 2050.83      recon: 2032.33, 2036.65,     kl: 11.91, 11.68,     l2: 2.50138,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:295, step:7400 (TRAIN, VALID): total: 2047.72, 2049.88      recon: 2033.29, 2035.48,     kl: 11.93, 11.90,     l2: 2.49990,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:296, step:7425 (TRAIN, VALID): total: 2047.22, 2048.34      recon: 2032.78, 2034.11,     kl: 11.94, 11.73,     l2: 2.50226,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:297, step:7450 (TRAIN, VALID): total: 2047.32, 2049.12      recon: 2032.90, 2034.87,     kl: 11.92, 11.75,     l2: 2.50253,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:298, step:7475 (TRAIN, VALID): total: 2046.63, 2047.86      recon: 2032.26, 2033.87,     kl: 11.87, 11.48,     l2: 2.50413,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:299, step:7500 (TRAIN, VALID): total: 2047.61, 2049.71      recon: 2033.20, 2035.44,     kl: 11.91, 11.77,     l2: 2.50249,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:300, step:7525 (TRAIN, VALID): total: 2047.00, 2048.30      recon: 2032.56, 2034.07,     kl: 11.94, 11.72,     l2: 2.50494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:301, step:7550 (TRAIN, VALID): total: 2046.67, 2049.90      recon: 2032.30, 2035.70,     kl: 11.86, 11.70,     l2: 2.50241,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:302, step:7575 (TRAIN, VALID): total: 2047.08, 2050.37      recon: 2032.67, 2036.15,     kl: 11.91, 11.72,     l2: 2.50066,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:303, step:7600 (TRAIN, VALID): total: 2047.54, 2057.28      recon: 2033.10, 2042.91,     kl: 11.94, 11.87,     l2: 2.49964,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:304, step:7625 (TRAIN, VALID): total: 2049.10, 2049.27      recon: 2034.75, 2035.16,     kl: 11.85, 11.60,     l2: 2.50088,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003235.\n",
      "Epoch:305, step:7650 (TRAIN, VALID): total: 2046.87, 2049.45      recon: 2032.51, 2035.35,     kl: 11.85, 11.59,     l2: 2.50567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:306, step:7675 (TRAIN, VALID): total: 2046.47, 2047.69      recon: 2032.12, 2033.44,     kl: 11.84, 11.75,     l2: 2.50798,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:307, step:7700 (TRAIN, VALID): total: 2047.25, 2048.69      recon: 2032.80, 2034.60,     kl: 11.95, 11.59,     l2: 2.50694,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:308, step:7725 (TRAIN, VALID): total: 2046.66, 2049.12      recon: 2032.24, 2034.92,     kl: 11.91, 11.69,     l2: 2.50499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:309, step:7750 (TRAIN, VALID): total: 2046.79, 2047.06      recon: 2032.27, 2032.83,     kl: 12.02, 11.73,     l2: 2.50619,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:310, step:7775 (TRAIN, VALID): total: 2047.66, 2048.55      recon: 2033.11, 2034.22,     kl: 12.04, 11.82,     l2: 2.50727,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:311, step:7800 (TRAIN, VALID): total: 2047.26, 2048.58      recon: 2032.82, 2034.37,     kl: 11.93, 11.71,     l2: 2.50610,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:312, step:7825 (TRAIN, VALID): total: 2046.81, 2049.14      recon: 2032.35, 2035.02,     kl: 11.95, 11.61,     l2: 2.50944,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:313, step:7850 (TRAIN, VALID): total: 2046.95, 2050.41      recon: 2032.43, 2035.93,     kl: 12.02, 11.97,     l2: 2.50860,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:314, step:7875 (TRAIN, VALID): total: 2046.90, 2048.48      recon: 2032.40, 2034.25,     kl: 12.00, 11.72,     l2: 2.50808,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:315, step:7900 (TRAIN, VALID): total: 2046.98, 2049.51      recon: 2032.48, 2035.26,     kl: 11.99, 11.74,     l2: 2.50692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:316, step:7925 (TRAIN, VALID): total: 2046.56, 2048.53      recon: 2032.12, 2034.37,     kl: 11.93, 11.65,     l2: 2.50871,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:317, step:7950 (TRAIN, VALID): total: 2046.69, 2048.50      recon: 2032.26, 2034.17,     kl: 11.92, 11.82,     l2: 2.50594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:318, step:7975 (TRAIN, VALID): total: 2046.60, 2049.94      recon: 2032.10, 2035.72,     kl: 11.99, 11.72,     l2: 2.50640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:319, step:8000 (TRAIN, VALID): total: 2046.46, 2047.92      recon: 2032.06, 2033.72,     kl: 11.90, 11.69,     l2: 2.50624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:320, step:8025 (TRAIN, VALID): total: 2046.33, 2048.93      recon: 2031.95, 2034.89,     kl: 11.88, 11.53,     l2: 2.50420,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:321, step:8050 (TRAIN, VALID): total: 2046.33, 2047.04      recon: 2031.89, 2032.82,     kl: 11.94, 11.71,     l2: 2.50702,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:322, step:8075 (TRAIN, VALID): total: 2046.81, 2052.28      recon: 2032.39, 2038.06,     kl: 11.91, 11.72,     l2: 2.50331,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.003074.\n",
      "Epoch:323, step:8100 (TRAIN, VALID): total: 2046.66, 2047.90      recon: 2032.23, 2033.77,     kl: 11.92, 11.63,     l2: 2.50569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:324, step:8125 (TRAIN, VALID): total: 2046.15, 2049.75      recon: 2031.80, 2035.39,     kl: 11.85, 11.85,     l2: 2.50510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:325, step:8150 (TRAIN, VALID): total: 2046.30, 2049.19      recon: 2031.79, 2035.02,     kl: 12.00, 11.67,     l2: 2.50570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:326, step:8175 (TRAIN, VALID): total: 2046.04, 2049.43      recon: 2031.62, 2035.12,     kl: 11.91, 11.81,     l2: 2.50182,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:327, step:8200 (TRAIN, VALID): total: 2046.06, 2048.38      recon: 2031.61, 2034.05,     kl: 11.95, 11.83,     l2: 2.49981,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:328, step:8225 (TRAIN, VALID): total: 2047.11, 2048.95      recon: 2032.53, 2034.62,     kl: 12.09, 11.83,     l2: 2.49983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:329, step:8250 (TRAIN, VALID): total: 2047.13, 2049.28      recon: 2032.75, 2035.13,     kl: 11.88, 11.65,     l2: 2.49968,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002920.\n",
      "Epoch:330, step:8275 (TRAIN, VALID): total: 2046.65, 2048.95      recon: 2032.33, 2034.74,     kl: 11.82, 11.71,     l2: 2.50133,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:331, step:8300 (TRAIN, VALID): total: 2047.28, 2048.88      recon: 2032.73, 2034.60,     kl: 12.05, 11.78,     l2: 2.50321,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:332, step:8325 (TRAIN, VALID): total: 2046.21, 2047.87      recon: 2031.77, 2033.57,     kl: 11.94, 11.80,     l2: 2.50607,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:333, step:8350 (TRAIN, VALID): total: 2046.03, 2047.91      recon: 2031.56, 2033.77,     kl: 11.96, 11.63,     l2: 2.50518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:334, step:8375 (TRAIN, VALID): total: 2046.23, 2048.31      recon: 2031.75, 2034.21,     kl: 11.98, 11.60,     l2: 2.50427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:335, step:8400 (TRAIN, VALID): total: 2046.21, 2048.84      recon: 2031.75, 2034.55,     kl: 11.95, 11.79,     l2: 2.50514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:336, step:8425 (TRAIN, VALID): total: 2046.90, 2048.82      recon: 2032.37, 2034.31,     kl: 12.03, 12.01,     l2: 2.50325,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:337, step:8450 (TRAIN, VALID): total: 2046.27, 2049.89      recon: 2031.81, 2035.39,     kl: 11.96, 12.00,     l2: 2.50283,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:338, step:8475 (TRAIN, VALID): total: 2046.38, 2049.58      recon: 2031.96, 2035.35,     kl: 11.91, 11.73,     l2: 2.50170,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:339, step:8500 (TRAIN, VALID): total: 2046.21, 2048.15      recon: 2031.80, 2033.91,     kl: 11.91, 11.73,     l2: 2.50116,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:340, step:8525 (TRAIN, VALID): total: 2045.94, 2047.28      recon: 2031.45, 2033.14,     kl: 11.98, 11.65,     l2: 2.50174,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:341, step:8550 (TRAIN, VALID): total: 2046.28, 2048.11      recon: 2031.82, 2033.63,     kl: 11.96, 11.97,     l2: 2.50127,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:342, step:8575 (TRAIN, VALID): total: 2046.46, 2048.74      recon: 2031.98, 2034.43,     kl: 11.98, 11.81,     l2: 2.50281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:343, step:8600 (TRAIN, VALID): total: 2046.34, 2048.72      recon: 2031.86, 2034.45,     kl: 11.98, 11.77,     l2: 2.50136,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:344, step:8625 (TRAIN, VALID): total: 2046.20, 2048.67      recon: 2031.78, 2034.50,     kl: 11.91, 11.67,     l2: 2.50270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:345, step:8650 (TRAIN, VALID): total: 2046.61, 2048.28      recon: 2032.17, 2033.97,     kl: 11.94, 11.81,     l2: 2.50240,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002774.\n",
      "Epoch:346, step:8675 (TRAIN, VALID): total: 2046.16, 2049.86      recon: 2031.74, 2035.66,     kl: 11.92, 11.70,     l2: 2.50354,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:347, step:8700 (TRAIN, VALID): total: 2046.61, 2048.61      recon: 2032.17, 2034.36,     kl: 11.94, 11.74,     l2: 2.49998,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:348, step:8725 (TRAIN, VALID): total: 2045.89, 2048.79      recon: 2031.48, 2034.61,     kl: 11.92, 11.68,     l2: 2.50031,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:349, step:8750 (TRAIN, VALID): total: 2045.79, 2047.50      recon: 2031.37, 2033.28,     kl: 11.92, 11.72,     l2: 2.50019,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:350, step:8775 (TRAIN, VALID): total: 2046.34, 2048.46      recon: 2031.85, 2034.04,     kl: 11.99, 11.92,     l2: 2.50057,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:351, step:8800 (TRAIN, VALID): total: 2046.09, 2049.48      recon: 2031.59, 2035.12,     kl: 12.00, 11.86,     l2: 2.49587,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:352, step:8825 (TRAIN, VALID): total: 2047.21, 2049.37      recon: 2032.39, 2034.94,     kl: 12.32, 11.93,     l2: 2.49690,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002635.\n",
      "Epoch:353, step:8850 (TRAIN, VALID): total: 2046.38, 2047.60      recon: 2031.86, 2033.32,     kl: 12.02, 11.78,     l2: 2.49818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:354, step:8875 (TRAIN, VALID): total: 2045.69, 2049.45      recon: 2031.35, 2035.25,     kl: 11.84, 11.70,     l2: 2.49926,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:355, step:8900 (TRAIN, VALID): total: 2046.06, 2048.38      recon: 2031.60, 2034.00,     kl: 11.96, 11.89,     l2: 2.49747,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:356, step:8925 (TRAIN, VALID): total: 2045.82, 2047.75      recon: 2031.39, 2033.69,     kl: 11.93, 11.57,     l2: 2.49711,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:357, step:8950 (TRAIN, VALID): total: 2046.05, 2049.27      recon: 2031.68, 2035.16,     kl: 11.88, 11.61,     l2: 2.49793,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:358, step:8975 (TRAIN, VALID): total: 2045.83, 2048.13      recon: 2031.40, 2033.97,     kl: 11.93, 11.67,     l2: 2.49823,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:359, step:9000 (TRAIN, VALID): total: 2045.95, 2047.85      recon: 2031.45, 2033.62,     kl: 12.00, 11.73,     l2: 2.49872,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:360, step:9025 (TRAIN, VALID): total: 2045.79, 2049.35      recon: 2031.40, 2035.15,     kl: 11.88, 11.71,     l2: 2.49839,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:361, step:9050 (TRAIN, VALID): total: 2046.81, 2048.87      recon: 2032.19, 2034.67,     kl: 12.13, 11.70,     l2: 2.49866,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002503.\n",
      "Epoch:362, step:9075 (TRAIN, VALID): total: 2047.18, 2048.33      recon: 2032.69, 2034.10,     kl: 11.99, 11.74,     l2: 2.49657,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:363, step:9100 (TRAIN, VALID): total: 2045.91, 2049.18      recon: 2031.49, 2034.97,     kl: 11.92, 11.72,     l2: 2.49838,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:364, step:9125 (TRAIN, VALID): total: 2045.96, 2048.28      recon: 2031.58, 2033.96,     kl: 11.87, 11.82,     l2: 2.49986,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:365, step:9150 (TRAIN, VALID): total: 2045.71, 2048.21      recon: 2031.22, 2033.82,     kl: 11.99, 11.90,     l2: 2.50036,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:366, step:9175 (TRAIN, VALID): total: 2045.57, 2047.68      recon: 2031.10, 2033.36,     kl: 11.97, 11.82,     l2: 2.49785,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:367, step:9200 (TRAIN, VALID): total: 2046.20, 2049.54      recon: 2031.53, 2035.16,     kl: 12.17, 11.88,     l2: 2.49728,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:368, step:9225 (TRAIN, VALID): total: 2045.81, 2048.23      recon: 2031.34, 2034.03,     kl: 11.98, 11.70,     l2: 2.49749,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:369, step:9250 (TRAIN, VALID): total: 2045.93, 2049.21      recon: 2031.52, 2035.13,     kl: 11.92, 11.58,     l2: 2.49763,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:370, step:9275 (TRAIN, VALID): total: 2045.47, 2047.32      recon: 2031.10, 2033.08,     kl: 11.87, 11.74,     l2: 2.49828,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:371, step:9300 (TRAIN, VALID): total: 2045.52, 2048.15      recon: 2031.06, 2033.77,     kl: 11.96, 11.89,     l2: 2.49930,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:372, step:9325 (TRAIN, VALID): total: 2045.69, 2048.68      recon: 2031.23, 2034.63,     kl: 11.97, 11.55,     l2: 2.49776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:373, step:9350 (TRAIN, VALID): total: 2046.04, 2048.53      recon: 2031.55, 2034.34,     kl: 12.00, 11.69,     l2: 2.49795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:374, step:9375 (TRAIN, VALID): total: 2045.58, 2048.25      recon: 2031.21, 2033.96,     kl: 11.88, 11.79,     l2: 2.49779,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:375, step:9400 (TRAIN, VALID): total: 2045.93, 2047.96      recon: 2031.39, 2033.72,     kl: 12.04, 11.74,     l2: 2.49698,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:376, step:9425 (TRAIN, VALID): total: 2046.15, 2048.80      recon: 2031.62, 2034.44,     kl: 12.03, 11.87,     l2: 2.49865,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002378.\n",
      "Epoch:377, step:9450 (TRAIN, VALID): total: 2045.55, 2047.01      recon: 2031.07, 2032.64,     kl: 11.98, 11.86,     l2: 2.49762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:378, step:9475 (TRAIN, VALID): total: 2045.26, 2047.32      recon: 2030.75, 2033.09,     kl: 12.01, 11.73,     l2: 2.49770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:379, step:9500 (TRAIN, VALID): total: 2045.16, 2047.77      recon: 2030.71, 2033.60,     kl: 11.95, 11.68,     l2: 2.49713,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:380, step:9525 (TRAIN, VALID): total: 2045.50, 2047.05      recon: 2031.09, 2032.99,     kl: 11.91, 11.57,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:381, step:9550 (TRAIN, VALID): total: 2045.49, 2048.43      recon: 2031.14, 2034.35,     kl: 11.86, 11.58,     l2: 2.49728,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:382, step:9575 (TRAIN, VALID): total: 2046.20, 2049.09      recon: 2031.61, 2034.72,     kl: 12.10, 11.88,     l2: 2.49773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:383, step:9600 (TRAIN, VALID): total: 2045.46, 2047.97      recon: 2030.95, 2033.69,     kl: 12.01, 11.78,     l2: 2.49589,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:384, step:9625 (TRAIN, VALID): total: 2045.25, 2047.44      recon: 2030.82, 2033.18,     kl: 11.93, 11.76,     l2: 2.49624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:385, step:9650 (TRAIN, VALID): total: 2045.45, 2047.70      recon: 2030.99, 2033.45,     kl: 11.96, 11.76,     l2: 2.49377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:386, step:9675 (TRAIN, VALID): total: 2045.22, 2047.81      recon: 2030.82, 2033.70,     kl: 11.90, 11.62,     l2: 2.49450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:387, step:9700 (TRAIN, VALID): total: 2045.42, 2047.05      recon: 2030.92, 2032.72,     kl: 12.00, 11.84,     l2: 2.49536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:388, step:9725 (TRAIN, VALID): total: 2045.80, 2048.22      recon: 2031.31, 2033.75,     kl: 11.99, 11.97,     l2: 2.49416,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:389, step:9750 (TRAIN, VALID): total: 2045.65, 2047.21      recon: 2031.20, 2033.06,     kl: 11.96, 11.65,     l2: 2.49583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:390, step:9775 (TRAIN, VALID): total: 2045.40, 2048.75      recon: 2031.05, 2034.59,     kl: 11.86, 11.66,     l2: 2.49562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:391, step:9800 (TRAIN, VALID): total: 2045.30, 2048.01      recon: 2030.88, 2033.71,     kl: 11.93, 11.81,     l2: 2.49479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:392, step:9825 (TRAIN, VALID): total: 2045.89, 2048.15      recon: 2031.32, 2034.02,     kl: 12.08, 11.64,     l2: 2.49425,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002259.\n",
      "Epoch:393, step:9850 (TRAIN, VALID): total: 2046.18, 2047.79      recon: 2031.72, 2033.45,     kl: 11.96, 11.84,     l2: 2.49426,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:394, step:9875 (TRAIN, VALID): total: 2045.15, 2047.64      recon: 2030.72, 2033.44,     kl: 11.93, 11.70,     l2: 2.49577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:395, step:9900 (TRAIN, VALID): total: 2045.22, 2047.44      recon: 2030.81, 2033.33,     kl: 11.92, 11.61,     l2: 2.49464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:396, step:9925 (TRAIN, VALID): total: 2045.22, 2048.99      recon: 2030.77, 2034.73,     kl: 11.95, 11.76,     l2: 2.49391,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:397, step:9950 (TRAIN, VALID): total: 2045.20, 2048.49      recon: 2030.78, 2034.38,     kl: 11.93, 11.62,     l2: 2.49431,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:398, step:9975 (TRAIN, VALID): total: 2045.20, 2048.57      recon: 2030.78, 2034.40,     kl: 11.92, 11.68,     l2: 2.49542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:399, step:10000 (TRAIN, VALID): total: 2046.01, 2049.03      recon: 2031.49, 2034.77,     kl: 12.02, 11.76,     l2: 2.49450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:400, step:10025 (TRAIN, VALID): total: 2045.68, 2048.01      recon: 2031.19, 2033.72,     kl: 11.99, 11.80,     l2: 2.49311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:401, step:10050 (TRAIN, VALID): total: 2045.05, 2047.62      recon: 2030.69, 2033.59,     kl: 11.86, 11.54,     l2: 2.49611,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:402, step:10075 (TRAIN, VALID): total: 2045.73, 2048.01      recon: 2031.27, 2033.95,     kl: 11.96, 11.56,     l2: 2.49627,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:403, step:10100 (TRAIN, VALID): total: 2045.64, 2048.20      recon: 2030.98, 2033.93,     kl: 12.16, 11.78,     l2: 2.49437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:404, step:10125 (TRAIN, VALID): total: 2045.25, 2048.47      recon: 2030.80, 2034.31,     kl: 11.96, 11.67,     l2: 2.49400,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:405, step:10150 (TRAIN, VALID): total: 2045.37, 2047.98      recon: 2030.94, 2033.77,     kl: 11.93, 11.72,     l2: 2.49464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:406, step:10175 (TRAIN, VALID): total: 2045.24, 2047.55      recon: 2030.82, 2033.36,     kl: 11.92, 11.69,     l2: 2.49575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:407, step:10200 (TRAIN, VALID): total: 2045.13, 2047.53      recon: 2030.73, 2033.42,     kl: 11.91, 11.61,     l2: 2.49648,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:408, step:10225 (TRAIN, VALID): total: 2045.62, 2047.92      recon: 2031.03, 2033.62,     kl: 12.10, 11.80,     l2: 2.49550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:409, step:10250 (TRAIN, VALID): total: 2045.52, 2049.00      recon: 2031.12, 2034.68,     kl: 11.90, 11.83,     l2: 2.49575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:410, step:10275 (TRAIN, VALID): total: 2045.49, 2049.19      recon: 2030.88, 2034.99,     kl: 12.11, 11.70,     l2: 2.49794,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:411, step:10300 (TRAIN, VALID): total: 2045.37, 2048.63      recon: 2030.93, 2034.38,     kl: 11.95, 11.75,     l2: 2.49757,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:412, step:10325 (TRAIN, VALID): total: 2046.71, 2049.04      recon: 2032.22, 2034.80,     kl: 12.00, 11.74,     l2: 2.49580,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002146.\n",
      "Epoch:413, step:10350 (TRAIN, VALID): total: 2045.75, 2047.96      recon: 2031.29, 2033.45,     kl: 11.97, 12.02,     l2: 2.49548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:414, step:10375 (TRAIN, VALID): total: 2045.85, 2047.35      recon: 2031.24, 2033.06,     kl: 12.11, 11.80,     l2: 2.49542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:415, step:10400 (TRAIN, VALID): total: 2045.22, 2047.55      recon: 2030.75, 2033.27,     kl: 11.97, 11.79,     l2: 2.49643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:416, step:10425 (TRAIN, VALID): total: 2045.17, 2046.88      recon: 2030.67, 2032.70,     kl: 12.00, 11.68,     l2: 2.49750,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:417, step:10450 (TRAIN, VALID): total: 2045.13, 2049.42      recon: 2030.70, 2035.16,     kl: 11.93, 11.76,     l2: 2.49866,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:418, step:10475 (TRAIN, VALID): total: 2045.18, 2048.04      recon: 2030.87, 2033.85,     kl: 11.82, 11.70,     l2: 2.49805,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:419, step:10500 (TRAIN, VALID): total: 2045.40, 2048.53      recon: 2030.80, 2034.34,     kl: 12.10, 11.68,     l2: 2.49894,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:420, step:10525 (TRAIN, VALID): total: 2044.89, 2049.01      recon: 2030.43, 2034.71,     kl: 11.96, 11.80,     l2: 2.49811,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:421, step:10550 (TRAIN, VALID): total: 2046.06, 2048.87      recon: 2031.49, 2034.62,     kl: 12.07, 11.75,     l2: 2.49787,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002039.\n",
      "Epoch:422, step:10575 (TRAIN, VALID): total: 2045.53, 2047.97      recon: 2031.01, 2033.71,     kl: 12.02, 11.76,     l2: 2.49847,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:423, step:10600 (TRAIN, VALID): total: 2045.19, 2048.31      recon: 2030.61, 2033.97,     kl: 12.08, 11.84,     l2: 2.49810,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:424, step:10625 (TRAIN, VALID): total: 2044.99, 2047.12      recon: 2030.41, 2032.75,     kl: 12.08, 11.88,     l2: 2.49740,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:425, step:10650 (TRAIN, VALID): total: 2044.79, 2048.48      recon: 2030.39, 2034.34,     kl: 11.91, 11.64,     l2: 2.49842,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:426, step:10675 (TRAIN, VALID): total: 2044.97, 2047.77      recon: 2030.53, 2033.55,     kl: 11.94, 11.73,     l2: 2.49680,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:427, step:10700 (TRAIN, VALID): total: 2045.09, 2048.26      recon: 2030.65, 2034.03,     kl: 11.94, 11.74,     l2: 2.49684,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:428, step:10725 (TRAIN, VALID): total: 2045.29, 2048.53      recon: 2030.81, 2034.32,     kl: 11.98, 11.71,     l2: 2.49774,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:429, step:10750 (TRAIN, VALID): total: 2044.89, 2047.99      recon: 2030.41, 2033.77,     kl: 11.98, 11.72,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:430, step:10775 (TRAIN, VALID): total: 2045.02, 2047.13      recon: 2030.57, 2033.00,     kl: 11.95, 11.63,     l2: 2.49600,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:431, step:10800 (TRAIN, VALID): total: 2044.95, 2047.63      recon: 2030.48, 2033.48,     kl: 11.97, 11.66,     l2: 2.49773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:432, step:10825 (TRAIN, VALID): total: 2045.50, 2048.46      recon: 2030.98, 2034.03,     kl: 12.02, 11.93,     l2: 2.49700,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001937.\n",
      "Epoch:433, step:10850 (TRAIN, VALID): total: 2045.33, 2047.36      recon: 2030.81, 2033.13,     kl: 12.03, 11.73,     l2: 2.49648,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:434, step:10875 (TRAIN, VALID): total: 2045.01, 2047.53      recon: 2030.53, 2033.20,     kl: 11.98, 11.83,     l2: 2.49576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:435, step:10900 (TRAIN, VALID): total: 2044.86, 2048.23      recon: 2030.33, 2033.78,     kl: 12.03, 11.96,     l2: 2.49680,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:436, step:10925 (TRAIN, VALID): total: 2044.95, 2047.87      recon: 2030.39, 2033.62,     kl: 12.06, 11.75,     l2: 2.49692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:437, step:10950 (TRAIN, VALID): total: 2044.95, 2048.48      recon: 2030.55, 2033.84,     kl: 11.90, 12.14,     l2: 2.49742,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:438, step:10975 (TRAIN, VALID): total: 2045.60, 2047.58      recon: 2030.76, 2033.32,     kl: 12.34, 11.76,     l2: 2.49577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:439, step:11000 (TRAIN, VALID): total: 2045.03, 2048.05      recon: 2030.59, 2033.72,     kl: 11.94, 11.83,     l2: 2.49609,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:440, step:11025 (TRAIN, VALID): total: 2044.97, 2046.27      recon: 2030.44, 2031.99,     kl: 12.04, 11.79,     l2: 2.49539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:441, step:11050 (TRAIN, VALID): total: 2045.11, 2046.98      recon: 2030.47, 2032.71,     kl: 12.14, 11.77,     l2: 2.49656,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:442, step:11075 (TRAIN, VALID): total: 2045.00, 2048.26      recon: 2030.49, 2033.99,     kl: 12.02, 11.77,     l2: 2.49669,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:443, step:11100 (TRAIN, VALID): total: 2044.88, 2047.80      recon: 2030.40, 2033.47,     kl: 11.98, 11.84,     l2: 2.49717,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:444, step:11125 (TRAIN, VALID): total: 2044.69, 2048.39      recon: 2030.31, 2034.14,     kl: 11.89, 11.75,     l2: 2.49625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:445, step:11150 (TRAIN, VALID): total: 2044.73, 2047.19      recon: 2030.29, 2033.00,     kl: 11.94, 11.69,     l2: 2.49839,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:446, step:11175 (TRAIN, VALID): total: 2044.70, 2048.76      recon: 2030.33, 2034.59,     kl: 11.87, 11.68,     l2: 2.49710,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:447, step:11200 (TRAIN, VALID): total: 2044.73, 2048.90      recon: 2030.27, 2034.60,     kl: 11.96, 11.80,     l2: 2.49805,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:448, step:11225 (TRAIN, VALID): total: 2045.09, 2045.98      recon: 2030.60, 2031.74,     kl: 11.99, 11.75,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001840.\n",
      "Epoch:449, step:11250 (TRAIN, VALID): total: 2045.32, 2047.97      recon: 2030.74, 2033.66,     kl: 12.09, 11.81,     l2: 2.49887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:450, step:11275 (TRAIN, VALID): total: 2044.95, 2049.01      recon: 2030.44, 2034.74,     kl: 12.02, 11.77,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:451, step:11300 (TRAIN, VALID): total: 2045.17, 2047.59      recon: 2030.68, 2033.34,     kl: 11.99, 11.76,     l2: 2.49841,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:452, step:11325 (TRAIN, VALID): total: 2044.60, 2047.53      recon: 2030.18, 2033.22,     kl: 11.92, 11.81,     l2: 2.49751,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:453, step:11350 (TRAIN, VALID): total: 2044.65, 2047.65      recon: 2030.16, 2033.36,     kl: 11.99, 11.79,     l2: 2.49906,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:454, step:11375 (TRAIN, VALID): total: 2045.89, 2049.44      recon: 2031.29, 2035.00,     kl: 12.09, 11.94,     l2: 2.49745,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:455, step:11400 (TRAIN, VALID): total: 2045.10, 2047.29      recon: 2030.58, 2032.95,     kl: 12.02, 11.85,     l2: 2.49620,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:456, step:11425 (TRAIN, VALID): total: 2044.89, 2046.98      recon: 2030.37, 2032.79,     kl: 12.03, 11.70,     l2: 2.49693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:457, step:11450 (TRAIN, VALID): total: 2044.54, 2047.40      recon: 2030.08, 2033.19,     kl: 11.96, 11.71,     l2: 2.49831,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:458, step:11475 (TRAIN, VALID): total: 2044.66, 2049.52      recon: 2030.25, 2035.19,     kl: 11.91, 11.83,     l2: 2.49828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:459, step:11500 (TRAIN, VALID): total: 2044.84, 2047.34      recon: 2030.29, 2032.85,     kl: 12.04, 11.99,     l2: 2.49762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:460, step:11525 (TRAIN, VALID): total: 2044.80, 2047.82      recon: 2030.25, 2033.39,     kl: 12.05, 11.93,     l2: 2.49774,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:461, step:11550 (TRAIN, VALID): total: 2044.94, 2048.08      recon: 2030.29, 2033.77,     kl: 12.15, 11.81,     l2: 2.49767,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:462, step:11575 (TRAIN, VALID): total: 2044.81, 2048.06      recon: 2030.34, 2033.86,     kl: 11.97, 11.70,     l2: 2.49673,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:463, step:11600 (TRAIN, VALID): total: 2044.84, 2048.23      recon: 2030.34, 2033.97,     kl: 12.01, 11.76,     l2: 2.49661,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:464, step:11625 (TRAIN, VALID): total: 2044.58, 2049.35      recon: 2030.11, 2035.17,     kl: 11.96, 11.68,     l2: 2.49726,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:465, step:11650 (TRAIN, VALID): total: 2044.92, 2049.04      recon: 2030.48, 2034.68,     kl: 11.95, 11.86,     l2: 2.49578,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:466, step:11675 (TRAIN, VALID): total: 2044.83, 2048.03      recon: 2030.35, 2033.68,     kl: 11.98, 11.85,     l2: 2.49688,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:467, step:11700 (TRAIN, VALID): total: 2044.70, 2047.42      recon: 2030.22, 2033.09,     kl: 11.98, 11.83,     l2: 2.49606,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:468, step:11725 (TRAIN, VALID): total: 2045.20, 2048.76      recon: 2030.64, 2034.38,     kl: 12.07, 11.88,     l2: 2.49550,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001748.\n",
      "Epoch:469, step:11750 (TRAIN, VALID): total: 2045.11, 2047.48      recon: 2030.48, 2033.16,     kl: 12.14, 11.83,     l2: 2.49714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:470, step:11775 (TRAIN, VALID): total: 2044.61, 2047.79      recon: 2030.11, 2033.51,     kl: 12.01, 11.78,     l2: 2.49714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:471, step:11800 (TRAIN, VALID): total: 2044.50, 2047.84      recon: 2030.07, 2033.56,     kl: 11.94, 11.78,     l2: 2.49775,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:472, step:11825 (TRAIN, VALID): total: 2044.43, 2047.62      recon: 2030.01, 2033.49,     kl: 11.93, 11.63,     l2: 2.49900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:473, step:11850 (TRAIN, VALID): total: 2044.58, 2048.07      recon: 2030.12, 2033.70,     kl: 11.97, 11.88,     l2: 2.49979,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:474, step:11875 (TRAIN, VALID): total: 2044.74, 2047.03      recon: 2030.22, 2032.78,     kl: 12.02, 11.75,     l2: 2.49895,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:475, step:11900 (TRAIN, VALID): total: 2044.36, 2048.38      recon: 2029.89, 2034.08,     kl: 11.98, 11.80,     l2: 2.49760,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:476, step:11925 (TRAIN, VALID): total: 2044.55, 2047.98      recon: 2029.94, 2033.68,     kl: 12.11, 11.81,     l2: 2.49804,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:477, step:11950 (TRAIN, VALID): total: 2044.47, 2047.70      recon: 2029.99, 2033.42,     kl: 11.99, 11.78,     l2: 2.49937,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:478, step:11975 (TRAIN, VALID): total: 2044.65, 2047.76      recon: 2030.15, 2033.43,     kl: 12.00, 11.82,     l2: 2.49925,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:479, step:12000 (TRAIN, VALID): total: 2044.70, 2047.86      recon: 2030.18, 2033.56,     kl: 12.03, 11.80,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:480, step:12025 (TRAIN, VALID): total: 2044.83, 2047.01      recon: 2030.41, 2032.76,     kl: 11.92, 11.75,     l2: 2.49830,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001661.\n",
      "Epoch:481, step:12050 (TRAIN, VALID): total: 2044.68, 2049.44      recon: 2030.24, 2035.31,     kl: 11.95, 11.63,     l2: 2.49796,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:482, step:12075 (TRAIN, VALID): total: 2044.67, 2047.64      recon: 2030.21, 2033.55,     kl: 11.96, 11.59,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:483, step:12100 (TRAIN, VALID): total: 2044.45, 2046.24      recon: 2030.02, 2031.83,     kl: 11.93, 11.91,     l2: 2.49920,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:484, step:12125 (TRAIN, VALID): total: 2044.35, 2048.06      recon: 2029.87, 2033.78,     kl: 11.98, 11.78,     l2: 2.50075,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:485, step:12150 (TRAIN, VALID): total: 2044.58, 2047.54      recon: 2030.08, 2033.28,     kl: 12.00, 11.75,     l2: 2.50103,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:486, step:12175 (TRAIN, VALID): total: 2044.46, 2048.01      recon: 2029.88, 2033.73,     kl: 12.08, 11.79,     l2: 2.50039,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:487, step:12200 (TRAIN, VALID): total: 2044.46, 2046.85      recon: 2030.01, 2032.68,     kl: 11.95, 11.67,     l2: 2.50001,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:488, step:12225 (TRAIN, VALID): total: 2044.41, 2046.80      recon: 2029.94, 2032.55,     kl: 11.97, 11.75,     l2: 2.50070,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:489, step:12250 (TRAIN, VALID): total: 2044.25, 2047.20      recon: 2029.85, 2033.03,     kl: 11.90, 11.67,     l2: 2.49993,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:490, step:12275 (TRAIN, VALID): total: 2044.27, 2047.41      recon: 2029.88, 2033.19,     kl: 11.89, 11.72,     l2: 2.50083,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:491, step:12300 (TRAIN, VALID): total: 2044.47, 2047.23      recon: 2030.04, 2032.97,     kl: 11.93, 11.77,     l2: 2.49882,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:492, step:12325 (TRAIN, VALID): total: 2044.44, 2048.07      recon: 2030.01, 2033.86,     kl: 11.93, 11.71,     l2: 2.49926,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:493, step:12350 (TRAIN, VALID): total: 2044.37, 2047.42      recon: 2029.90, 2033.19,     kl: 11.98, 11.72,     l2: 2.49963,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:494, step:12375 (TRAIN, VALID): total: 2044.41, 2046.03      recon: 2030.06, 2031.72,     kl: 11.85, 11.82,     l2: 2.50043,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:495, step:12400 (TRAIN, VALID): total: 2044.58, 2046.69      recon: 2030.12, 2032.58,     kl: 11.95, 11.61,     l2: 2.50017,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001578.\n",
      "Epoch:496, step:12425 (TRAIN, VALID): total: 2044.30, 2046.72      recon: 2029.92, 2032.52,     kl: 11.88, 11.70,     l2: 2.49946,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:497, step:12450 (TRAIN, VALID): total: 2044.44, 2047.40      recon: 2029.97, 2033.16,     kl: 11.97, 11.74,     l2: 2.49995,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:498, step:12475 (TRAIN, VALID): total: 2044.38, 2047.91      recon: 2029.89, 2033.52,     kl: 11.98, 11.89,     l2: 2.50129,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:499, step:12500 (TRAIN, VALID): total: 2044.21, 2047.40      recon: 2029.73, 2033.18,     kl: 11.97, 11.72,     l2: 2.50219,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:500, step:12525 (TRAIN, VALID): total: 2044.43, 2049.79      recon: 2029.92, 2035.37,     kl: 12.01, 11.91,     l2: 2.50204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:501, step:12550 (TRAIN, VALID): total: 2044.94, 2047.89      recon: 2030.32, 2033.53,     kl: 12.11, 11.86,     l2: 2.50186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:502, step:12575 (TRAIN, VALID): total: 2044.31, 2049.50      recon: 2029.89, 2035.35,     kl: 11.92, 11.65,     l2: 2.50179,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:503, step:12600 (TRAIN, VALID): total: 2044.39, 2046.49      recon: 2029.92, 2032.35,     kl: 11.96, 11.64,     l2: 2.50146,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:504, step:12625 (TRAIN, VALID): total: 2044.39, 2047.69      recon: 2029.95, 2033.36,     kl: 11.93, 11.83,     l2: 2.50077,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:505, step:12650 (TRAIN, VALID): total: 2044.14, 2047.54      recon: 2029.74, 2033.26,     kl: 11.90, 11.78,     l2: 2.50133,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:506, step:12675 (TRAIN, VALID): total: 2044.37, 2048.13      recon: 2029.98, 2033.97,     kl: 11.88, 11.66,     l2: 2.50093,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:507, step:12700 (TRAIN, VALID): total: 2044.44, 2047.77      recon: 2029.94, 2033.40,     kl: 12.00, 11.87,     l2: 2.50255,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:508, step:12725 (TRAIN, VALID): total: 2044.52, 2049.28      recon: 2030.05, 2035.06,     kl: 11.97, 11.72,     l2: 2.50158,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001499.\n",
      "Epoch:509, step:12750 (TRAIN, VALID): total: 2044.74, 2048.22      recon: 2030.17, 2033.71,     kl: 12.06, 12.00,     l2: 2.50217,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:510, step:12775 (TRAIN, VALID): total: 2044.38, 2047.14      recon: 2029.84, 2032.94,     kl: 12.04, 11.70,     l2: 2.50156,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:511, step:12800 (TRAIN, VALID): total: 2044.19, 2048.97      recon: 2029.81, 2034.55,     kl: 11.88, 11.92,     l2: 2.50213,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:512, step:12825 (TRAIN, VALID): total: 2044.99, 2049.41      recon: 2030.35, 2035.05,     kl: 12.14, 11.86,     l2: 2.50214,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:513, step:12850 (TRAIN, VALID): total: 2044.49, 2048.60      recon: 2029.94, 2034.36,     kl: 12.05, 11.74,     l2: 2.50320,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:514, step:12875 (TRAIN, VALID): total: 2044.30, 2046.68      recon: 2029.80, 2032.45,     kl: 12.00, 11.73,     l2: 2.50328,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:515, step:12900 (TRAIN, VALID): total: 2044.24, 2047.44      recon: 2029.80, 2033.12,     kl: 11.93, 11.82,     l2: 2.50322,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:516, step:12925 (TRAIN, VALID): total: 2044.24, 2049.06      recon: 2029.79, 2034.78,     kl: 11.95, 11.78,     l2: 2.50325,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:517, step:12950 (TRAIN, VALID): total: 2044.04, 2048.16      recon: 2029.59, 2034.03,     kl: 11.95, 11.63,     l2: 2.50270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:518, step:12975 (TRAIN, VALID): total: 2044.47, 2047.41      recon: 2030.04, 2033.11,     kl: 11.93, 11.80,     l2: 2.50311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:519, step:13000 (TRAIN, VALID): total: 2044.30, 2047.33      recon: 2029.76, 2033.01,     kl: 12.04, 11.81,     l2: 2.50241,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:520, step:13025 (TRAIN, VALID): total: 2044.03, 2048.09      recon: 2029.62, 2033.94,     kl: 11.92, 11.65,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:521, step:13050 (TRAIN, VALID): total: 2043.99, 2047.76      recon: 2029.59, 2033.55,     kl: 11.90, 11.70,     l2: 2.50294,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:522, step:13075 (TRAIN, VALID): total: 2044.16, 2048.11      recon: 2029.78, 2033.81,     kl: 11.88, 11.79,     l2: 2.50335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:523, step:13100 (TRAIN, VALID): total: 2044.20, 2047.19      recon: 2029.68, 2032.83,     kl: 12.01, 11.86,     l2: 2.50437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:524, step:13125 (TRAIN, VALID): total: 2044.38, 2048.56      recon: 2029.84, 2034.21,     kl: 12.04, 11.85,     l2: 2.50401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:525, step:13150 (TRAIN, VALID): total: 2044.14, 2048.01      recon: 2029.62, 2033.82,     kl: 12.02, 11.69,     l2: 2.50407,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:526, step:13175 (TRAIN, VALID): total: 2044.07, 2046.75      recon: 2029.62, 2032.42,     kl: 11.94, 11.82,     l2: 2.50356,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:527, step:13200 (TRAIN, VALID): total: 2044.03, 2048.07      recon: 2029.50, 2033.58,     kl: 12.03, 11.99,     l2: 2.50385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:528, step:13225 (TRAIN, VALID): total: 2043.89, 2046.24      recon: 2029.40, 2032.07,     kl: 11.99, 11.67,     l2: 2.50330,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:529, step:13250 (TRAIN, VALID): total: 2044.16, 2048.11      recon: 2029.67, 2033.87,     kl: 11.98, 11.74,     l2: 2.50451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:530, step:13275 (TRAIN, VALID): total: 2044.32, 2047.40      recon: 2029.87, 2033.16,     kl: 11.95, 11.74,     l2: 2.50474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:531, step:13300 (TRAIN, VALID): total: 2044.14, 2047.41      recon: 2029.63, 2033.19,     kl: 12.01, 11.72,     l2: 2.50401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:532, step:13325 (TRAIN, VALID): total: 2044.11, 2047.99      recon: 2029.61, 2033.73,     kl: 12.00, 11.75,     l2: 2.50418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:533, step:13350 (TRAIN, VALID): total: 2044.13, 2047.33      recon: 2029.67, 2032.79,     kl: 11.96, 12.04,     l2: 2.50447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:534, step:13375 (TRAIN, VALID): total: 2044.53, 2047.84      recon: 2029.80, 2033.73,     kl: 12.22, 11.60,     l2: 2.50504,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001424.\n",
      "Epoch:535, step:13400 (TRAIN, VALID): total: 2044.06, 2048.08      recon: 2029.63, 2033.89,     kl: 11.92, 11.68,     l2: 2.50566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:536, step:13425 (TRAIN, VALID): total: 2044.13, 2047.81      recon: 2029.73, 2033.57,     kl: 11.89, 11.73,     l2: 2.50438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:537, step:13450 (TRAIN, VALID): total: 2043.99, 2046.92      recon: 2029.55, 2032.72,     kl: 11.93, 11.69,     l2: 2.50452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:538, step:13475 (TRAIN, VALID): total: 2044.22, 2046.53      recon: 2029.80, 2032.18,     kl: 11.92, 11.84,     l2: 2.50459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:539, step:13500 (TRAIN, VALID): total: 2044.48, 2046.85      recon: 2029.95, 2032.57,     kl: 12.02, 11.78,     l2: 2.50257,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:540, step:13525 (TRAIN, VALID): total: 2044.11, 2046.75      recon: 2029.56, 2032.29,     kl: 12.04, 11.95,     l2: 2.50321,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:541, step:13550 (TRAIN, VALID): total: 2043.89, 2047.33      recon: 2029.41, 2033.11,     kl: 11.97, 11.71,     l2: 2.50523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:542, step:13575 (TRAIN, VALID): total: 2043.94, 2046.83      recon: 2029.52, 2032.66,     kl: 11.92, 11.66,     l2: 2.50336,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:543, step:13600 (TRAIN, VALID): total: 2044.53, 2046.82      recon: 2029.98, 2032.55,     kl: 12.05, 11.77,     l2: 2.50318,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001353.\n",
      "Epoch:544, step:13625 (TRAIN, VALID): total: 2043.92, 2047.08      recon: 2029.51, 2032.97,     kl: 11.90, 11.61,     l2: 2.50350,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:545, step:13650 (TRAIN, VALID): total: 2043.91, 2047.47      recon: 2029.43, 2033.24,     kl: 11.98, 11.72,     l2: 2.50377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:546, step:13675 (TRAIN, VALID): total: 2043.90, 2047.99      recon: 2029.44, 2033.75,     kl: 11.95, 11.74,     l2: 2.50345,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:547, step:13700 (TRAIN, VALID): total: 2043.77, 2047.67      recon: 2029.36, 2033.53,     kl: 11.91, 11.64,     l2: 2.50377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:548, step:13725 (TRAIN, VALID): total: 2044.09, 2047.26      recon: 2029.66, 2033.00,     kl: 11.93, 11.76,     l2: 2.50406,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:549, step:13750 (TRAIN, VALID): total: 2044.67, 2047.77      recon: 2030.16, 2033.51,     kl: 12.01, 11.75,     l2: 2.50234,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:550, step:13775 (TRAIN, VALID): total: 2044.05, 2048.00      recon: 2029.63, 2033.59,     kl: 11.91, 11.91,     l2: 2.50351,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:551, step:13800 (TRAIN, VALID): total: 2044.03, 2047.69      recon: 2029.51, 2033.47,     kl: 12.02, 11.72,     l2: 2.50418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:552, step:13825 (TRAIN, VALID): total: 2043.86, 2048.12      recon: 2029.45, 2033.86,     kl: 11.91, 11.76,     l2: 2.50414,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:553, step:13850 (TRAIN, VALID): total: 2044.44, 2046.56      recon: 2029.90, 2032.18,     kl: 12.03, 11.87,     l2: 2.50350,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:554, step:13875 (TRAIN, VALID): total: 2044.16, 2047.57      recon: 2029.58, 2033.20,     kl: 12.08, 11.86,     l2: 2.50459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:555, step:13900 (TRAIN, VALID): total: 2044.31, 2046.87      recon: 2029.73, 2032.51,     kl: 12.07, 11.86,     l2: 2.50376,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:556, step:13925 (TRAIN, VALID): total: 2044.06, 2048.04      recon: 2029.59, 2033.95,     kl: 11.97, 11.59,     l2: 2.50391,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:557, step:13950 (TRAIN, VALID): total: 2044.27, 2047.77      recon: 2029.73, 2033.34,     kl: 12.04, 11.92,     l2: 2.50534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:558, step:13975 (TRAIN, VALID): total: 2043.93, 2047.37      recon: 2029.45, 2033.08,     kl: 11.98, 11.79,     l2: 2.50475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:559, step:14000 (TRAIN, VALID): total: 2044.02, 2047.64      recon: 2029.54, 2033.43,     kl: 11.97, 11.70,     l2: 2.50397,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:560, step:14025 (TRAIN, VALID): total: 2043.79, 2047.76      recon: 2029.36, 2033.58,     kl: 11.93, 11.68,     l2: 2.50352,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:561, step:14050 (TRAIN, VALID): total: 2044.02, 2048.11      recon: 2029.52, 2033.78,     kl: 11.99, 11.82,     l2: 2.50461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:562, step:14075 (TRAIN, VALID): total: 2043.88, 2049.18      recon: 2029.45, 2034.88,     kl: 11.93, 11.79,     l2: 2.50536,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:563, step:14100 (TRAIN, VALID): total: 2043.88, 2047.91      recon: 2029.36, 2033.61,     kl: 12.02, 11.80,     l2: 2.50537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:564, step:14125 (TRAIN, VALID): total: 2043.91, 2046.36      recon: 2029.43, 2032.07,     kl: 11.98, 11.78,     l2: 2.50595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:565, step:14150 (TRAIN, VALID): total: 2044.15, 2046.33      recon: 2029.64, 2032.06,     kl: 12.00, 11.77,     l2: 2.50493,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001285.\n",
      "Epoch:566, step:14175 (TRAIN, VALID): total: 2044.42, 2046.50      recon: 2029.78, 2032.08,     kl: 12.14, 11.92,     l2: 2.50584,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:567, step:14200 (TRAIN, VALID): total: 2044.43, 2047.18      recon: 2029.89, 2032.77,     kl: 12.03, 11.91,     l2: 2.50577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:568, step:14225 (TRAIN, VALID): total: 2043.98, 2047.42      recon: 2029.41, 2033.15,     kl: 12.07, 11.76,     l2: 2.50691,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:569, step:14250 (TRAIN, VALID): total: 2043.91, 2047.28      recon: 2029.36, 2032.92,     kl: 12.04, 11.86,     l2: 2.50643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:570, step:14275 (TRAIN, VALID): total: 2043.91, 2047.60      recon: 2029.38, 2033.42,     kl: 12.02, 11.68,     l2: 2.50788,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:571, step:14300 (TRAIN, VALID): total: 2043.95, 2047.03      recon: 2029.51, 2032.85,     kl: 11.94, 11.67,     l2: 2.50818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:572, step:14325 (TRAIN, VALID): total: 2044.11, 2048.29      recon: 2029.54, 2033.85,     kl: 12.06, 11.93,     l2: 2.50756,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:573, step:14350 (TRAIN, VALID): total: 2043.89, 2047.20      recon: 2029.35, 2032.97,     kl: 12.04, 11.72,     l2: 2.50705,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:574, step:14375 (TRAIN, VALID): total: 2043.87, 2047.51      recon: 2029.44, 2033.21,     kl: 11.92, 11.79,     l2: 2.50714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:575, step:14400 (TRAIN, VALID): total: 2043.85, 2046.99      recon: 2029.37, 2032.74,     kl: 11.97, 11.74,     l2: 2.50640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:576, step:14425 (TRAIN, VALID): total: 2043.95, 2047.14      recon: 2029.42, 2032.78,     kl: 12.02, 11.85,     l2: 2.50701,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:577, step:14450 (TRAIN, VALID): total: 2043.87, 2047.94      recon: 2029.34, 2033.47,     kl: 12.02, 11.97,     l2: 2.50835,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:578, step:14475 (TRAIN, VALID): total: 2044.15, 2047.41      recon: 2029.57, 2033.06,     kl: 12.07, 11.85,     l2: 2.50888,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001221.\n",
      "Epoch:579, step:14500 (TRAIN, VALID): total: 2044.18, 2045.64      recon: 2029.59, 2031.37,     kl: 12.09, 11.76,     l2: 2.50957,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:580, step:14525 (TRAIN, VALID): total: 2043.96, 2047.36      recon: 2029.40, 2032.85,     kl: 12.05, 12.00,     l2: 2.50876,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:581, step:14550 (TRAIN, VALID): total: 2044.16, 2047.00      recon: 2029.52, 2032.80,     kl: 12.14, 11.69,     l2: 2.50900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:582, step:14575 (TRAIN, VALID): total: 2043.76, 2049.58      recon: 2029.29, 2035.35,     kl: 11.96, 11.72,     l2: 2.50948,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:583, step:14600 (TRAIN, VALID): total: 2043.86, 2046.77      recon: 2029.44, 2032.49,     kl: 11.91, 11.77,     l2: 2.50885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:584, step:14625 (TRAIN, VALID): total: 2043.80, 2047.08      recon: 2029.23, 2032.64,     kl: 12.06, 11.93,     l2: 2.50959,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:585, step:14650 (TRAIN, VALID): total: 2043.63, 2046.91      recon: 2029.13, 2032.63,     kl: 11.99, 11.77,     l2: 2.51052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:586, step:14675 (TRAIN, VALID): total: 2044.22, 2046.64      recon: 2029.61, 2032.37,     kl: 12.10, 11.76,     l2: 2.51028,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001160.\n",
      "Epoch:587, step:14700 (TRAIN, VALID): total: 2043.97, 2046.12      recon: 2029.43, 2031.77,     kl: 12.03, 11.84,     l2: 2.50987,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:588, step:14725 (TRAIN, VALID): total: 2043.58, 2047.13      recon: 2029.06, 2032.93,     kl: 12.01, 11.69,     l2: 2.50958,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:589, step:14750 (TRAIN, VALID): total: 2043.65, 2048.59      recon: 2029.25, 2034.35,     kl: 11.89, 11.73,     l2: 2.51102,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:590, step:14775 (TRAIN, VALID): total: 2043.77, 2047.74      recon: 2029.28, 2033.56,     kl: 11.98, 11.67,     l2: 2.51059,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:591, step:14800 (TRAIN, VALID): total: 2043.69, 2047.23      recon: 2029.16, 2032.87,     kl: 12.01, 11.85,     l2: 2.51203,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:592, step:14825 (TRAIN, VALID): total: 2043.58, 2047.59      recon: 2029.10, 2033.39,     kl: 11.97, 11.69,     l2: 2.51223,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:593, step:14850 (TRAIN, VALID): total: 2044.23, 2047.39      recon: 2029.68, 2033.09,     kl: 12.04, 11.79,     l2: 2.51175,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001102.\n",
      "Epoch:594, step:14875 (TRAIN, VALID): total: 2043.64, 2046.06      recon: 2029.15, 2031.75,     kl: 11.97, 11.79,     l2: 2.51202,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:595, step:14900 (TRAIN, VALID): total: 2043.69, 2046.84      recon: 2029.20, 2032.58,     kl: 11.98, 11.75,     l2: 2.51281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:596, step:14925 (TRAIN, VALID): total: 2043.79, 2047.21      recon: 2029.23, 2032.92,     kl: 12.05, 11.78,     l2: 2.51218,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:597, step:14950 (TRAIN, VALID): total: 2043.69, 2046.60      recon: 2029.24, 2032.33,     kl: 11.94, 11.76,     l2: 2.51198,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:598, step:14975 (TRAIN, VALID): total: 2043.54, 2046.60      recon: 2029.05, 2032.31,     kl: 11.97, 11.77,     l2: 2.51224,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:599, step:15000 (TRAIN, VALID): total: 2043.52, 2047.47      recon: 2029.01, 2033.24,     kl: 12.00, 11.73,     l2: 2.51201,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:600, step:15025 (TRAIN, VALID): total: 2043.49, 2047.40      recon: 2029.08, 2033.13,     kl: 11.90, 11.76,     l2: 2.51185,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:601, step:15050 (TRAIN, VALID): total: 2043.68, 2048.21      recon: 2029.17, 2033.84,     kl: 12.00, 11.86,     l2: 2.51126,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:602, step:15075 (TRAIN, VALID): total: 2043.75, 2046.40      recon: 2029.16, 2032.20,     kl: 12.08, 11.69,     l2: 2.51176,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:603, step:15100 (TRAIN, VALID): total: 2043.64, 2048.46      recon: 2029.16, 2034.15,     kl: 11.97, 11.80,     l2: 2.51100,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:604, step:15125 (TRAIN, VALID): total: 2043.71, 2047.60      recon: 2029.15, 2033.26,     kl: 12.05, 11.82,     l2: 2.51218,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:605, step:15150 (TRAIN, VALID): total: 2043.75, 2046.87      recon: 2029.29, 2032.46,     kl: 11.95, 11.90,     l2: 2.51217,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:606, step:15175 (TRAIN, VALID): total: 2043.75, 2046.38      recon: 2029.20, 2032.14,     kl: 12.03, 11.73,     l2: 2.51323,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:607, step:15200 (TRAIN, VALID): total: 2043.62, 2047.03      recon: 2029.09, 2032.68,     kl: 12.02, 11.83,     l2: 2.51317,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:608, step:15225 (TRAIN, VALID): total: 2043.50, 2046.61      recon: 2029.04, 2032.44,     kl: 11.94, 11.65,     l2: 2.51385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:609, step:15250 (TRAIN, VALID): total: 2043.41, 2046.53      recon: 2028.90, 2032.30,     kl: 11.99, 11.72,     l2: 2.51400,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:610, step:15275 (TRAIN, VALID): total: 2043.83, 2047.61      recon: 2029.35, 2033.26,     kl: 11.97, 11.83,     l2: 2.51389,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.001047.\n",
      "Epoch:611, step:15300 (TRAIN, VALID): total: 2043.58, 2046.93      recon: 2029.04, 2032.72,     kl: 12.02, 11.69,     l2: 2.51401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:612, step:15325 (TRAIN, VALID): total: 2043.71, 2045.97      recon: 2029.28, 2031.76,     kl: 11.92, 11.69,     l2: 2.51333,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:613, step:15350 (TRAIN, VALID): total: 2043.30, 2046.98      recon: 2028.89, 2032.80,     kl: 11.90, 11.66,     l2: 2.51369,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:614, step:15375 (TRAIN, VALID): total: 2044.35, 2046.16      recon: 2029.74, 2031.89,     kl: 12.10, 11.76,     l2: 2.51303,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:615, step:15400 (TRAIN, VALID): total: 2043.60, 2048.13      recon: 2029.13, 2033.88,     kl: 11.96, 11.73,     l2: 2.51327,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:616, step:15425 (TRAIN, VALID): total: 2043.53, 2048.46      recon: 2029.02, 2034.20,     kl: 11.99, 11.75,     l2: 2.51361,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:617, step:15450 (TRAIN, VALID): total: 2043.73, 2047.83      recon: 2029.26, 2033.56,     kl: 11.96, 11.76,     l2: 2.51351,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:618, step:15475 (TRAIN, VALID): total: 2043.46, 2046.34      recon: 2028.98, 2032.07,     kl: 11.97, 11.75,     l2: 2.51424,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:619, step:15500 (TRAIN, VALID): total: 2043.49, 2047.18      recon: 2029.01, 2032.88,     kl: 11.97, 11.78,     l2: 2.51500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:620, step:15525 (TRAIN, VALID): total: 2043.38, 2046.61      recon: 2028.90, 2032.41,     kl: 11.97, 11.69,     l2: 2.51392,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:621, step:15550 (TRAIN, VALID): total: 2043.40, 2046.59      recon: 2029.00, 2032.46,     kl: 11.89, 11.61,     l2: 2.51456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:622, step:15575 (TRAIN, VALID): total: 2043.83, 2046.43      recon: 2029.31, 2032.17,     kl: 12.00, 11.75,     l2: 2.51519,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000994.\n",
      "Epoch:623, step:15600 (TRAIN, VALID): total: 2043.34, 2047.59      recon: 2028.82, 2033.30,     kl: 12.00, 11.78,     l2: 2.51527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:624, step:15625 (TRAIN, VALID): total: 2043.72, 2047.62      recon: 2029.16, 2033.14,     kl: 12.04, 11.96,     l2: 2.51387,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:625, step:15650 (TRAIN, VALID): total: 2043.47, 2046.75      recon: 2028.86, 2032.50,     kl: 12.09, 11.73,     l2: 2.51527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:626, step:15675 (TRAIN, VALID): total: 2043.52, 2048.71      recon: 2029.05, 2034.31,     kl: 11.96, 11.89,     l2: 2.51432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:627, step:15700 (TRAIN, VALID): total: 2043.79, 2046.26      recon: 2029.22, 2032.02,     kl: 12.05, 11.73,     l2: 2.51443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:628, step:15725 (TRAIN, VALID): total: 2043.33, 2047.23      recon: 2028.86, 2032.92,     kl: 11.96, 11.79,     l2: 2.51471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:629, step:15750 (TRAIN, VALID): total: 2043.51, 2045.70      recon: 2029.02, 2031.47,     kl: 11.98, 11.71,     l2: 2.51510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:630, step:15775 (TRAIN, VALID): total: 2043.37, 2046.78      recon: 2028.92, 2032.58,     kl: 11.94, 11.69,     l2: 2.51511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:631, step:15800 (TRAIN, VALID): total: 2043.40, 2048.17      recon: 2028.87, 2033.79,     kl: 12.02, 11.87,     l2: 2.51624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:632, step:15825 (TRAIN, VALID): total: 2043.62, 2047.43      recon: 2029.09, 2033.13,     kl: 12.01, 11.79,     l2: 2.51554,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:633, step:15850 (TRAIN, VALID): total: 2043.40, 2047.77      recon: 2028.88, 2033.55,     kl: 12.01, 11.70,     l2: 2.51626,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:634, step:15875 (TRAIN, VALID): total: 2043.52, 2048.85      recon: 2028.94, 2034.53,     kl: 12.06, 11.80,     l2: 2.51598,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:635, step:15900 (TRAIN, VALID): total: 2043.48, 2046.16      recon: 2029.01, 2031.89,     kl: 11.96, 11.75,     l2: 2.51530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:636, step:15925 (TRAIN, VALID): total: 2043.35, 2047.31      recon: 2028.81, 2033.03,     kl: 12.02, 11.76,     l2: 2.51536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:637, step:15950 (TRAIN, VALID): total: 2043.38, 2047.62      recon: 2028.93, 2033.34,     kl: 11.93, 11.77,     l2: 2.51498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:638, step:15975 (TRAIN, VALID): total: 2043.63, 2048.00      recon: 2029.08, 2033.65,     kl: 12.03, 11.83,     l2: 2.51575,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000945.\n",
      "Epoch:639, step:16000 (TRAIN, VALID): total: 2043.76, 2046.48      recon: 2029.19, 2032.21,     kl: 12.05, 11.76,     l2: 2.51574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:640, step:16025 (TRAIN, VALID): total: 2043.43, 2047.56      recon: 2028.89, 2033.27,     kl: 12.02, 11.77,     l2: 2.51504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:641, step:16050 (TRAIN, VALID): total: 2043.30, 2046.12      recon: 2028.83, 2031.97,     kl: 11.95, 11.64,     l2: 2.51605,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:642, step:16075 (TRAIN, VALID): total: 2043.74, 2048.11      recon: 2029.25, 2033.78,     kl: 11.97, 11.82,     l2: 2.51494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:643, step:16100 (TRAIN, VALID): total: 2043.49, 2046.87      recon: 2028.96, 2032.65,     kl: 12.01, 11.70,     l2: 2.51488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:644, step:16125 (TRAIN, VALID): total: 2043.40, 2046.47      recon: 2028.93, 2032.18,     kl: 11.96, 11.78,     l2: 2.51458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:645, step:16150 (TRAIN, VALID): total: 2043.53, 2047.06      recon: 2028.99, 2032.70,     kl: 12.02, 11.84,     l2: 2.51569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:646, step:16175 (TRAIN, VALID): total: 2043.75, 2047.39      recon: 2029.17, 2033.07,     kl: 12.07, 11.81,     l2: 2.51623,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000897.\n",
      "Epoch:647, step:16200 (TRAIN, VALID): total: 2043.45, 2047.12      recon: 2028.82, 2032.72,     kl: 12.11, 11.88,     l2: 2.51601,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:648, step:16225 (TRAIN, VALID): total: 2043.40, 2046.60      recon: 2028.84, 2032.32,     kl: 12.05, 11.76,     l2: 2.51577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:649, step:16250 (TRAIN, VALID): total: 2043.26, 2046.94      recon: 2028.81, 2032.76,     kl: 11.93, 11.66,     l2: 2.51653,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:650, step:16275 (TRAIN, VALID): total: 2043.81, 2048.09      recon: 2029.21, 2033.72,     kl: 12.09, 11.86,     l2: 2.51690,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:651, step:16300 (TRAIN, VALID): total: 2043.41, 2046.71      recon: 2028.93, 2032.45,     kl: 11.96, 11.74,     l2: 2.51619,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:652, step:16325 (TRAIN, VALID): total: 2043.38, 2047.23      recon: 2028.88, 2032.95,     kl: 11.98, 11.77,     l2: 2.51625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:653, step:16350 (TRAIN, VALID): total: 2043.23, 2047.89      recon: 2028.75, 2033.67,     kl: 11.96, 11.70,     l2: 2.51704,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:654, step:16375 (TRAIN, VALID): total: 2043.35, 2047.63      recon: 2028.86, 2033.37,     kl: 11.96, 11.74,     l2: 2.51656,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:655, step:16400 (TRAIN, VALID): total: 2043.78, 2047.03      recon: 2029.17, 2032.65,     kl: 12.10, 11.86,     l2: 2.51692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:656, step:16425 (TRAIN, VALID): total: 2043.37, 2046.87      recon: 2028.81, 2032.67,     kl: 12.04, 11.68,     l2: 2.51633,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:657, step:16450 (TRAIN, VALID): total: 2043.30, 2046.54      recon: 2028.86, 2032.25,     kl: 11.92, 11.77,     l2: 2.51604,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:658, step:16475 (TRAIN, VALID): total: 2043.51, 2047.05      recon: 2028.75, 2032.59,     kl: 12.25, 11.94,     l2: 2.51550,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:659, step:16500 (TRAIN, VALID): total: 2043.40, 2046.69      recon: 2028.82, 2032.39,     kl: 12.07, 11.78,     l2: 2.51614,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:660, step:16525 (TRAIN, VALID): total: 2043.41, 2048.01      recon: 2028.84, 2033.63,     kl: 12.05, 11.86,     l2: 2.51558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:661, step:16550 (TRAIN, VALID): total: 2043.36, 2046.23      recon: 2028.84, 2031.91,     kl: 12.01, 11.80,     l2: 2.51567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:662, step:16575 (TRAIN, VALID): total: 2043.43, 2046.11      recon: 2028.86, 2031.68,     kl: 12.06, 11.91,     l2: 2.51546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:663, step:16600 (TRAIN, VALID): total: 2043.35, 2047.18      recon: 2028.78, 2032.87,     kl: 12.05, 11.79,     l2: 2.51548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:664, step:16625 (TRAIN, VALID): total: 2043.32, 2047.28      recon: 2028.81, 2032.98,     kl: 11.99, 11.78,     l2: 2.51600,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:665, step:16650 (TRAIN, VALID): total: 2043.43, 2046.58      recon: 2028.96, 2032.21,     kl: 11.95, 11.85,     l2: 2.51681,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:666, step:16675 (TRAIN, VALID): total: 2043.53, 2046.71      recon: 2028.91, 2032.37,     kl: 12.10, 11.82,     l2: 2.51565,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000853.\n",
      "Epoch:667, step:16700 (TRAIN, VALID): total: 2043.20, 2047.42      recon: 2028.69, 2033.17,     kl: 11.99, 11.73,     l2: 2.51719,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:668, step:16725 (TRAIN, VALID): total: 2043.28, 2046.30      recon: 2028.81, 2032.04,     kl: 11.95, 11.75,     l2: 2.51686,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:669, step:16750 (TRAIN, VALID): total: 2043.42, 2046.49      recon: 2028.95, 2032.20,     kl: 11.96, 11.78,     l2: 2.51643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:670, step:16775 (TRAIN, VALID): total: 2043.10, 2047.66      recon: 2028.62, 2033.48,     kl: 11.97, 11.67,     l2: 2.51743,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:671, step:16800 (TRAIN, VALID): total: 2043.31, 2047.20      recon: 2028.83, 2032.87,     kl: 11.97, 11.81,     l2: 2.51705,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:672, step:16825 (TRAIN, VALID): total: 2043.30, 2046.79      recon: 2028.76, 2032.45,     kl: 12.03, 11.83,     l2: 2.51716,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:673, step:16850 (TRAIN, VALID): total: 2043.45, 2048.46      recon: 2028.94, 2034.17,     kl: 11.99, 11.77,     l2: 2.51726,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000810.\n",
      "Epoch:674, step:16875 (TRAIN, VALID): total: 2043.15, 2047.79      recon: 2028.65, 2033.46,     kl: 11.98, 11.81,     l2: 2.51776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:675, step:16900 (TRAIN, VALID): total: 2043.13, 2047.30      recon: 2028.57, 2033.06,     kl: 12.05, 11.73,     l2: 2.51859,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:676, step:16925 (TRAIN, VALID): total: 2043.28, 2047.31      recon: 2028.84, 2032.99,     kl: 11.91, 11.80,     l2: 2.51894,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:677, step:16950 (TRAIN, VALID): total: 2043.53, 2047.24      recon: 2028.88, 2032.92,     kl: 12.13, 11.81,     l2: 2.51961,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:678, step:16975 (TRAIN, VALID): total: 2043.30, 2047.96      recon: 2028.76, 2033.53,     kl: 12.02, 11.91,     l2: 2.51896,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:679, step:17000 (TRAIN, VALID): total: 2043.18, 2046.49      recon: 2028.61, 2032.06,     kl: 12.06, 11.90,     l2: 2.51902,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:680, step:17025 (TRAIN, VALID): total: 2043.20, 2047.61      recon: 2028.55, 2033.22,     kl: 12.13, 11.87,     l2: 2.51904,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:681, step:17050 (TRAIN, VALID): total: 2043.31, 2046.85      recon: 2028.72, 2032.59,     kl: 12.07, 11.73,     l2: 2.51851,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:682, step:17075 (TRAIN, VALID): total: 2043.12, 2047.62      recon: 2028.62, 2033.33,     kl: 11.98, 11.77,     l2: 2.51908,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:683, step:17100 (TRAIN, VALID): total: 2043.14, 2046.09      recon: 2028.65, 2031.75,     kl: 11.97, 11.82,     l2: 2.51884,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:684, step:17125 (TRAIN, VALID): total: 2043.17, 2047.67      recon: 2028.60, 2033.26,     kl: 12.04, 11.90,     l2: 2.51889,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:685, step:17150 (TRAIN, VALID): total: 2043.06, 2048.45      recon: 2028.53, 2034.23,     kl: 12.00, 11.70,     l2: 2.51863,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:686, step:17175 (TRAIN, VALID): total: 2043.17, 2047.31      recon: 2028.70, 2033.02,     kl: 11.95, 11.77,     l2: 2.51908,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:687, step:17200 (TRAIN, VALID): total: 2043.50, 2047.41      recon: 2028.91, 2032.93,     kl: 12.06, 11.96,     l2: 2.51926,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000769.\n",
      "Epoch:688, step:17225 (TRAIN, VALID): total: 2043.19, 2046.32      recon: 2028.67, 2032.17,     kl: 12.00, 11.64,     l2: 2.51900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:689, step:17250 (TRAIN, VALID): total: 2043.28, 2046.59      recon: 2028.82, 2032.23,     kl: 11.94, 11.84,     l2: 2.51887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:690, step:17275 (TRAIN, VALID): total: 2043.12, 2047.06      recon: 2028.60, 2032.73,     kl: 12.01, 11.80,     l2: 2.51910,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:691, step:17300 (TRAIN, VALID): total: 2043.03, 2046.79      recon: 2028.54, 2032.52,     kl: 11.97, 11.75,     l2: 2.51885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:692, step:17325 (TRAIN, VALID): total: 2043.03, 2046.07      recon: 2028.51, 2031.76,     kl: 12.00, 11.79,     l2: 2.51829,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:693, step:17350 (TRAIN, VALID): total: 2043.03, 2045.59      recon: 2028.55, 2031.34,     kl: 11.97, 11.73,     l2: 2.51902,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:694, step:17375 (TRAIN, VALID): total: 2043.04, 2047.50      recon: 2028.58, 2033.22,     kl: 11.95, 11.76,     l2: 2.51917,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:695, step:17400 (TRAIN, VALID): total: 2043.06, 2048.21      recon: 2028.54, 2033.90,     kl: 12.00, 11.79,     l2: 2.51941,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:696, step:17425 (TRAIN, VALID): total: 2043.00, 2047.78      recon: 2028.47, 2033.58,     kl: 12.01, 11.68,     l2: 2.52015,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:697, step:17450 (TRAIN, VALID): total: 2043.04, 2047.63      recon: 2028.58, 2033.36,     kl: 11.94, 11.76,     l2: 2.51923,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:698, step:17475 (TRAIN, VALID): total: 2043.37, 2046.60      recon: 2028.86, 2032.22,     kl: 11.99, 11.85,     l2: 2.51920,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000731.\n",
      "Epoch:699, step:17500 (TRAIN, VALID): total: 2043.22, 2046.78      recon: 2028.68, 2032.57,     kl: 12.02, 11.69,     l2: 2.51973,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:700, step:17525 (TRAIN, VALID): total: 2042.95, 2047.71      recon: 2028.49, 2033.41,     kl: 11.94, 11.78,     l2: 2.52070,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:701, step:17550 (TRAIN, VALID): total: 2043.37, 2046.72      recon: 2028.83, 2032.41,     kl: 12.01, 11.79,     l2: 2.52104,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:702, step:17575 (TRAIN, VALID): total: 2043.03, 2047.26      recon: 2028.54, 2033.09,     kl: 11.98, 11.65,     l2: 2.52100,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:703, step:17600 (TRAIN, VALID): total: 2043.39, 2048.41      recon: 2028.86, 2034.01,     kl: 12.01, 11.88,     l2: 2.52028,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:704, step:17625 (TRAIN, VALID): total: 2042.95, 2047.48      recon: 2028.45, 2033.33,     kl: 11.98, 11.63,     l2: 2.52052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:705, step:17650 (TRAIN, VALID): total: 2043.07, 2048.20      recon: 2028.57, 2033.78,     kl: 11.97, 11.90,     l2: 2.52054,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:706, step:17675 (TRAIN, VALID): total: 2043.04, 2047.50      recon: 2028.50, 2033.19,     kl: 12.03, 11.79,     l2: 2.52119,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:707, step:17700 (TRAIN, VALID): total: 2043.01, 2046.86      recon: 2028.57, 2032.58,     kl: 11.92, 11.77,     l2: 2.52066,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:708, step:17725 (TRAIN, VALID): total: 2043.17, 2046.82      recon: 2028.57, 2032.44,     kl: 12.07, 11.86,     l2: 2.52010,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:709, step:17750 (TRAIN, VALID): total: 2042.92, 2046.80      recon: 2028.46, 2032.54,     kl: 11.95, 11.74,     l2: 2.51949,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:710, step:17775 (TRAIN, VALID): total: 2043.25, 2047.95      recon: 2028.61, 2033.42,     kl: 12.13, 12.00,     l2: 2.52021,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000694.\n",
      "Epoch:711, step:17800 (TRAIN, VALID): total: 2043.09, 2046.86      recon: 2028.53, 2032.64,     kl: 12.05, 11.70,     l2: 2.51965,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:712, step:17825 (TRAIN, VALID): total: 2043.25, 2047.23      recon: 2028.68, 2032.82,     kl: 12.05, 11.89,     l2: 2.51980,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:713, step:17850 (TRAIN, VALID): total: 2042.96, 2046.96      recon: 2028.41, 2032.71,     kl: 12.03, 11.73,     l2: 2.52032,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:714, step:17875 (TRAIN, VALID): total: 2042.86, 2046.63      recon: 2028.38, 2032.29,     kl: 11.96, 11.82,     l2: 2.52068,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:715, step:17900 (TRAIN, VALID): total: 2043.18, 2047.96      recon: 2028.63, 2033.63,     kl: 12.02, 11.80,     l2: 2.52125,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:716, step:17925 (TRAIN, VALID): total: 2043.16, 2046.94      recon: 2028.60, 2032.66,     kl: 12.04, 11.76,     l2: 2.51997,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:717, step:17950 (TRAIN, VALID): total: 2042.95, 2046.97      recon: 2028.48, 2032.76,     kl: 11.95, 11.69,     l2: 2.51961,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:718, step:17975 (TRAIN, VALID): total: 2043.07, 2047.25      recon: 2028.58, 2032.97,     kl: 11.96, 11.76,     l2: 2.51974,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:719, step:18000 (TRAIN, VALID): total: 2043.18, 2047.39      recon: 2028.59, 2032.95,     kl: 12.06, 11.93,     l2: 2.52033,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000660.\n",
      "Epoch:720, step:18025 (TRAIN, VALID): total: 2043.14, 2047.77      recon: 2028.56, 2033.41,     kl: 12.07, 11.84,     l2: 2.51989,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:721, step:18050 (TRAIN, VALID): total: 2042.94, 2046.32      recon: 2028.40, 2032.08,     kl: 12.02, 11.72,     l2: 2.52026,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:722, step:18075 (TRAIN, VALID): total: 2042.91, 2046.45      recon: 2028.51, 2032.21,     kl: 11.88, 11.71,     l2: 2.52024,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:723, step:18100 (TRAIN, VALID): total: 2042.94, 2047.72      recon: 2028.48, 2033.44,     kl: 11.94, 11.77,     l2: 2.52064,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:724, step:18125 (TRAIN, VALID): total: 2043.07, 2047.06      recon: 2028.49, 2032.78,     kl: 12.07, 11.76,     l2: 2.52011,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:725, step:18150 (TRAIN, VALID): total: 2042.96, 2047.74      recon: 2028.41, 2033.41,     kl: 12.03, 11.82,     l2: 2.52069,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:726, step:18175 (TRAIN, VALID): total: 2042.88, 2046.73      recon: 2028.38, 2032.52,     kl: 11.98, 11.69,     l2: 2.52065,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:727, step:18200 (TRAIN, VALID): total: 2042.85, 2047.90      recon: 2028.42, 2033.67,     kl: 11.91, 11.71,     l2: 2.52101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:728, step:18225 (TRAIN, VALID): total: 2042.85, 2046.64      recon: 2028.39, 2032.46,     kl: 11.93, 11.66,     l2: 2.52063,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:729, step:18250 (TRAIN, VALID): total: 2042.78, 2046.58      recon: 2028.38, 2032.40,     kl: 11.88, 11.65,     l2: 2.52102,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:730, step:18275 (TRAIN, VALID): total: 2042.89, 2046.50      recon: 2028.40, 2032.24,     kl: 11.97, 11.74,     l2: 2.52095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:731, step:18300 (TRAIN, VALID): total: 2043.01, 2045.82      recon: 2028.55, 2031.54,     kl: 11.94, 11.76,     l2: 2.52052,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000627.\n",
      "Epoch:732, step:18325 (TRAIN, VALID): total: 2043.24, 2046.97      recon: 2028.70, 2032.71,     kl: 12.02, 11.74,     l2: 2.52101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:733, step:18350 (TRAIN, VALID): total: 2043.01, 2046.06      recon: 2028.50, 2031.79,     kl: 11.99, 11.75,     l2: 2.52136,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:734, step:18375 (TRAIN, VALID): total: 2042.99, 2047.31      recon: 2028.51, 2033.05,     kl: 11.95, 11.74,     l2: 2.52168,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:735, step:18400 (TRAIN, VALID): total: 2042.85, 2047.61      recon: 2028.37, 2033.40,     kl: 11.96, 11.69,     l2: 2.52124,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:736, step:18425 (TRAIN, VALID): total: 2043.28, 2046.08      recon: 2028.61, 2031.53,     kl: 12.15, 12.03,     l2: 2.52248,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:737, step:18450 (TRAIN, VALID): total: 2042.86, 2045.73      recon: 2028.29, 2031.51,     kl: 12.05, 11.70,     l2: 2.52256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:738, step:18475 (TRAIN, VALID): total: 2042.85, 2048.33      recon: 2028.41, 2034.08,     kl: 11.92, 11.73,     l2: 2.52178,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:739, step:18500 (TRAIN, VALID): total: 2042.90, 2048.02      recon: 2028.35, 2033.49,     kl: 12.03, 12.01,     l2: 2.52193,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:740, step:18525 (TRAIN, VALID): total: 2043.07, 2047.34      recon: 2028.39, 2033.00,     kl: 12.15, 11.81,     l2: 2.52270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:741, step:18550 (TRAIN, VALID): total: 2042.92, 2046.67      recon: 2028.37, 2032.36,     kl: 12.03, 11.79,     l2: 2.52205,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:742, step:18575 (TRAIN, VALID): total: 2042.83, 2046.40      recon: 2028.35, 2032.11,     kl: 11.96, 11.77,     l2: 2.52222,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:743, step:18600 (TRAIN, VALID): total: 2042.96, 2045.40      recon: 2028.43, 2031.12,     kl: 12.01, 11.76,     l2: 2.52266,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:744, step:18625 (TRAIN, VALID): total: 2042.94, 2046.55      recon: 2028.38, 2032.17,     kl: 12.04, 11.86,     l2: 2.52232,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:745, step:18650 (TRAIN, VALID): total: 2042.84, 2046.32      recon: 2028.29, 2032.10,     kl: 12.03, 11.69,     l2: 2.52212,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:746, step:18675 (TRAIN, VALID): total: 2042.94, 2047.59      recon: 2028.45, 2033.23,     kl: 11.97, 11.84,     l2: 2.52190,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:747, step:18700 (TRAIN, VALID): total: 2042.83, 2046.79      recon: 2028.35, 2032.64,     kl: 11.97, 11.63,     l2: 2.52151,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:748, step:18725 (TRAIN, VALID): total: 2042.86, 2046.80      recon: 2028.42, 2032.59,     kl: 11.93, 11.69,     l2: 2.52252,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:749, step:18750 (TRAIN, VALID): total: 2042.87, 2047.48      recon: 2028.41, 2033.21,     kl: 11.94, 11.75,     l2: 2.52210,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:750, step:18775 (TRAIN, VALID): total: 2042.76, 2046.40      recon: 2028.28, 2032.19,     kl: 11.96, 11.70,     l2: 2.52254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:751, step:18800 (TRAIN, VALID): total: 2042.88, 2047.37      recon: 2028.45, 2033.15,     kl: 11.90, 11.69,     l2: 2.52210,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:752, step:18825 (TRAIN, VALID): total: 2042.96, 2046.98      recon: 2028.51, 2032.69,     kl: 11.92, 11.76,     l2: 2.52255,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000595.\n",
      "Epoch:753, step:18850 (TRAIN, VALID): total: 2043.07, 2046.37      recon: 2028.38, 2031.85,     kl: 12.16, 12.00,     l2: 2.52245,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:754, step:18875 (TRAIN, VALID): total: 2042.87, 2046.95      recon: 2028.32, 2032.74,     kl: 12.03, 11.69,     l2: 2.52264,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:755, step:18900 (TRAIN, VALID): total: 2042.85, 2047.35      recon: 2028.31, 2033.02,     kl: 12.01, 11.80,     l2: 2.52284,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:756, step:18925 (TRAIN, VALID): total: 2043.00, 2046.36      recon: 2028.41, 2032.03,     kl: 12.07, 11.81,     l2: 2.52254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:757, step:18950 (TRAIN, VALID): total: 2042.71, 2046.66      recon: 2028.20, 2032.47,     kl: 11.99, 11.67,     l2: 2.52333,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:758, step:18975 (TRAIN, VALID): total: 2042.75, 2047.20      recon: 2028.28, 2032.89,     kl: 11.95, 11.79,     l2: 2.52360,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:759, step:19000 (TRAIN, VALID): total: 2042.84, 2047.21      recon: 2028.35, 2032.96,     kl: 11.97, 11.72,     l2: 2.52308,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:760, step:19025 (TRAIN, VALID): total: 2042.84, 2047.07      recon: 2028.35, 2032.84,     kl: 11.97, 11.70,     l2: 2.52306,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:761, step:19050 (TRAIN, VALID): total: 2043.03, 2046.15      recon: 2028.54, 2031.83,     kl: 11.97, 11.80,     l2: 2.52317,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000566.\n",
      "Epoch:762, step:19075 (TRAIN, VALID): total: 2042.74, 2047.12      recon: 2028.24, 2032.88,     kl: 11.98, 11.72,     l2: 2.52259,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:763, step:19100 (TRAIN, VALID): total: 2042.76, 2047.46      recon: 2028.31, 2033.24,     kl: 11.93, 11.70,     l2: 2.52240,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:764, step:19125 (TRAIN, VALID): total: 2042.65, 2046.60      recon: 2028.16, 2032.39,     kl: 11.96, 11.69,     l2: 2.52303,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:765, step:19150 (TRAIN, VALID): total: 2042.69, 2047.48      recon: 2028.21, 2033.27,     kl: 11.95, 11.69,     l2: 2.52343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:766, step:19175 (TRAIN, VALID): total: 2042.93, 2046.69      recon: 2028.47, 2032.33,     kl: 11.93, 11.84,     l2: 2.52344,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:767, step:19200 (TRAIN, VALID): total: 2042.82, 2046.19      recon: 2028.28, 2031.92,     kl: 12.02, 11.74,     l2: 2.52323,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:768, step:19225 (TRAIN, VALID): total: 2042.81, 2048.58      recon: 2028.30, 2034.23,     kl: 11.99, 11.83,     l2: 2.52278,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:769, step:19250 (TRAIN, VALID): total: 2043.13, 2047.28      recon: 2028.56, 2032.97,     kl: 12.04, 11.79,     l2: 2.52303,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000537.\n",
      "Epoch:770, step:19275 (TRAIN, VALID): total: 2042.90, 2047.98      recon: 2028.35, 2033.67,     kl: 12.03, 11.79,     l2: 2.52347,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:771, step:19300 (TRAIN, VALID): total: 2042.84, 2047.75      recon: 2028.37, 2033.52,     kl: 11.94, 11.71,     l2: 2.52335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:772, step:19325 (TRAIN, VALID): total: 2042.80, 2046.10      recon: 2028.32, 2031.88,     kl: 11.95, 11.70,     l2: 2.52284,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:773, step:19350 (TRAIN, VALID): total: 2042.83, 2047.52      recon: 2028.33, 2033.15,     kl: 11.98, 11.85,     l2: 2.52256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:774, step:19375 (TRAIN, VALID): total: 2042.81, 2045.28      recon: 2028.27, 2031.02,     kl: 12.02, 11.74,     l2: 2.52322,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:775, step:19400 (TRAIN, VALID): total: 2042.76, 2046.59      recon: 2028.21, 2032.30,     kl: 12.02, 11.77,     l2: 2.52327,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:776, step:19425 (TRAIN, VALID): total: 2042.73, 2046.90      recon: 2028.23, 2032.61,     kl: 11.97, 11.77,     l2: 2.52339,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:777, step:19450 (TRAIN, VALID): total: 2042.74, 2047.50      recon: 2028.19, 2033.23,     kl: 12.03, 11.74,     l2: 2.52360,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:778, step:19475 (TRAIN, VALID): total: 2042.85, 2046.78      recon: 2028.35, 2032.48,     kl: 11.97, 11.78,     l2: 2.52380,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000510.\n",
      "Epoch:779, step:19500 (TRAIN, VALID): total: 2042.68, 2046.67      recon: 2028.14, 2032.38,     kl: 12.02, 11.76,     l2: 2.52370,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:780, step:19525 (TRAIN, VALID): total: 2042.75, 2046.33      recon: 2028.21, 2032.10,     kl: 12.02, 11.70,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:781, step:19550 (TRAIN, VALID): total: 2042.71, 2046.92      recon: 2028.20, 2032.61,     kl: 11.98, 11.78,     l2: 2.52426,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:782, step:19575 (TRAIN, VALID): total: 2042.66, 2046.51      recon: 2028.15, 2032.26,     kl: 11.98, 11.73,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:783, step:19600 (TRAIN, VALID): total: 2043.14, 2046.56      recon: 2028.62, 2032.06,     kl: 12.00, 11.97,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:784, step:19625 (TRAIN, VALID): total: 2042.79, 2046.63      recon: 2028.12, 2032.37,     kl: 12.15, 11.73,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:785, step:19650 (TRAIN, VALID): total: 2042.73, 2046.82      recon: 2028.25, 2032.53,     kl: 11.96, 11.77,     l2: 2.52418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:786, step:19675 (TRAIN, VALID): total: 2042.71, 2047.32      recon: 2028.19, 2033.04,     kl: 12.00, 11.75,     l2: 2.52379,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:787, step:19700 (TRAIN, VALID): total: 2042.65, 2045.83      recon: 2028.16, 2031.59,     kl: 11.96, 11.71,     l2: 2.52402,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:788, step:19725 (TRAIN, VALID): total: 2042.75, 2047.03      recon: 2028.25, 2032.76,     kl: 11.98, 11.74,     l2: 2.52404,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:789, step:19750 (TRAIN, VALID): total: 2042.75, 2045.43      recon: 2028.24, 2031.15,     kl: 11.98, 11.76,     l2: 2.52398,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:790, step:19775 (TRAIN, VALID): total: 2042.68, 2047.16      recon: 2028.22, 2032.86,     kl: 11.93, 11.77,     l2: 2.52418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:791, step:19800 (TRAIN, VALID): total: 2042.85, 2047.28      recon: 2028.29, 2032.95,     kl: 12.03, 11.80,     l2: 2.52391,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000485.\n",
      "Epoch:792, step:19825 (TRAIN, VALID): total: 2042.68, 2046.94      recon: 2028.19, 2032.71,     kl: 11.97, 11.70,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:793, step:19850 (TRAIN, VALID): total: 2042.88, 2047.32      recon: 2028.32, 2032.91,     kl: 12.03, 11.88,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:794, step:19875 (TRAIN, VALID): total: 2042.71, 2046.14      recon: 2028.11, 2031.83,     kl: 12.08, 11.79,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:795, step:19900 (TRAIN, VALID): total: 2042.67, 2048.65      recon: 2028.16, 2034.36,     kl: 11.99, 11.76,     l2: 2.52411,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:796, step:19925 (TRAIN, VALID): total: 2042.70, 2047.24      recon: 2028.20, 2032.96,     kl: 11.98, 11.75,     l2: 2.52407,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:797, step:19950 (TRAIN, VALID): total: 2042.62, 2046.60      recon: 2028.11, 2032.34,     kl: 11.98, 11.74,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:798, step:19975 (TRAIN, VALID): total: 2042.72, 2045.72      recon: 2028.24, 2031.42,     kl: 11.96, 11.77,     l2: 2.52409,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:799, step:20000 (TRAIN, VALID): total: 2042.59, 2046.96      recon: 2028.08, 2032.71,     kl: 11.98, 11.72,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:800, step:20025 (TRAIN, VALID): total: 2042.72, 2046.11      recon: 2028.29, 2031.81,     kl: 11.91, 11.77,     l2: 2.52457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:801, step:20050 (TRAIN, VALID): total: 2042.65, 2046.58      recon: 2028.07, 2032.25,     kl: 12.06, 11.80,     l2: 2.52427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:802, step:20075 (TRAIN, VALID): total: 2042.74, 2047.37      recon: 2028.17, 2033.00,     kl: 12.05, 11.84,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000461.\n",
      "Epoch:803, step:20100 (TRAIN, VALID): total: 2042.78, 2048.72      recon: 2028.25, 2034.37,     kl: 12.00, 11.82,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:804, step:20125 (TRAIN, VALID): total: 2042.62, 2047.08      recon: 2028.08, 2032.83,     kl: 12.02, 11.72,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:805, step:20150 (TRAIN, VALID): total: 2042.65, 2046.61      recon: 2028.13, 2032.32,     kl: 12.00, 11.77,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:806, step:20175 (TRAIN, VALID): total: 2042.66, 2047.83      recon: 2028.16, 2033.52,     kl: 11.97, 11.79,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:807, step:20200 (TRAIN, VALID): total: 2042.70, 2048.01      recon: 2028.19, 2033.75,     kl: 11.99, 11.74,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:808, step:20225 (TRAIN, VALID): total: 2042.58, 2047.49      recon: 2028.12, 2033.24,     kl: 11.94, 11.73,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:809, step:20250 (TRAIN, VALID): total: 2042.97, 2047.07      recon: 2028.46, 2032.75,     kl: 11.98, 11.80,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000438.\n",
      "Epoch:810, step:20275 (TRAIN, VALID): total: 2042.73, 2046.96      recon: 2028.10, 2032.57,     kl: 12.10, 11.87,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:811, step:20300 (TRAIN, VALID): total: 2042.63, 2046.88      recon: 2028.12, 2032.62,     kl: 11.98, 11.73,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:812, step:20325 (TRAIN, VALID): total: 2042.58, 2046.67      recon: 2028.06, 2032.39,     kl: 12.00, 11.75,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:813, step:20350 (TRAIN, VALID): total: 2042.52, 2046.98      recon: 2028.04, 2032.74,     kl: 11.96, 11.71,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:814, step:20375 (TRAIN, VALID): total: 2042.62, 2047.31      recon: 2028.16, 2033.12,     kl: 11.94, 11.67,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:815, step:20400 (TRAIN, VALID): total: 2042.69, 2047.25      recon: 2028.22, 2032.97,     kl: 11.94, 11.75,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:816, step:20425 (TRAIN, VALID): total: 2042.50, 2046.35      recon: 2028.00, 2032.02,     kl: 11.98, 11.81,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:817, step:20450 (TRAIN, VALID): total: 2042.53, 2047.68      recon: 2028.01, 2033.45,     kl: 11.99, 11.70,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:818, step:20475 (TRAIN, VALID): total: 2042.60, 2047.01      recon: 2028.16, 2032.76,     kl: 11.91, 11.73,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:819, step:20500 (TRAIN, VALID): total: 2042.62, 2046.91      recon: 2028.12, 2032.62,     kl: 11.98, 11.76,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:820, step:20525 (TRAIN, VALID): total: 2042.61, 2046.10      recon: 2028.10, 2031.87,     kl: 11.99, 11.70,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:821, step:20550 (TRAIN, VALID): total: 2042.59, 2046.87      recon: 2028.06, 2032.47,     kl: 12.01, 11.87,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:822, step:20575 (TRAIN, VALID): total: 2042.58, 2046.79      recon: 2028.02, 2032.52,     kl: 12.03, 11.74,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:823, step:20600 (TRAIN, VALID): total: 2042.57, 2046.37      recon: 2028.09, 2032.11,     kl: 11.96, 11.73,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:824, step:20625 (TRAIN, VALID): total: 2042.59, 2045.13      recon: 2028.08, 2030.89,     kl: 11.99, 11.71,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:825, step:20650 (TRAIN, VALID): total: 2043.08, 2047.37      recon: 2028.48, 2032.91,     kl: 12.08, 11.94,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000416.\n",
      "Epoch:826, step:20675 (TRAIN, VALID): total: 2042.75, 2047.18      recon: 2028.12, 2032.80,     kl: 12.10, 11.85,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:827, step:20700 (TRAIN, VALID): total: 2042.60, 2046.93      recon: 2027.99, 2032.62,     kl: 12.08, 11.78,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:828, step:20725 (TRAIN, VALID): total: 2042.51, 2046.85      recon: 2027.98, 2032.58,     kl: 12.00, 11.74,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:829, step:20750 (TRAIN, VALID): total: 2042.82, 2046.69      recon: 2028.29, 2032.41,     kl: 12.01, 11.76,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:830, step:20775 (TRAIN, VALID): total: 2042.77, 2046.23      recon: 2028.21, 2031.87,     kl: 12.03, 11.84,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:831, step:20800 (TRAIN, VALID): total: 2042.52, 2046.13      recon: 2028.00, 2031.90,     kl: 11.99, 11.70,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:832, step:20825 (TRAIN, VALID): total: 2042.55, 2047.72      recon: 2028.06, 2033.41,     kl: 11.96, 11.79,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:833, step:20850 (TRAIN, VALID): total: 2042.83, 2046.59      recon: 2028.27, 2032.33,     kl: 12.04, 11.74,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000395.\n",
      "Epoch:834, step:20875 (TRAIN, VALID): total: 2042.49, 2047.47      recon: 2028.00, 2033.20,     kl: 11.96, 11.74,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:835, step:20900 (TRAIN, VALID): total: 2042.43, 2046.45      recon: 2027.99, 2032.22,     kl: 11.92, 11.70,     l2: 2.52583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:836, step:20925 (TRAIN, VALID): total: 2042.54, 2046.11      recon: 2028.03, 2031.78,     kl: 11.98, 11.80,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:837, step:20950 (TRAIN, VALID): total: 2042.57, 2047.23      recon: 2028.04, 2032.93,     kl: 12.00, 11.77,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:838, step:20975 (TRAIN, VALID): total: 2042.53, 2046.68      recon: 2028.02, 2032.36,     kl: 11.98, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:839, step:21000 (TRAIN, VALID): total: 2042.48, 2047.19      recon: 2027.97, 2032.86,     kl: 11.99, 11.81,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:840, step:21025 (TRAIN, VALID): total: 2042.49, 2047.10      recon: 2027.92, 2032.84,     kl: 12.04, 11.73,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:841, step:21050 (TRAIN, VALID): total: 2042.42, 2047.64      recon: 2027.96, 2033.44,     kl: 11.93, 11.67,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:842, step:21075 (TRAIN, VALID): total: 2042.75, 2046.84      recon: 2028.19, 2032.41,     kl: 12.03, 11.91,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000375.\n",
      "Epoch:843, step:21100 (TRAIN, VALID): total: 2042.64, 2047.06      recon: 2027.99, 2032.72,     kl: 12.12, 11.82,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:844, step:21125 (TRAIN, VALID): total: 2042.55, 2047.13      recon: 2028.05, 2032.85,     kl: 11.98, 11.75,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:845, step:21150 (TRAIN, VALID): total: 2042.61, 2047.82      recon: 2028.07, 2033.49,     kl: 12.02, 11.81,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:846, step:21175 (TRAIN, VALID): total: 2042.80, 2046.80      recon: 2028.26, 2032.43,     kl: 12.02, 11.84,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:847, step:21200 (TRAIN, VALID): total: 2042.62, 2045.64      recon: 2028.08, 2031.33,     kl: 12.02, 11.79,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:848, step:21225 (TRAIN, VALID): total: 2042.50, 2047.21      recon: 2027.95, 2032.93,     kl: 12.02, 11.75,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:849, step:21250 (TRAIN, VALID): total: 2042.56, 2046.89      recon: 2028.03, 2032.59,     kl: 12.01, 11.77,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:850, step:21275 (TRAIN, VALID): total: 2042.49, 2046.01      recon: 2027.97, 2031.72,     kl: 12.00, 11.77,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:851, step:21300 (TRAIN, VALID): total: 2042.63, 2046.55      recon: 2028.11, 2032.25,     kl: 11.99, 11.77,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:852, step:21325 (TRAIN, VALID): total: 2042.53, 2046.55      recon: 2028.00, 2032.24,     kl: 12.01, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:853, step:21350 (TRAIN, VALID): total: 2042.50, 2045.88      recon: 2027.96, 2031.57,     kl: 12.02, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:854, step:21375 (TRAIN, VALID): total: 2042.44, 2046.81      recon: 2027.95, 2032.55,     kl: 11.97, 11.73,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:855, step:21400 (TRAIN, VALID): total: 2042.55, 2047.70      recon: 2028.00, 2033.39,     kl: 12.03, 11.79,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:856, step:21425 (TRAIN, VALID): total: 2042.73, 2046.29      recon: 2028.21, 2032.02,     kl: 12.00, 11.74,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000356.\n",
      "Epoch:857, step:21450 (TRAIN, VALID): total: 2042.65, 2046.61      recon: 2028.14, 2032.32,     kl: 11.99, 11.77,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:858, step:21475 (TRAIN, VALID): total: 2042.48, 2046.64      recon: 2027.95, 2032.30,     kl: 12.00, 11.81,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:859, step:21500 (TRAIN, VALID): total: 2042.47, 2047.92      recon: 2027.93, 2033.56,     kl: 12.02, 11.83,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:860, step:21525 (TRAIN, VALID): total: 2042.76, 2047.37      recon: 2028.18, 2033.02,     kl: 12.06, 11.83,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:861, step:21550 (TRAIN, VALID): total: 2042.54, 2046.08      recon: 2027.94, 2031.72,     kl: 12.07, 11.84,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:862, step:21575 (TRAIN, VALID): total: 2042.49, 2047.88      recon: 2027.94, 2033.62,     kl: 12.02, 11.74,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:863, step:21600 (TRAIN, VALID): total: 2042.45, 2046.55      recon: 2027.94, 2032.17,     kl: 11.98, 11.85,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:864, step:21625 (TRAIN, VALID): total: 2042.27, 2047.57      recon: 2027.72, 2033.31,     kl: 12.03, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:865, step:21650 (TRAIN, VALID): total: 2042.42, 2047.31      recon: 2027.95, 2033.09,     kl: 11.95, 11.69,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:866, step:21675 (TRAIN, VALID): total: 2042.43, 2047.01      recon: 2027.95, 2032.75,     kl: 11.95, 11.73,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:867, step:21700 (TRAIN, VALID): total: 2042.49, 2047.52      recon: 2028.00, 2033.22,     kl: 11.97, 11.78,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:868, step:21725 (TRAIN, VALID): total: 2042.47, 2046.88      recon: 2027.96, 2032.57,     kl: 11.98, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:869, step:21750 (TRAIN, VALID): total: 2042.45, 2046.37      recon: 2027.95, 2032.05,     kl: 11.98, 11.79,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:870, step:21775 (TRAIN, VALID): total: 2042.49, 2046.86      recon: 2027.94, 2032.54,     kl: 12.03, 11.79,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000339.\n",
      "Epoch:871, step:21800 (TRAIN, VALID): total: 2042.52, 2046.34      recon: 2027.90, 2031.98,     kl: 12.10, 11.83,     l2: 2.52595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:872, step:21825 (TRAIN, VALID): total: 2042.39, 2046.18      recon: 2027.86, 2031.89,     kl: 12.00, 11.76,     l2: 2.52593,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:873, step:21850 (TRAIN, VALID): total: 2042.49, 2047.67      recon: 2028.01, 2033.44,     kl: 11.95, 11.70,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:874, step:21875 (TRAIN, VALID): total: 2042.42, 2047.22      recon: 2027.93, 2032.99,     kl: 11.96, 11.70,     l2: 2.52592,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:875, step:21900 (TRAIN, VALID): total: 2042.39, 2047.90      recon: 2027.91, 2033.63,     kl: 11.96, 11.74,     l2: 2.52596,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:876, step:21925 (TRAIN, VALID): total: 2042.64, 2047.76      recon: 2028.15, 2033.45,     kl: 11.97, 11.79,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:877, step:21950 (TRAIN, VALID): total: 2042.40, 2047.06      recon: 2027.86, 2032.77,     kl: 12.01, 11.77,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:878, step:21975 (TRAIN, VALID): total: 2042.37, 2046.09      recon: 2027.85, 2031.81,     kl: 11.99, 11.75,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:879, step:22000 (TRAIN, VALID): total: 2042.35, 2045.58      recon: 2027.87, 2031.30,     kl: 11.95, 11.76,     l2: 2.52587,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:880, step:22025 (TRAIN, VALID): total: 2042.52, 2046.90      recon: 2028.02, 2032.61,     kl: 11.97, 11.76,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:881, step:22050 (TRAIN, VALID): total: 2042.48, 2047.86      recon: 2028.02, 2033.62,     kl: 11.94, 11.72,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:882, step:22075 (TRAIN, VALID): total: 2042.41, 2047.28      recon: 2027.94, 2032.99,     kl: 11.94, 11.76,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:883, step:22100 (TRAIN, VALID): total: 2042.67, 2047.25      recon: 2028.08, 2032.87,     kl: 12.07, 11.85,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000322.\n",
      "Epoch:884, step:22125 (TRAIN, VALID): total: 2042.46, 2046.09      recon: 2027.89, 2031.82,     kl: 12.05, 11.75,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:885, step:22150 (TRAIN, VALID): total: 2042.69, 2046.38      recon: 2028.13, 2032.08,     kl: 12.03, 11.78,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:886, step:22175 (TRAIN, VALID): total: 2042.58, 2046.68      recon: 2027.93, 2032.23,     kl: 12.13, 11.93,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:887, step:22200 (TRAIN, VALID): total: 2042.43, 2047.14      recon: 2027.86, 2032.81,     kl: 12.05, 11.80,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:888, step:22225 (TRAIN, VALID): total: 2042.31, 2045.99      recon: 2027.76, 2031.74,     kl: 12.03, 11.72,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:889, step:22250 (TRAIN, VALID): total: 2042.63, 2045.64      recon: 2028.10, 2031.31,     kl: 12.01, 11.81,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:890, step:22275 (TRAIN, VALID): total: 2042.30, 2046.43      recon: 2027.71, 2032.14,     kl: 12.07, 11.77,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:891, step:22300 (TRAIN, VALID): total: 2042.46, 2046.93      recon: 2027.94, 2032.64,     kl: 12.00, 11.76,     l2: 2.52605,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:892, step:22325 (TRAIN, VALID): total: 2042.66, 2047.17      recon: 2028.09, 2032.83,     kl: 12.05, 11.81,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000306.\n",
      "Epoch:893, step:22350 (TRAIN, VALID): total: 2042.38, 2046.57      recon: 2027.87, 2032.30,     kl: 11.98, 11.75,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:894, step:22375 (TRAIN, VALID): total: 2042.31, 2046.10      recon: 2027.82, 2031.83,     kl: 11.97, 11.75,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:895, step:22400 (TRAIN, VALID): total: 2042.31, 2046.64      recon: 2027.84, 2032.43,     kl: 11.94, 11.69,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:896, step:22425 (TRAIN, VALID): total: 2042.50, 2046.32      recon: 2028.02, 2032.02,     kl: 11.95, 11.77,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:897, step:22450 (TRAIN, VALID): total: 2042.75, 2046.16      recon: 2028.19, 2031.85,     kl: 12.04, 11.79,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:898, step:22475 (TRAIN, VALID): total: 2042.34, 2045.73      recon: 2027.84, 2031.46,     kl: 11.97, 11.74,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:899, step:22500 (TRAIN, VALID): total: 2042.58, 2045.34      recon: 2028.04, 2031.03,     kl: 12.02, 11.79,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:900, step:22525 (TRAIN, VALID): total: 2042.72, 2046.18      recon: 2028.17, 2031.86,     kl: 12.02, 11.79,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:901, step:22550 (TRAIN, VALID): total: 2042.40, 2046.39      recon: 2027.87, 2032.08,     kl: 12.00, 11.78,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:902, step:22575 (TRAIN, VALID): total: 2042.53, 2046.02      recon: 2027.95, 2031.62,     kl: 12.05, 11.87,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:903, step:22600 (TRAIN, VALID): total: 2042.52, 2047.43      recon: 2027.94, 2033.14,     kl: 12.06, 11.77,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:904, step:22625 (TRAIN, VALID): total: 2042.32, 2046.31      recon: 2027.77, 2032.07,     kl: 12.02, 11.71,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:905, step:22650 (TRAIN, VALID): total: 2042.49, 2045.90      recon: 2028.03, 2031.60,     kl: 11.94, 11.78,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:906, step:22675 (TRAIN, VALID): total: 2042.39, 2046.52      recon: 2027.84, 2032.20,     kl: 12.02, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:907, step:22700 (TRAIN, VALID): total: 2042.34, 2047.22      recon: 2027.79, 2032.90,     kl: 12.02, 11.79,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:908, step:22725 (TRAIN, VALID): total: 2042.44, 2047.02      recon: 2027.92, 2032.71,     kl: 11.99, 11.78,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:909, step:22750 (TRAIN, VALID): total: 2042.27, 2047.20      recon: 2027.76, 2032.97,     kl: 11.99, 11.71,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:910, step:22775 (TRAIN, VALID): total: 2042.46, 2046.44      recon: 2027.98, 2032.15,     kl: 11.95, 11.76,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:911, step:22800 (TRAIN, VALID): total: 2042.53, 2046.44      recon: 2027.95, 2032.08,     kl: 12.06, 11.84,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000290.\n",
      "Epoch:912, step:22825 (TRAIN, VALID): total: 2042.40, 2046.30      recon: 2027.83, 2031.98,     kl: 12.05, 11.80,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:913, step:22850 (TRAIN, VALID): total: 2042.29, 2045.91      recon: 2027.79, 2031.62,     kl: 11.97, 11.76,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:914, step:22875 (TRAIN, VALID): total: 2042.37, 2046.35      recon: 2027.85, 2032.08,     kl: 12.00, 11.74,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:915, step:22900 (TRAIN, VALID): total: 2042.29, 2046.45      recon: 2027.78, 2032.19,     kl: 11.99, 11.74,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:916, step:22925 (TRAIN, VALID): total: 2042.31, 2047.61      recon: 2027.78, 2033.31,     kl: 12.01, 11.77,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:917, step:22950 (TRAIN, VALID): total: 2042.30, 2047.49      recon: 2027.77, 2033.16,     kl: 12.00, 11.80,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:918, step:22975 (TRAIN, VALID): total: 2042.42, 2047.40      recon: 2027.88, 2033.11,     kl: 12.01, 11.77,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000276.\n",
      "Epoch:919, step:23000 (TRAIN, VALID): total: 2042.20, 2048.46      recon: 2027.70, 2034.21,     kl: 11.98, 11.72,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:920, step:23025 (TRAIN, VALID): total: 2042.37, 2045.76      recon: 2027.89, 2031.46,     kl: 11.96, 11.77,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:921, step:23050 (TRAIN, VALID): total: 2042.49, 2045.49      recon: 2027.93, 2031.16,     kl: 12.04, 11.81,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:922, step:23075 (TRAIN, VALID): total: 2042.44, 2046.55      recon: 2027.90, 2032.21,     kl: 12.01, 11.81,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:923, step:23100 (TRAIN, VALID): total: 2042.40, 2047.10      recon: 2027.85, 2032.76,     kl: 12.03, 11.81,     l2: 2.52604,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:924, step:23125 (TRAIN, VALID): total: 2042.69, 2047.67      recon: 2028.10, 2033.30,     kl: 12.07, 11.84,     l2: 2.52594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:925, step:23150 (TRAIN, VALID): total: 2042.63, 2047.32      recon: 2028.04, 2032.96,     kl: 12.06, 11.83,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:926, step:23175 (TRAIN, VALID): total: 2042.33, 2046.81      recon: 2027.73, 2032.46,     kl: 12.07, 11.82,     l2: 2.52590,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:927, step:23200 (TRAIN, VALID): total: 2042.26, 2048.42      recon: 2027.71, 2034.13,     kl: 12.02, 11.76,     l2: 2.52585,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:928, step:23225 (TRAIN, VALID): total: 2042.32, 2046.67      recon: 2027.79, 2032.37,     kl: 12.00, 11.78,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:929, step:23250 (TRAIN, VALID): total: 2042.30, 2046.63      recon: 2027.77, 2032.32,     kl: 12.00, 11.79,     l2: 2.52616,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:930, step:23275 (TRAIN, VALID): total: 2042.32, 2047.40      recon: 2027.79, 2033.09,     kl: 12.01, 11.78,     l2: 2.52599,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:931, step:23300 (TRAIN, VALID): total: 2042.23, 2046.27      recon: 2027.70, 2032.02,     kl: 12.01, 11.73,     l2: 2.52632,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:932, step:23325 (TRAIN, VALID): total: 2042.32, 2045.93      recon: 2027.83, 2031.64,     kl: 11.96, 11.76,     l2: 2.52597,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:933, step:23350 (TRAIN, VALID): total: 2042.56, 2046.47      recon: 2028.04, 2032.17,     kl: 12.00, 11.77,     l2: 2.52602,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000262.\n",
      "Epoch:934, step:23375 (TRAIN, VALID): total: 2042.37, 2046.56      recon: 2027.82, 2032.22,     kl: 12.03, 11.81,     l2: 2.52586,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:935, step:23400 (TRAIN, VALID): total: 2042.30, 2046.45      recon: 2027.75, 2032.13,     kl: 12.02, 11.80,     l2: 2.52602,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:936, step:23425 (TRAIN, VALID): total: 2042.32, 2047.42      recon: 2027.79, 2033.10,     kl: 12.00, 11.79,     l2: 2.52595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:937, step:23450 (TRAIN, VALID): total: 2042.24, 2046.66      recon: 2027.71, 2032.42,     kl: 12.01, 11.72,     l2: 2.52594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:938, step:23475 (TRAIN, VALID): total: 2042.64, 2046.95      recon: 2028.15, 2032.67,     kl: 11.96, 11.76,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:939, step:23500 (TRAIN, VALID): total: 2042.34, 2046.32      recon: 2027.78, 2031.96,     kl: 12.04, 11.83,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:940, step:23525 (TRAIN, VALID): total: 2042.25, 2048.51      recon: 2027.71, 2034.25,     kl: 12.01, 11.73,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:941, step:23550 (TRAIN, VALID): total: 2042.32, 2046.44      recon: 2027.83, 2032.17,     kl: 11.96, 11.75,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:942, step:23575 (TRAIN, VALID): total: 2042.43, 2047.11      recon: 2027.88, 2032.72,     kl: 12.02, 11.87,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:943, step:23600 (TRAIN, VALID): total: 2042.38, 2047.08      recon: 2027.79, 2032.76,     kl: 12.07, 11.80,     l2: 2.52578,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:944, step:23625 (TRAIN, VALID): total: 2042.47, 2046.44      recon: 2027.94, 2032.14,     kl: 12.01, 11.77,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:945, step:23650 (TRAIN, VALID): total: 2042.32, 2046.60      recon: 2027.78, 2032.26,     kl: 12.01, 11.81,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:946, step:23675 (TRAIN, VALID): total: 2042.48, 2045.59      recon: 2027.97, 2031.30,     kl: 11.99, 11.76,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000249.\n",
      "Epoch:947, step:23700 (TRAIN, VALID): total: 2042.37, 2047.12      recon: 2027.80, 2032.77,     kl: 12.04, 11.83,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:948, step:23725 (TRAIN, VALID): total: 2042.29, 2046.09      recon: 2027.70, 2031.76,     kl: 12.06, 11.80,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:949, step:23750 (TRAIN, VALID): total: 2042.28, 2047.14      recon: 2027.71, 2032.81,     kl: 12.04, 11.81,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:950, step:23775 (TRAIN, VALID): total: 2042.21, 2046.56      recon: 2027.68, 2032.27,     kl: 12.00, 11.76,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:951, step:23800 (TRAIN, VALID): total: 2042.28, 2045.95      recon: 2027.73, 2031.62,     kl: 12.03, 11.81,     l2: 2.52567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:952, step:23825 (TRAIN, VALID): total: 2042.79, 2047.39      recon: 2028.20, 2033.00,     kl: 12.07, 11.86,     l2: 2.52583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:953, step:23850 (TRAIN, VALID): total: 2042.29, 2046.44      recon: 2027.70, 2032.14,     kl: 12.07, 11.78,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:954, step:23875 (TRAIN, VALID): total: 2042.30, 2046.61      recon: 2027.76, 2032.32,     kl: 12.02, 11.76,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:955, step:23900 (TRAIN, VALID): total: 2042.30, 2047.90      recon: 2027.75, 2033.59,     kl: 12.03, 11.78,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:956, step:23925 (TRAIN, VALID): total: 2042.33, 2046.33      recon: 2027.76, 2032.01,     kl: 12.04, 11.79,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:957, step:23950 (TRAIN, VALID): total: 2042.38, 2047.36      recon: 2027.85, 2032.99,     kl: 12.01, 11.85,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:958, step:23975 (TRAIN, VALID): total: 2042.24, 2046.65      recon: 2027.65, 2032.25,     kl: 12.07, 11.87,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:959, step:24000 (TRAIN, VALID): total: 2042.36, 2045.77      recon: 2027.80, 2031.51,     kl: 12.03, 11.74,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:960, step:24025 (TRAIN, VALID): total: 2042.41, 2047.38      recon: 2027.85, 2033.03,     kl: 12.04, 11.83,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000236.\n",
      "Epoch:961, step:24050 (TRAIN, VALID): total: 2042.48, 2047.33      recon: 2027.92, 2033.02,     kl: 12.03, 11.79,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:962, step:24075 (TRAIN, VALID): total: 2042.40, 2045.72      recon: 2027.77, 2031.33,     kl: 12.11, 11.87,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:963, step:24100 (TRAIN, VALID): total: 2042.19, 2047.63      recon: 2027.63, 2033.33,     kl: 12.04, 11.77,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:964, step:24125 (TRAIN, VALID): total: 2042.22, 2047.30      recon: 2027.70, 2033.00,     kl: 11.99, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:965, step:24150 (TRAIN, VALID): total: 2042.31, 2046.63      recon: 2027.74, 2032.28,     kl: 12.04, 11.83,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:966, step:24175 (TRAIN, VALID): total: 2042.17, 2046.75      recon: 2027.61, 2032.42,     kl: 12.04, 11.80,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:967, step:24200 (TRAIN, VALID): total: 2042.20, 2046.45      recon: 2027.69, 2032.19,     kl: 11.99, 11.74,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:968, step:24225 (TRAIN, VALID): total: 2042.27, 2045.80      recon: 2027.74, 2031.54,     kl: 12.00, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:969, step:24250 (TRAIN, VALID): total: 2042.24, 2046.34      recon: 2027.73, 2032.02,     kl: 11.99, 11.80,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:970, step:24275 (TRAIN, VALID): total: 2042.24, 2045.82      recon: 2027.72, 2031.52,     kl: 12.00, 11.77,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:971, step:24300 (TRAIN, VALID): total: 2042.48, 2047.84      recon: 2027.95, 2033.43,     kl: 12.01, 11.88,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000225.\n",
      "Epoch:972, step:24325 (TRAIN, VALID): total: 2042.24, 2046.82      recon: 2027.63, 2032.46,     kl: 12.09, 11.83,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:973, step:24350 (TRAIN, VALID): total: 2042.14, 2047.01      recon: 2027.61, 2032.75,     kl: 12.01, 11.74,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:974, step:24375 (TRAIN, VALID): total: 2042.43, 2046.50      recon: 2027.92, 2032.17,     kl: 11.99, 11.80,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:975, step:24400 (TRAIN, VALID): total: 2042.25, 2047.34      recon: 2027.68, 2033.02,     kl: 12.04, 11.80,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:976, step:24425 (TRAIN, VALID): total: 2042.28, 2046.36      recon: 2027.73, 2032.00,     kl: 12.03, 11.84,     l2: 2.52545,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:977, step:24450 (TRAIN, VALID): total: 2042.44, 2046.58      recon: 2027.85, 2032.16,     kl: 12.06, 11.90,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:978, step:24475 (TRAIN, VALID): total: 2042.22, 2045.64      recon: 2027.60, 2031.30,     kl: 12.09, 11.81,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:979, step:24500 (TRAIN, VALID): total: 2042.29, 2046.28      recon: 2027.74, 2031.95,     kl: 12.02, 11.81,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:980, step:24525 (TRAIN, VALID): total: 2042.34, 2046.62      recon: 2027.79, 2032.31,     kl: 12.03, 11.78,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:981, step:24550 (TRAIN, VALID): total: 2042.22, 2045.90      recon: 2027.68, 2031.58,     kl: 12.02, 11.79,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:982, step:24575 (TRAIN, VALID): total: 2042.48, 2047.52      recon: 2027.91, 2033.14,     kl: 12.05, 11.86,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000213.\n",
      "Epoch:983, step:24600 (TRAIN, VALID): total: 2042.40, 2046.70      recon: 2027.85, 2032.40,     kl: 12.03, 11.78,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:984, step:24625 (TRAIN, VALID): total: 2042.38, 2046.43      recon: 2027.86, 2032.13,     kl: 11.99, 11.78,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:985, step:24650 (TRAIN, VALID): total: 2042.31, 2046.28      recon: 2027.72, 2031.89,     kl: 12.06, 11.86,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:986, step:24675 (TRAIN, VALID): total: 2042.29, 2047.14      recon: 2027.71, 2032.80,     kl: 12.06, 11.81,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:987, step:24700 (TRAIN, VALID): total: 2042.20, 2046.01      recon: 2027.65, 2031.75,     kl: 12.02, 11.74,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:988, step:24725 (TRAIN, VALID): total: 2042.24, 2044.70      recon: 2027.66, 2030.34,     kl: 12.06, 11.83,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:989, step:24750 (TRAIN, VALID): total: 2042.23, 2046.66      recon: 2027.66, 2032.34,     kl: 12.04, 11.80,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:990, step:24775 (TRAIN, VALID): total: 2042.22, 2047.40      recon: 2027.69, 2033.11,     kl: 12.01, 11.76,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:991, step:24800 (TRAIN, VALID): total: 2042.18, 2046.02      recon: 2027.66, 2031.72,     kl: 11.99, 11.77,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:992, step:24825 (TRAIN, VALID): total: 2042.14, 2046.68      recon: 2027.64, 2032.41,     kl: 11.97, 11.75,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:993, step:24850 (TRAIN, VALID): total: 2042.25, 2046.45      recon: 2027.74, 2032.13,     kl: 11.98, 11.79,     l2: 2.52599,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000203.\n",
      "Epoch:994, step:24875 (TRAIN, VALID): total: 2042.41, 2047.88      recon: 2027.84, 2033.55,     kl: 12.04, 11.80,     l2: 2.52586,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:995, step:24900 (TRAIN, VALID): total: 2042.42, 2046.47      recon: 2027.84, 2032.13,     kl: 12.06, 11.81,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:996, step:24925 (TRAIN, VALID): total: 2042.26, 2046.65      recon: 2027.69, 2032.30,     kl: 12.04, 11.82,     l2: 2.52579,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:997, step:24950 (TRAIN, VALID): total: 2042.25, 2046.36      recon: 2027.71, 2032.03,     kl: 12.02, 11.81,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:998, step:24975 (TRAIN, VALID): total: 2042.29, 2045.74      recon: 2027.75, 2031.45,     kl: 12.02, 11.76,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:999, step:25000 (TRAIN, VALID): total: 2042.18, 2046.01      recon: 2027.65, 2031.73,     kl: 12.01, 11.76,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1000, step:25025 (TRAIN, VALID): total: 2042.29, 2046.89      recon: 2027.76, 2032.59,     kl: 12.00, 11.77,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1001, step:25050 (TRAIN, VALID): total: 2042.17, 2047.47      recon: 2027.65, 2033.16,     kl: 12.00, 11.78,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1002, step:25075 (TRAIN, VALID): total: 2042.14, 2046.73      recon: 2027.61, 2032.48,     kl: 12.01, 11.73,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1003, step:25100 (TRAIN, VALID): total: 2042.05, 2047.25      recon: 2027.56, 2033.00,     kl: 11.97, 11.73,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1004, step:25125 (TRAIN, VALID): total: 2042.27, 2047.01      recon: 2027.78, 2032.71,     kl: 11.96, 11.77,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1005, step:25150 (TRAIN, VALID): total: 2042.39, 2046.81      recon: 2027.83, 2032.42,     kl: 12.04, 11.87,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000193.\n",
      "Epoch:1006, step:25175 (TRAIN, VALID): total: 2042.17, 2045.48      recon: 2027.57, 2031.14,     kl: 12.07, 11.81,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1007, step:25200 (TRAIN, VALID): total: 2042.19, 2045.48      recon: 2027.67, 2031.21,     kl: 11.99, 11.74,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1008, step:25225 (TRAIN, VALID): total: 2042.19, 2046.70      recon: 2027.65, 2032.39,     kl: 12.01, 11.79,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1009, step:25250 (TRAIN, VALID): total: 2042.17, 2046.15      recon: 2027.65, 2031.89,     kl: 11.99, 11.73,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1010, step:25275 (TRAIN, VALID): total: 2042.42, 2046.14      recon: 2027.91, 2031.82,     kl: 11.98, 11.79,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1011, step:25300 (TRAIN, VALID): total: 2042.22, 2047.16      recon: 2027.68, 2032.87,     kl: 12.02, 11.77,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1012, step:25325 (TRAIN, VALID): total: 2042.18, 2046.02      recon: 2027.66, 2031.70,     kl: 12.00, 11.80,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1013, step:25350 (TRAIN, VALID): total: 2042.21, 2047.55      recon: 2027.63, 2033.22,     kl: 12.06, 11.80,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1014, step:25375 (TRAIN, VALID): total: 2042.11, 2045.00      recon: 2027.54, 2030.71,     kl: 12.04, 11.76,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1015, step:25400 (TRAIN, VALID): total: 2042.21, 2046.52      recon: 2027.68, 2032.21,     kl: 12.00, 11.79,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1016, step:25425 (TRAIN, VALID): total: 2042.17, 2047.03      recon: 2027.66, 2032.72,     kl: 11.98, 11.78,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1017, step:25450 (TRAIN, VALID): total: 2042.19, 2047.06      recon: 2027.64, 2032.72,     kl: 12.03, 11.81,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1018, step:25475 (TRAIN, VALID): total: 2042.13, 2046.15      recon: 2027.56, 2031.92,     kl: 12.04, 11.71,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1019, step:25500 (TRAIN, VALID): total: 2042.23, 2047.33      recon: 2027.74, 2033.04,     kl: 11.97, 11.76,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000183.\n",
      "Epoch:1020, step:25525 (TRAIN, VALID): total: 2042.26, 2046.83      recon: 2027.71, 2032.47,     kl: 12.03, 11.84,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1021, step:25550 (TRAIN, VALID): total: 2042.24, 2047.25      recon: 2027.68, 2032.88,     kl: 12.04, 11.85,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1022, step:25575 (TRAIN, VALID): total: 2042.25, 2045.99      recon: 2027.67, 2031.65,     kl: 12.05, 11.81,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1023, step:25600 (TRAIN, VALID): total: 2042.15, 2046.59      recon: 2027.59, 2032.32,     kl: 12.04, 11.74,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1024, step:25625 (TRAIN, VALID): total: 2042.31, 2047.83      recon: 2027.77, 2033.46,     kl: 12.01, 11.85,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1025, step:25650 (TRAIN, VALID): total: 2042.18, 2047.78      recon: 2027.60, 2033.49,     kl: 12.05, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1026, step:25675 (TRAIN, VALID): total: 2042.18, 2046.14      recon: 2027.61, 2031.85,     kl: 12.04, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1027, step:25700 (TRAIN, VALID): total: 2042.35, 2047.19      recon: 2027.80, 2032.86,     kl: 12.02, 11.81,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000174.\n",
      "Epoch:1028, step:25725 (TRAIN, VALID): total: 2042.09, 2046.54      recon: 2027.56, 2032.30,     kl: 12.01, 11.72,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1029, step:25750 (TRAIN, VALID): total: 2042.13, 2046.48      recon: 2027.64, 2032.22,     kl: 11.97, 11.73,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1030, step:25775 (TRAIN, VALID): total: 2042.33, 2046.11      recon: 2027.81, 2031.76,     kl: 12.00, 11.83,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1031, step:25800 (TRAIN, VALID): total: 2042.15, 2047.27      recon: 2027.59, 2032.94,     kl: 12.04, 11.80,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1032, step:25825 (TRAIN, VALID): total: 2042.15, 2046.30      recon: 2027.62, 2031.99,     kl: 12.00, 11.78,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1033, step:25850 (TRAIN, VALID): total: 2042.05, 2045.94      recon: 2027.51, 2031.65,     kl: 12.02, 11.77,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1034, step:25875 (TRAIN, VALID): total: 2042.13, 2046.44      recon: 2027.63, 2032.17,     kl: 11.97, 11.74,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1035, step:25900 (TRAIN, VALID): total: 2042.16, 2047.40      recon: 2027.67, 2033.12,     kl: 11.97, 11.76,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1036, step:25925 (TRAIN, VALID): total: 2042.12, 2046.78      recon: 2027.61, 2032.50,     kl: 11.99, 11.76,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1037, step:25950 (TRAIN, VALID): total: 2042.21, 2047.04      recon: 2027.73, 2032.77,     kl: 11.96, 11.75,     l2: 2.52554,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000165.\n",
      "Epoch:1038, step:25975 (TRAIN, VALID): total: 2042.54, 2046.80      recon: 2028.00, 2032.47,     kl: 12.01, 11.80,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1039, step:26000 (TRAIN, VALID): total: 2042.36, 2045.91      recon: 2027.81, 2031.56,     kl: 12.02, 11.82,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1040, step:26025 (TRAIN, VALID): total: 2042.17, 2046.46      recon: 2027.61, 2032.15,     kl: 12.04, 11.79,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1041, step:26050 (TRAIN, VALID): total: 2042.14, 2046.38      recon: 2027.61, 2032.12,     kl: 12.00, 11.74,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1042, step:26075 (TRAIN, VALID): total: 2042.10, 2046.70      recon: 2027.57, 2032.42,     kl: 12.00, 11.76,     l2: 2.52561,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1043, step:26100 (TRAIN, VALID): total: 2042.16, 2046.90      recon: 2027.65, 2032.54,     kl: 11.99, 11.83,     l2: 2.52576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1044, step:26125 (TRAIN, VALID): total: 2042.18, 2047.36      recon: 2027.63, 2033.04,     kl: 12.03, 11.80,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1045, step:26150 (TRAIN, VALID): total: 2042.25, 2045.68      recon: 2027.70, 2031.33,     kl: 12.03, 11.83,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1046, step:26175 (TRAIN, VALID): total: 2042.39, 2047.83      recon: 2027.79, 2033.47,     kl: 12.07, 11.84,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000157.\n",
      "Epoch:1047, step:26200 (TRAIN, VALID): total: 2042.47, 2047.22      recon: 2027.90, 2032.87,     kl: 12.04, 11.83,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1048, step:26225 (TRAIN, VALID): total: 2042.11, 2046.28      recon: 2027.54, 2031.97,     kl: 12.04, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1049, step:26250 (TRAIN, VALID): total: 2042.11, 2047.66      recon: 2027.55, 2033.33,     kl: 12.04, 11.80,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1050, step:26275 (TRAIN, VALID): total: 2042.20, 2046.52      recon: 2027.69, 2032.24,     kl: 11.98, 11.75,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1051, step:26300 (TRAIN, VALID): total: 2042.19, 2046.13      recon: 2027.70, 2031.86,     kl: 11.96, 11.75,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1052, step:26325 (TRAIN, VALID): total: 2042.07, 2046.72      recon: 2027.52, 2032.42,     kl: 12.03, 11.78,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1053, step:26350 (TRAIN, VALID): total: 2042.32, 2046.12      recon: 2027.80, 2031.79,     kl: 11.99, 11.80,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1054, step:26375 (TRAIN, VALID): total: 2042.05, 2048.17      recon: 2027.49, 2033.83,     kl: 12.04, 11.82,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1055, step:26400 (TRAIN, VALID): total: 2042.18, 2047.17      recon: 2027.64, 2032.84,     kl: 12.01, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1056, step:26425 (TRAIN, VALID): total: 2042.24, 2045.34      recon: 2027.68, 2031.02,     kl: 12.03, 11.79,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1057, step:26450 (TRAIN, VALID): total: 2042.20, 2046.87      recon: 2027.62, 2032.50,     kl: 12.05, 11.85,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1058, step:26475 (TRAIN, VALID): total: 2042.04, 2046.34      recon: 2027.46, 2032.02,     kl: 12.05, 11.80,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1059, step:26500 (TRAIN, VALID): total: 2042.14, 2047.67      recon: 2027.60, 2033.34,     kl: 12.02, 11.80,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1060, step:26525 (TRAIN, VALID): total: 2042.13, 2046.00      recon: 2027.60, 2031.70,     kl: 12.00, 11.78,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1061, step:26550 (TRAIN, VALID): total: 2042.14, 2046.43      recon: 2027.64, 2032.14,     kl: 11.98, 11.76,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1062, step:26575 (TRAIN, VALID): total: 2042.18, 2046.30      recon: 2027.63, 2031.95,     kl: 12.02, 11.82,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1063, step:26600 (TRAIN, VALID): total: 2042.00, 2046.71      recon: 2027.45, 2032.42,     kl: 12.03, 11.76,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1064, step:26625 (TRAIN, VALID): total: 2042.03, 2047.41      recon: 2027.54, 2033.12,     kl: 11.97, 11.76,     l2: 2.52545,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1065, step:26650 (TRAIN, VALID): total: 2042.16, 2048.03      recon: 2027.65, 2033.75,     kl: 11.99, 11.76,     l2: 2.52516,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1066, step:26675 (TRAIN, VALID): total: 2042.07, 2047.51      recon: 2027.55, 2033.22,     kl: 12.00, 11.77,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1067, step:26700 (TRAIN, VALID): total: 2042.11, 2047.26      recon: 2027.56, 2032.93,     kl: 12.02, 11.80,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1068, step:26725 (TRAIN, VALID): total: 2042.14, 2046.63      recon: 2027.60, 2032.27,     kl: 12.01, 11.83,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1069, step:26750 (TRAIN, VALID): total: 2042.09, 2047.76      recon: 2027.54, 2033.47,     kl: 12.03, 11.77,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1070, step:26775 (TRAIN, VALID): total: 2042.17, 2046.31      recon: 2027.62, 2031.93,     kl: 12.02, 11.85,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000149.\n",
      "Epoch:1071, step:26800 (TRAIN, VALID): total: 2042.22, 2047.40      recon: 2027.60, 2033.02,     kl: 12.09, 11.85,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1072, step:26825 (TRAIN, VALID): total: 2042.11, 2046.63      recon: 2027.52, 2032.29,     kl: 12.06, 11.81,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1073, step:26850 (TRAIN, VALID): total: 2042.10, 2046.58      recon: 2027.51, 2032.24,     kl: 12.06, 11.81,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1074, step:26875 (TRAIN, VALID): total: 2042.13, 2047.17      recon: 2027.56, 2032.86,     kl: 12.04, 11.78,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1075, step:26900 (TRAIN, VALID): total: 2042.17, 2046.61      recon: 2027.62, 2032.26,     kl: 12.03, 11.83,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1076, step:26925 (TRAIN, VALID): total: 2042.12, 2046.43      recon: 2027.57, 2032.08,     kl: 12.02, 11.82,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1077, step:26950 (TRAIN, VALID): total: 2042.05, 2046.73      recon: 2027.50, 2032.40,     kl: 12.02, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1078, step:26975 (TRAIN, VALID): total: 2042.22, 2046.88      recon: 2027.65, 2032.57,     kl: 12.04, 11.79,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000142.\n",
      "Epoch:1079, step:27000 (TRAIN, VALID): total: 2042.19, 2046.33      recon: 2027.66, 2032.01,     kl: 12.01, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1080, step:27025 (TRAIN, VALID): total: 2042.13, 2047.50      recon: 2027.58, 2033.22,     kl: 12.02, 11.76,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1081, step:27050 (TRAIN, VALID): total: 2042.07, 2046.31      recon: 2027.56, 2032.03,     kl: 11.98, 11.76,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1082, step:27075 (TRAIN, VALID): total: 2042.51, 2046.09      recon: 2027.98, 2031.73,     kl: 12.01, 11.84,     l2: 2.52493,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1083, step:27100 (TRAIN, VALID): total: 2042.17, 2046.13      recon: 2027.56, 2031.75,     kl: 12.08, 11.85,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1084, step:27125 (TRAIN, VALID): total: 2042.14, 2046.77      recon: 2027.55, 2032.42,     kl: 12.06, 11.83,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1085, step:27150 (TRAIN, VALID): total: 2042.05, 2046.25      recon: 2027.47, 2031.93,     kl: 12.05, 11.80,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1086, step:27175 (TRAIN, VALID): total: 2042.09, 2048.37      recon: 2027.54, 2034.06,     kl: 12.02, 11.79,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1087, step:27200 (TRAIN, VALID): total: 2041.95, 2046.90      recon: 2027.45, 2032.61,     kl: 11.98, 11.77,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1088, step:27225 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.53, 2032.22,     kl: 11.99, 11.74,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1089, step:27250 (TRAIN, VALID): total: 2041.96, 2047.32      recon: 2027.48, 2033.08,     kl: 11.95, 11.71,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1090, step:27275 (TRAIN, VALID): total: 2042.16, 2046.94      recon: 2027.66, 2032.67,     kl: 11.97, 11.75,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000135.\n",
      "Epoch:1091, step:27300 (TRAIN, VALID): total: 2042.30, 2047.08      recon: 2027.72, 2032.68,     kl: 12.05, 11.87,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1092, step:27325 (TRAIN, VALID): total: 2042.08, 2046.70      recon: 2027.51, 2032.34,     kl: 12.04, 11.83,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1093, step:27350 (TRAIN, VALID): total: 2042.15, 2045.70      recon: 2027.61, 2031.40,     kl: 12.01, 11.78,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1094, step:27375 (TRAIN, VALID): total: 2042.11, 2045.57      recon: 2027.58, 2031.25,     kl: 12.00, 11.80,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1095, step:27400 (TRAIN, VALID): total: 2042.37, 2047.77      recon: 2027.82, 2033.46,     kl: 12.03, 11.79,     l2: 2.52524,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1096, step:27425 (TRAIN, VALID): total: 2042.29, 2047.53      recon: 2027.77, 2033.22,     kl: 12.00, 11.78,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1097, step:27450 (TRAIN, VALID): total: 2042.04, 2047.54      recon: 2027.50, 2033.22,     kl: 12.01, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1098, step:27475 (TRAIN, VALID): total: 2042.31, 2047.08      recon: 2027.77, 2032.71,     kl: 12.02, 11.84,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1099, step:27500 (TRAIN, VALID): total: 2042.22, 2046.17      recon: 2027.67, 2031.84,     kl: 12.02, 11.81,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1100, step:27525 (TRAIN, VALID): total: 2042.20, 2046.37      recon: 2027.61, 2032.02,     kl: 12.06, 11.82,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1101, step:27550 (TRAIN, VALID): total: 2042.15, 2046.78      recon: 2027.59, 2032.46,     kl: 12.04, 11.79,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1102, step:27575 (TRAIN, VALID): total: 2042.33, 2047.43      recon: 2027.77, 2033.10,     kl: 12.03, 11.81,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000128.\n",
      "Epoch:1103, step:27600 (TRAIN, VALID): total: 2042.17, 2046.45      recon: 2027.61, 2032.13,     kl: 12.03, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1104, step:27625 (TRAIN, VALID): total: 2042.29, 2047.02      recon: 2027.74, 2032.67,     kl: 12.03, 11.82,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1105, step:27650 (TRAIN, VALID): total: 2042.17, 2046.55      recon: 2027.60, 2032.20,     kl: 12.04, 11.82,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1106, step:27675 (TRAIN, VALID): total: 2041.95, 2047.09      recon: 2027.42, 2032.76,     kl: 12.01, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1107, step:27700 (TRAIN, VALID): total: 2042.03, 2047.25      recon: 2027.50, 2032.93,     kl: 12.00, 11.79,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1108, step:27725 (TRAIN, VALID): total: 2042.11, 2047.47      recon: 2027.60, 2033.16,     kl: 11.98, 11.78,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1109, step:27750 (TRAIN, VALID): total: 2042.06, 2047.51      recon: 2027.56, 2033.21,     kl: 11.97, 11.78,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1110, step:27775 (TRAIN, VALID): total: 2042.22, 2046.02      recon: 2027.67, 2031.69,     kl: 12.03, 11.80,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1111, step:27800 (TRAIN, VALID): total: 2042.02, 2046.87      recon: 2027.45, 2032.53,     kl: 12.04, 11.81,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1112, step:27825 (TRAIN, VALID): total: 2042.06, 2046.20      recon: 2027.49, 2031.88,     kl: 12.04, 11.79,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1113, step:27850 (TRAIN, VALID): total: 2042.17, 2045.68      recon: 2027.60, 2031.29,     kl: 12.05, 11.86,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1114, step:27875 (TRAIN, VALID): total: 2042.13, 2047.43      recon: 2027.50, 2033.04,     kl: 12.11, 11.87,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1115, step:27900 (TRAIN, VALID): total: 2041.95, 2046.69      recon: 2027.35, 2032.33,     kl: 12.07, 11.83,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1116, step:27925 (TRAIN, VALID): total: 2042.08, 2047.40      recon: 2027.52, 2033.05,     kl: 12.03, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1117, step:27950 (TRAIN, VALID): total: 2042.13, 2045.93      recon: 2027.60, 2031.59,     kl: 12.01, 11.82,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1118, step:27975 (TRAIN, VALID): total: 2042.11, 2047.08      recon: 2027.56, 2032.76,     kl: 12.02, 11.80,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1119, step:28000 (TRAIN, VALID): total: 2041.96, 2045.94      recon: 2027.39, 2031.66,     kl: 12.04, 11.76,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1120, step:28025 (TRAIN, VALID): total: 2041.99, 2046.33      recon: 2027.51, 2032.05,     kl: 11.96, 11.75,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1121, step:28050 (TRAIN, VALID): total: 2042.30, 2045.65      recon: 2027.79, 2031.32,     kl: 11.98, 11.81,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000121.\n",
      "Epoch:1122, step:28075 (TRAIN, VALID): total: 2042.13, 2045.67      recon: 2027.56, 2031.37,     kl: 12.04, 11.77,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1123, step:28100 (TRAIN, VALID): total: 2041.90, 2045.70      recon: 2027.38, 2031.45,     kl: 11.99, 11.72,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1124, step:28125 (TRAIN, VALID): total: 2042.06, 2046.88      recon: 2027.56, 2032.57,     kl: 11.98, 11.78,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1125, step:28150 (TRAIN, VALID): total: 2042.03, 2046.24      recon: 2027.50, 2031.90,     kl: 12.01, 11.81,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1126, step:28175 (TRAIN, VALID): total: 2041.92, 2046.87      recon: 2027.36, 2032.54,     kl: 12.03, 11.80,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1127, step:28200 (TRAIN, VALID): total: 2042.00, 2046.92      recon: 2027.48, 2032.63,     kl: 12.00, 11.76,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1128, step:28225 (TRAIN, VALID): total: 2042.00, 2046.84      recon: 2027.51, 2032.56,     kl: 11.97, 11.75,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1129, step:28250 (TRAIN, VALID): total: 2041.98, 2046.84      recon: 2027.49, 2032.58,     kl: 11.96, 11.74,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1130, step:28275 (TRAIN, VALID): total: 2041.97, 2046.90      recon: 2027.52, 2032.65,     kl: 11.93, 11.73,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1131, step:28300 (TRAIN, VALID): total: 2042.16, 2046.80      recon: 2027.67, 2032.56,     kl: 11.96, 11.71,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000115.\n",
      "Epoch:1132, step:28325 (TRAIN, VALID): total: 2042.20, 2046.14      recon: 2027.68, 2031.84,     kl: 11.99, 11.78,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1133, step:28350 (TRAIN, VALID): total: 2042.07, 2046.40      recon: 2027.55, 2032.13,     kl: 11.99, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1134, step:28375 (TRAIN, VALID): total: 2042.04, 2045.99      recon: 2027.56, 2031.70,     kl: 11.96, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1135, step:28400 (TRAIN, VALID): total: 2042.04, 2046.99      recon: 2027.54, 2032.70,     kl: 11.98, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1136, step:28425 (TRAIN, VALID): total: 2042.15, 2047.24      recon: 2027.62, 2032.90,     kl: 12.00, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1137, step:28450 (TRAIN, VALID): total: 2042.00, 2046.03      recon: 2027.41, 2031.71,     kl: 12.07, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1138, step:28475 (TRAIN, VALID): total: 2042.12, 2048.55      recon: 2027.55, 2034.20,     kl: 12.04, 11.82,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1139, step:28500 (TRAIN, VALID): total: 2042.26, 2046.59      recon: 2027.72, 2032.26,     kl: 12.01, 11.81,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000110.\n",
      "Epoch:1140, step:28525 (TRAIN, VALID): total: 2041.97, 2047.45      recon: 2027.44, 2033.12,     kl: 12.01, 11.81,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1141, step:28550 (TRAIN, VALID): total: 2042.06, 2045.83      recon: 2027.51, 2031.50,     kl: 12.02, 11.80,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1142, step:28575 (TRAIN, VALID): total: 2042.05, 2047.30      recon: 2027.51, 2033.02,     kl: 12.02, 11.76,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1143, step:28600 (TRAIN, VALID): total: 2041.96, 2046.57      recon: 2027.43, 2032.26,     kl: 12.00, 11.78,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1144, step:28625 (TRAIN, VALID): total: 2042.00, 2045.82      recon: 2027.48, 2031.54,     kl: 11.99, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1145, step:28650 (TRAIN, VALID): total: 2042.03, 2046.40      recon: 2027.52, 2032.15,     kl: 11.99, 11.73,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1146, step:28675 (TRAIN, VALID): total: 2042.13, 2047.35      recon: 2027.59, 2033.00,     kl: 12.01, 11.83,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000104.\n",
      "Epoch:1147, step:28700 (TRAIN, VALID): total: 2041.93, 2046.13      recon: 2027.40, 2031.84,     kl: 12.01, 11.77,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1148, step:28725 (TRAIN, VALID): total: 2041.98, 2046.53      recon: 2027.47, 2032.24,     kl: 11.98, 11.77,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1149, step:28750 (TRAIN, VALID): total: 2041.98, 2045.86      recon: 2027.47, 2031.54,     kl: 11.99, 11.79,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1150, step:28775 (TRAIN, VALID): total: 2041.98, 2046.65      recon: 2027.46, 2032.34,     kl: 11.99, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1151, step:28800 (TRAIN, VALID): total: 2042.09, 2045.96      recon: 2027.57, 2031.63,     kl: 11.99, 11.81,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1152, step:28825 (TRAIN, VALID): total: 2042.03, 2046.68      recon: 2027.46, 2032.37,     kl: 12.04, 11.78,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1153, step:28850 (TRAIN, VALID): total: 2041.94, 2048.31      recon: 2027.42, 2034.04,     kl: 12.00, 11.74,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1154, step:28875 (TRAIN, VALID): total: 2042.02, 2045.55      recon: 2027.54, 2031.31,     kl: 11.95, 11.71,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1155, step:28900 (TRAIN, VALID): total: 2041.96, 2045.42      recon: 2027.46, 2031.19,     kl: 11.97, 11.71,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1156, step:28925 (TRAIN, VALID): total: 2042.10, 2047.00      recon: 2027.61, 2032.72,     kl: 11.96, 11.76,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000099.\n",
      "Epoch:1157, step:28950 (TRAIN, VALID): total: 2041.99, 2046.63      recon: 2027.43, 2032.31,     kl: 12.03, 11.80,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1158, step:28975 (TRAIN, VALID): total: 2042.20, 2045.91      recon: 2027.65, 2031.61,     kl: 12.03, 11.78,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1159, step:29000 (TRAIN, VALID): total: 2042.09, 2045.92      recon: 2027.55, 2031.63,     kl: 12.01, 11.77,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1160, step:29025 (TRAIN, VALID): total: 2041.98, 2047.31      recon: 2027.46, 2033.01,     kl: 12.00, 11.77,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1161, step:29050 (TRAIN, VALID): total: 2042.07, 2047.57      recon: 2027.55, 2033.27,     kl: 11.99, 11.78,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1162, step:29075 (TRAIN, VALID): total: 2042.00, 2045.68      recon: 2027.47, 2031.38,     kl: 12.01, 11.77,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1163, step:29100 (TRAIN, VALID): total: 2042.15, 2047.43      recon: 2027.59, 2033.11,     kl: 12.03, 11.80,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1164, step:29125 (TRAIN, VALID): total: 2042.02, 2047.45      recon: 2027.47, 2033.11,     kl: 12.02, 11.81,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1165, step:29150 (TRAIN, VALID): total: 2042.08, 2047.25      recon: 2027.53, 2032.94,     kl: 12.02, 11.79,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1166, step:29175 (TRAIN, VALID): total: 2042.01, 2046.34      recon: 2027.47, 2032.03,     kl: 12.02, 11.79,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1167, step:29200 (TRAIN, VALID): total: 2042.19, 2047.04      recon: 2027.66, 2032.73,     kl: 12.01, 11.79,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000094.\n",
      "Epoch:1168, step:29225 (TRAIN, VALID): total: 2041.95, 2047.13      recon: 2027.42, 2032.84,     kl: 12.01, 11.76,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1169, step:29250 (TRAIN, VALID): total: 2041.91, 2046.91      recon: 2027.40, 2032.63,     kl: 11.99, 11.75,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1170, step:29275 (TRAIN, VALID): total: 2042.00, 2047.22      recon: 2027.49, 2032.96,     kl: 11.99, 11.74,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1171, step:29300 (TRAIN, VALID): total: 2042.02, 2047.09      recon: 2027.51, 2032.79,     kl: 11.98, 11.78,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1172, step:29325 (TRAIN, VALID): total: 2041.93, 2047.86      recon: 2027.41, 2033.56,     kl: 11.99, 11.78,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1173, step:29350 (TRAIN, VALID): total: 2042.05, 2045.89      recon: 2027.53, 2031.58,     kl: 12.00, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1174, step:29375 (TRAIN, VALID): total: 2042.00, 2046.24      recon: 2027.45, 2031.92,     kl: 12.02, 11.79,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1175, step:29400 (TRAIN, VALID): total: 2042.20, 2046.86      recon: 2027.66, 2032.50,     kl: 12.02, 11.84,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000089.\n",
      "Epoch:1176, step:29425 (TRAIN, VALID): total: 2042.03, 2046.46      recon: 2027.47, 2032.13,     kl: 12.03, 11.81,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1177, step:29450 (TRAIN, VALID): total: 2041.98, 2048.02      recon: 2027.39, 2033.68,     kl: 12.07, 11.82,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1178, step:29475 (TRAIN, VALID): total: 2042.02, 2046.86      recon: 2027.44, 2032.54,     kl: 12.06, 11.80,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1179, step:29500 (TRAIN, VALID): total: 2042.15, 2047.28      recon: 2027.58, 2032.92,     kl: 12.04, 11.83,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1180, step:29525 (TRAIN, VALID): total: 2042.00, 2045.32      recon: 2027.42, 2030.95,     kl: 12.06, 11.84,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1181, step:29550 (TRAIN, VALID): total: 2041.95, 2046.32      recon: 2027.36, 2032.01,     kl: 12.06, 11.78,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1182, step:29575 (TRAIN, VALID): total: 2041.88, 2046.83      recon: 2027.33, 2032.52,     kl: 12.03, 11.78,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1183, step:29600 (TRAIN, VALID): total: 2042.00, 2047.80      recon: 2027.46, 2033.47,     kl: 12.01, 11.81,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1184, step:29625 (TRAIN, VALID): total: 2042.20, 2047.63      recon: 2027.67, 2033.33,     kl: 12.00, 11.77,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000085.\n",
      "Epoch:1185, step:29650 (TRAIN, VALID): total: 2042.00, 2046.64      recon: 2027.45, 2032.31,     kl: 12.03, 11.81,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1186, step:29675 (TRAIN, VALID): total: 2042.01, 2046.37      recon: 2027.46, 2032.06,     kl: 12.02, 11.78,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1187, step:29700 (TRAIN, VALID): total: 2041.92, 2048.16      recon: 2027.40, 2033.85,     kl: 12.00, 11.79,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1188, step:29725 (TRAIN, VALID): total: 2041.95, 2046.82      recon: 2027.44, 2032.52,     kl: 11.99, 11.78,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1189, step:29750 (TRAIN, VALID): total: 2042.02, 2045.77      recon: 2027.50, 2031.49,     kl: 11.99, 11.75,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1190, step:29775 (TRAIN, VALID): total: 2042.05, 2046.96      recon: 2027.52, 2032.67,     kl: 12.01, 11.76,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1191, step:29800 (TRAIN, VALID): total: 2041.91, 2046.16      recon: 2027.39, 2031.89,     kl: 11.99, 11.75,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1192, step:29825 (TRAIN, VALID): total: 2042.00, 2047.95      recon: 2027.49, 2033.65,     kl: 11.99, 11.77,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1193, step:29850 (TRAIN, VALID): total: 2042.18, 2046.06      recon: 2027.65, 2031.77,     kl: 12.00, 11.77,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000081.\n",
      "Epoch:1194, step:29875 (TRAIN, VALID): total: 2042.03, 2045.94      recon: 2027.51, 2031.68,     kl: 12.00, 11.74,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1195, step:29900 (TRAIN, VALID): total: 2041.88, 2047.97      recon: 2027.38, 2033.69,     kl: 11.98, 11.75,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1196, step:29925 (TRAIN, VALID): total: 2042.04, 2046.02      recon: 2027.52, 2031.73,     kl: 11.99, 11.77,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1197, step:29950 (TRAIN, VALID): total: 2041.95, 2046.81      recon: 2027.42, 2032.49,     kl: 12.01, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1198, step:29975 (TRAIN, VALID): total: 2041.96, 2046.09      recon: 2027.43, 2031.76,     kl: 12.00, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1199, step:30000 (TRAIN, VALID): total: 2042.02, 2046.97      recon: 2027.49, 2032.66,     kl: 12.00, 11.78,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1200, step:30025 (TRAIN, VALID): total: 2042.04, 2045.83      recon: 2027.53, 2031.48,     kl: 11.99, 11.82,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000077.\n",
      "Epoch:1201, step:30050 (TRAIN, VALID): total: 2042.01, 2046.35      recon: 2027.45, 2032.00,     kl: 12.03, 11.82,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1202, step:30075 (TRAIN, VALID): total: 2042.41, 2046.61      recon: 2027.83, 2032.22,     kl: 12.06, 11.86,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1203, step:30100 (TRAIN, VALID): total: 2041.97, 2045.84      recon: 2027.38, 2031.48,     kl: 12.07, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1204, step:30125 (TRAIN, VALID): total: 2042.03, 2047.40      recon: 2027.48, 2033.07,     kl: 12.02, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1205, step:30150 (TRAIN, VALID): total: 2042.16, 2045.86      recon: 2027.60, 2031.51,     kl: 12.03, 11.83,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1206, step:30175 (TRAIN, VALID): total: 2042.17, 2046.74      recon: 2027.60, 2032.40,     kl: 12.04, 11.82,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1207, step:30200 (TRAIN, VALID): total: 2042.05, 2047.46      recon: 2027.51, 2033.12,     kl: 12.02, 11.82,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1208, step:30225 (TRAIN, VALID): total: 2042.15, 2047.37      recon: 2027.57, 2033.02,     kl: 12.06, 11.82,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1209, step:30250 (TRAIN, VALID): total: 2042.10, 2048.06      recon: 2027.54, 2033.72,     kl: 12.03, 11.81,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1210, step:30275 (TRAIN, VALID): total: 2042.20, 2044.82      recon: 2027.65, 2030.52,     kl: 12.03, 11.78,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000073.\n",
      "Epoch:1211, step:30300 (TRAIN, VALID): total: 2041.93, 2046.92      recon: 2027.37, 2032.59,     kl: 12.03, 11.80,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1212, step:30325 (TRAIN, VALID): total: 2041.95, 2047.45      recon: 2027.41, 2033.15,     kl: 12.02, 11.78,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1213, step:30350 (TRAIN, VALID): total: 2041.90, 2047.29      recon: 2027.34, 2032.96,     kl: 12.03, 11.80,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1214, step:30375 (TRAIN, VALID): total: 2042.04, 2045.74      recon: 2027.50, 2031.44,     kl: 12.02, 11.77,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1215, step:30400 (TRAIN, VALID): total: 2041.94, 2047.07      recon: 2027.42, 2032.76,     kl: 12.00, 11.78,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1216, step:30425 (TRAIN, VALID): total: 2042.03, 2047.04      recon: 2027.49, 2032.75,     kl: 12.01, 11.77,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1217, step:30450 (TRAIN, VALID): total: 2041.96, 2046.41      recon: 2027.39, 2032.05,     kl: 12.04, 11.84,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1218, step:30475 (TRAIN, VALID): total: 2042.02, 2045.69      recon: 2027.41, 2031.35,     kl: 12.08, 11.82,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1219, step:30500 (TRAIN, VALID): total: 2042.01, 2047.41      recon: 2027.41, 2033.07,     kl: 12.08, 11.82,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1220, step:30525 (TRAIN, VALID): total: 2042.18, 2045.90      recon: 2027.62, 2031.59,     kl: 12.04, 11.78,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000069.\n",
      "Epoch:1221, step:30550 (TRAIN, VALID): total: 2041.97, 2046.03      recon: 2027.37, 2031.71,     kl: 12.07, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1222, step:30575 (TRAIN, VALID): total: 2041.91, 2044.83      recon: 2027.34, 2030.49,     kl: 12.05, 11.82,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1223, step:30600 (TRAIN, VALID): total: 2042.10, 2045.00      recon: 2027.54, 2030.69,     kl: 12.04, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1224, step:30625 (TRAIN, VALID): total: 2041.97, 2048.68      recon: 2027.43, 2034.38,     kl: 12.02, 11.78,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1225, step:30650 (TRAIN, VALID): total: 2041.89, 2045.98      recon: 2027.36, 2031.65,     kl: 12.01, 11.80,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1226, step:30675 (TRAIN, VALID): total: 2041.91, 2047.74      recon: 2027.30, 2033.36,     kl: 12.09, 11.85,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1227, step:30700 (TRAIN, VALID): total: 2041.96, 2047.52      recon: 2027.40, 2033.17,     kl: 12.03, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1228, step:30725 (TRAIN, VALID): total: 2042.03, 2046.35      recon: 2027.48, 2032.06,     kl: 12.03, 11.77,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1229, step:30750 (TRAIN, VALID): total: 2042.12, 2046.17      recon: 2027.56, 2031.82,     kl: 12.03, 11.82,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000066.\n",
      "Epoch:1230, step:30775 (TRAIN, VALID): total: 2041.91, 2047.62      recon: 2027.34, 2033.25,     kl: 12.04, 11.85,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1231, step:30800 (TRAIN, VALID): total: 2041.86, 2046.84      recon: 2027.31, 2032.52,     kl: 12.02, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1232, step:30825 (TRAIN, VALID): total: 2041.84, 2047.31      recon: 2027.29, 2032.99,     kl: 12.02, 11.80,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1233, step:30850 (TRAIN, VALID): total: 2041.90, 2046.81      recon: 2027.36, 2032.56,     kl: 12.01, 11.73,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1234, step:30875 (TRAIN, VALID): total: 2041.91, 2047.08      recon: 2027.39, 2032.83,     kl: 11.99, 11.73,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1235, step:30900 (TRAIN, VALID): total: 2041.90, 2046.62      recon: 2027.37, 2032.33,     kl: 12.00, 11.76,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1236, step:30925 (TRAIN, VALID): total: 2041.98, 2046.59      recon: 2027.46, 2032.28,     kl: 12.00, 11.78,     l2: 2.52516,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000062.\n",
      "Epoch:1237, step:30950 (TRAIN, VALID): total: 2041.93, 2046.31      recon: 2027.39, 2032.00,     kl: 12.02, 11.79,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1238, step:30975 (TRAIN, VALID): total: 2042.10, 2046.47      recon: 2027.56, 2032.15,     kl: 12.01, 11.80,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1239, step:31000 (TRAIN, VALID): total: 2041.97, 2046.73      recon: 2027.44, 2032.45,     kl: 12.01, 11.75,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1240, step:31025 (TRAIN, VALID): total: 2041.98, 2046.51      recon: 2027.44, 2032.20,     kl: 12.01, 11.79,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1241, step:31050 (TRAIN, VALID): total: 2041.96, 2047.26      recon: 2027.41, 2032.91,     kl: 12.03, 11.83,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1242, step:31075 (TRAIN, VALID): total: 2042.15, 2047.84      recon: 2027.56, 2033.45,     kl: 12.07, 11.86,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1243, step:31100 (TRAIN, VALID): total: 2042.27, 2047.45      recon: 2027.67, 2033.06,     kl: 12.08, 11.87,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000059.\n",
      "Epoch:1244, step:31125 (TRAIN, VALID): total: 2041.93, 2046.46      recon: 2027.33, 2032.10,     kl: 12.08, 11.84,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1245, step:31150 (TRAIN, VALID): total: 2041.90, 2046.42      recon: 2027.32, 2032.04,     kl: 12.06, 11.85,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1246, step:31175 (TRAIN, VALID): total: 2041.82, 2046.24      recon: 2027.24, 2031.89,     kl: 12.05, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1247, step:31200 (TRAIN, VALID): total: 2041.99, 2047.20      recon: 2027.43, 2032.88,     kl: 12.04, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1248, step:31225 (TRAIN, VALID): total: 2041.84, 2046.46      recon: 2027.30, 2032.14,     kl: 12.02, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1249, step:31250 (TRAIN, VALID): total: 2041.94, 2045.99      recon: 2027.39, 2031.65,     kl: 12.02, 11.81,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1250, step:31275 (TRAIN, VALID): total: 2041.90, 2045.45      recon: 2027.35, 2031.15,     kl: 12.02, 11.78,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1251, step:31300 (TRAIN, VALID): total: 2042.10, 2047.68      recon: 2027.54, 2033.36,     kl: 12.04, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000056.\n",
      "Epoch:1252, step:31325 (TRAIN, VALID): total: 2041.88, 2046.08      recon: 2027.35, 2031.79,     kl: 12.01, 11.76,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1253, step:31350 (TRAIN, VALID): total: 2042.00, 2047.01      recon: 2027.44, 2032.69,     kl: 12.03, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1254, step:31375 (TRAIN, VALID): total: 2042.05, 2046.22      recon: 2027.50, 2031.90,     kl: 12.02, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1255, step:31400 (TRAIN, VALID): total: 2041.86, 2046.28      recon: 2027.33, 2031.96,     kl: 12.01, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1256, step:31425 (TRAIN, VALID): total: 2042.22, 2045.59      recon: 2027.67, 2031.27,     kl: 12.02, 11.80,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1257, step:31450 (TRAIN, VALID): total: 2041.91, 2047.32      recon: 2027.36, 2033.01,     kl: 12.02, 11.78,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1258, step:31475 (TRAIN, VALID): total: 2041.89, 2047.59      recon: 2027.38, 2033.30,     kl: 11.98, 11.77,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1259, step:31500 (TRAIN, VALID): total: 2041.96, 2045.66      recon: 2027.41, 2031.38,     kl: 12.02, 11.76,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1260, step:31525 (TRAIN, VALID): total: 2042.13, 2046.81      recon: 2027.59, 2032.51,     kl: 12.02, 11.77,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1261, step:31550 (TRAIN, VALID): total: 2041.93, 2047.23      recon: 2027.37, 2032.92,     kl: 12.03, 11.79,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1262, step:31575 (TRAIN, VALID): total: 2041.91, 2046.32      recon: 2027.38, 2032.02,     kl: 12.01, 11.78,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1263, step:31600 (TRAIN, VALID): total: 2041.98, 2045.78      recon: 2027.46, 2031.49,     kl: 12.00, 11.77,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1264, step:31625 (TRAIN, VALID): total: 2042.00, 2046.43      recon: 2027.47, 2032.13,     kl: 12.00, 11.78,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1265, step:31650 (TRAIN, VALID): total: 2041.92, 2046.58      recon: 2027.37, 2032.26,     kl: 12.03, 11.79,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1266, step:31675 (TRAIN, VALID): total: 2042.08, 2046.87      recon: 2027.52, 2032.54,     kl: 12.03, 11.80,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1267, step:31700 (TRAIN, VALID): total: 2042.16, 2046.89      recon: 2027.60, 2032.56,     kl: 12.04, 11.81,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000053.\n",
      "Epoch:1268, step:31725 (TRAIN, VALID): total: 2042.00, 2046.09      recon: 2027.44, 2031.77,     kl: 12.03, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1269, step:31750 (TRAIN, VALID): total: 2041.97, 2046.48      recon: 2027.42, 2032.16,     kl: 12.03, 11.79,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1270, step:31775 (TRAIN, VALID): total: 2041.94, 2046.62      recon: 2027.37, 2032.27,     kl: 12.04, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1271, step:31800 (TRAIN, VALID): total: 2041.87, 2046.31      recon: 2027.33, 2031.96,     kl: 12.02, 11.82,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1272, step:31825 (TRAIN, VALID): total: 2041.95, 2047.24      recon: 2027.40, 2032.96,     kl: 12.03, 11.75,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1273, step:31850 (TRAIN, VALID): total: 2041.94, 2045.95      recon: 2027.41, 2031.64,     kl: 12.01, 11.79,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1274, step:31875 (TRAIN, VALID): total: 2041.96, 2047.23      recon: 2027.43, 2032.92,     kl: 12.00, 11.78,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1275, step:31900 (TRAIN, VALID): total: 2042.19, 2046.85      recon: 2027.66, 2032.56,     kl: 12.00, 11.76,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000051.\n",
      "Epoch:1276, step:31925 (TRAIN, VALID): total: 2041.94, 2047.09      recon: 2027.41, 2032.80,     kl: 12.00, 11.77,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1277, step:31950 (TRAIN, VALID): total: 2041.91, 2047.16      recon: 2027.38, 2032.88,     kl: 12.00, 11.75,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1278, step:31975 (TRAIN, VALID): total: 2041.92, 2045.68      recon: 2027.40, 2031.39,     kl: 11.99, 11.76,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1279, step:32000 (TRAIN, VALID): total: 2041.75, 2046.92      recon: 2027.25, 2032.65,     kl: 11.98, 11.75,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1280, step:32025 (TRAIN, VALID): total: 2042.35, 2046.74      recon: 2027.84, 2032.45,     kl: 11.99, 11.77,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1281, step:32050 (TRAIN, VALID): total: 2041.89, 2047.21      recon: 2027.37, 2032.90,     kl: 12.00, 11.78,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1282, step:32075 (TRAIN, VALID): total: 2041.94, 2046.87      recon: 2027.41, 2032.54,     kl: 12.00, 11.81,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1283, step:32100 (TRAIN, VALID): total: 2041.84, 2046.37      recon: 2027.31, 2032.09,     kl: 12.01, 11.76,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1284, step:32125 (TRAIN, VALID): total: 2041.90, 2048.08      recon: 2027.36, 2033.75,     kl: 12.01, 11.81,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1285, step:32150 (TRAIN, VALID): total: 2041.90, 2046.65      recon: 2027.38, 2032.34,     kl: 12.00, 11.79,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1286, step:32175 (TRAIN, VALID): total: 2042.02, 2045.82      recon: 2027.48, 2031.51,     kl: 12.02, 11.78,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1287, step:32200 (TRAIN, VALID): total: 2041.88, 2047.23      recon: 2027.31, 2032.92,     kl: 12.04, 11.79,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1288, step:32225 (TRAIN, VALID): total: 2041.90, 2047.25      recon: 2027.33, 2032.92,     kl: 12.04, 11.80,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1289, step:32250 (TRAIN, VALID): total: 2042.20, 2045.86      recon: 2027.66, 2031.54,     kl: 12.01, 11.79,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000048.\n",
      "Epoch:1290, step:32275 (TRAIN, VALID): total: 2042.00, 2046.36      recon: 2027.46, 2032.04,     kl: 12.02, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1291, step:32300 (TRAIN, VALID): total: 2041.92, 2045.87      recon: 2027.37, 2031.58,     kl: 12.02, 11.76,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1292, step:32325 (TRAIN, VALID): total: 2042.02, 2046.79      recon: 2027.46, 2032.47,     kl: 12.04, 11.79,     l2: 2.52495,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1293, step:32350 (TRAIN, VALID): total: 2041.93, 2046.05      recon: 2027.41, 2031.76,     kl: 12.00, 11.76,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1294, step:32375 (TRAIN, VALID): total: 2041.97, 2045.52      recon: 2027.45, 2031.21,     kl: 12.00, 11.78,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1295, step:32400 (TRAIN, VALID): total: 2041.92, 2046.74      recon: 2027.39, 2032.42,     kl: 12.01, 11.80,     l2: 2.52489,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1296, step:32425 (TRAIN, VALID): total: 2041.94, 2046.32      recon: 2027.39, 2032.00,     kl: 12.03, 11.79,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1297, step:32450 (TRAIN, VALID): total: 2041.99, 2046.80      recon: 2027.46, 2032.49,     kl: 12.01, 11.78,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1298, step:32475 (TRAIN, VALID): total: 2042.02, 2046.99      recon: 2027.50, 2032.67,     kl: 12.00, 11.80,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1299, step:32500 (TRAIN, VALID): total: 2042.06, 2046.11      recon: 2027.53, 2031.80,     kl: 12.00, 11.79,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000046.\n",
      "Epoch:1300, step:32525 (TRAIN, VALID): total: 2042.02, 2045.97      recon: 2027.49, 2031.65,     kl: 12.00, 11.80,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1301, step:32550 (TRAIN, VALID): total: 2041.94, 2046.07      recon: 2027.40, 2031.72,     kl: 12.02, 11.82,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1302, step:32575 (TRAIN, VALID): total: 2041.86, 2046.95      recon: 2027.32, 2032.63,     kl: 12.02, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1303, step:32600 (TRAIN, VALID): total: 2042.24, 2047.60      recon: 2027.69, 2033.26,     kl: 12.03, 11.82,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1304, step:32625 (TRAIN, VALID): total: 2041.93, 2047.73      recon: 2027.36, 2033.38,     kl: 12.05, 11.83,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1305, step:32650 (TRAIN, VALID): total: 2041.86, 2047.29      recon: 2027.31, 2032.96,     kl: 12.03, 11.80,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1306, step:32675 (TRAIN, VALID): total: 2042.11, 2045.86      recon: 2027.55, 2031.49,     kl: 12.03, 11.84,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1307, step:32700 (TRAIN, VALID): total: 2041.91, 2047.80      recon: 2027.33, 2033.47,     kl: 12.05, 11.81,     l2: 2.52491,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1308, step:32725 (TRAIN, VALID): total: 2042.26, 2046.68      recon: 2027.70, 2032.35,     kl: 12.03, 11.80,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000044.\n",
      "Epoch:1309, step:32750 (TRAIN, VALID): total: 2042.00, 2047.11      recon: 2027.45, 2032.79,     kl: 12.02, 11.80,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1310, step:32775 (TRAIN, VALID): total: 2041.83, 2047.02      recon: 2027.28, 2032.70,     kl: 12.02, 11.80,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1311, step:32800 (TRAIN, VALID): total: 2041.98, 2045.85      recon: 2027.45, 2031.53,     kl: 12.01, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1312, step:32825 (TRAIN, VALID): total: 2041.92, 2046.76      recon: 2027.36, 2032.46,     kl: 12.03, 11.77,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1313, step:32850 (TRAIN, VALID): total: 2041.98, 2048.03      recon: 2027.46, 2033.71,     kl: 12.00, 11.79,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1314, step:32875 (TRAIN, VALID): total: 2041.87, 2047.57      recon: 2027.35, 2033.25,     kl: 12.00, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1315, step:32900 (TRAIN, VALID): total: 2041.85, 2045.96      recon: 2027.33, 2031.66,     kl: 12.00, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1316, step:32925 (TRAIN, VALID): total: 2042.07, 2047.06      recon: 2027.53, 2032.73,     kl: 12.02, 11.80,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000041.\n",
      "Epoch:1317, step:32950 (TRAIN, VALID): total: 2041.94, 2045.81      recon: 2027.40, 2031.48,     kl: 12.02, 11.81,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1318, step:32975 (TRAIN, VALID): total: 2041.86, 2047.06      recon: 2027.32, 2032.72,     kl: 12.02, 11.82,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1319, step:33000 (TRAIN, VALID): total: 2041.95, 2046.04      recon: 2027.41, 2031.70,     kl: 12.02, 11.82,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1320, step:33025 (TRAIN, VALID): total: 2041.83, 2046.01      recon: 2027.27, 2031.69,     kl: 12.03, 11.80,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1321, step:33050 (TRAIN, VALID): total: 2041.93, 2045.05      recon: 2027.40, 2030.76,     kl: 12.01, 11.77,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1322, step:33075 (TRAIN, VALID): total: 2041.91, 2046.55      recon: 2027.35, 2032.25,     kl: 12.03, 11.77,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1323, step:33100 (TRAIN, VALID): total: 2042.04, 2046.58      recon: 2027.48, 2032.26,     kl: 12.03, 11.80,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000039.\n",
      "Epoch:1324, step:33125 (TRAIN, VALID): total: 2041.91, 2046.06      recon: 2027.38, 2031.74,     kl: 12.00, 11.80,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1325, step:33150 (TRAIN, VALID): total: 2041.84, 2046.89      recon: 2027.31, 2032.57,     kl: 12.00, 11.79,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1326, step:33175 (TRAIN, VALID): total: 2041.97, 2046.58      recon: 2027.42, 2032.25,     kl: 12.03, 11.81,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1327, step:33200 (TRAIN, VALID): total: 2041.83, 2046.98      recon: 2027.29, 2032.66,     kl: 12.02, 11.79,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1328, step:33225 (TRAIN, VALID): total: 2041.93, 2046.20      recon: 2027.40, 2031.90,     kl: 12.00, 11.77,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1329, step:33250 (TRAIN, VALID): total: 2042.00, 2047.79      recon: 2027.48, 2033.48,     kl: 12.00, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1330, step:33275 (TRAIN, VALID): total: 2041.90, 2046.91      recon: 2027.38, 2032.60,     kl: 12.00, 11.79,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1331, step:33300 (TRAIN, VALID): total: 2041.89, 2045.47      recon: 2027.37, 2031.18,     kl: 12.00, 11.77,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1332, step:33325 (TRAIN, VALID): total: 2041.98, 2046.19      recon: 2027.44, 2031.85,     kl: 12.01, 11.81,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1333, step:33350 (TRAIN, VALID): total: 2041.91, 2046.83      recon: 2027.36, 2032.53,     kl: 12.03, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1334, step:33375 (TRAIN, VALID): total: 2042.25, 2046.47      recon: 2027.69, 2032.17,     kl: 12.03, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000037.\n",
      "Epoch:1335, step:33400 (TRAIN, VALID): total: 2041.95, 2046.46      recon: 2027.40, 2032.14,     kl: 12.02, 11.80,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1336, step:33425 (TRAIN, VALID): total: 2041.89, 2046.63      recon: 2027.34, 2032.31,     kl: 12.03, 11.79,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1337, step:33450 (TRAIN, VALID): total: 2041.96, 2046.78      recon: 2027.41, 2032.47,     kl: 12.02, 11.79,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1338, step:33475 (TRAIN, VALID): total: 2042.04, 2046.68      recon: 2027.49, 2032.35,     kl: 12.03, 11.80,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1339, step:33500 (TRAIN, VALID): total: 2042.00, 2046.73      recon: 2027.45, 2032.38,     kl: 12.03, 11.82,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1340, step:33525 (TRAIN, VALID): total: 2042.10, 2046.86      recon: 2027.56, 2032.51,     kl: 12.02, 11.82,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1341, step:33550 (TRAIN, VALID): total: 2042.08, 2046.17      recon: 2027.52, 2031.81,     kl: 12.03, 11.84,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1342, step:33575 (TRAIN, VALID): total: 2041.99, 2045.61      recon: 2027.41, 2031.26,     kl: 12.05, 11.82,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1343, step:33600 (TRAIN, VALID): total: 2042.10, 2046.99      recon: 2027.53, 2032.67,     kl: 12.04, 11.79,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1344, step:33625 (TRAIN, VALID): total: 2041.94, 2047.55      recon: 2027.38, 2033.18,     kl: 12.03, 11.84,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1345, step:33650 (TRAIN, VALID): total: 2041.95, 2046.92      recon: 2027.39, 2032.57,     kl: 12.03, 11.83,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1346, step:33675 (TRAIN, VALID): total: 2041.90, 2046.07      recon: 2027.31, 2031.74,     kl: 12.07, 11.81,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1347, step:33700 (TRAIN, VALID): total: 2042.06, 2047.08      recon: 2027.50, 2032.76,     kl: 12.03, 11.80,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1348, step:33725 (TRAIN, VALID): total: 2041.84, 2046.47      recon: 2027.31, 2032.15,     kl: 12.01, 11.80,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1349, step:33750 (TRAIN, VALID): total: 2041.92, 2046.63      recon: 2027.38, 2032.28,     kl: 12.01, 11.83,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1350, step:33775 (TRAIN, VALID): total: 2041.76, 2046.13      recon: 2027.20, 2031.80,     kl: 12.03, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1351, step:33800 (TRAIN, VALID): total: 2042.00, 2045.97      recon: 2027.45, 2031.66,     kl: 12.03, 11.79,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1352, step:33825 (TRAIN, VALID): total: 2041.94, 2046.81      recon: 2027.39, 2032.47,     kl: 12.03, 11.82,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1353, step:33850 (TRAIN, VALID): total: 2041.92, 2047.64      recon: 2027.36, 2033.31,     kl: 12.03, 11.80,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1354, step:33875 (TRAIN, VALID): total: 2041.85, 2046.18      recon: 2027.30, 2031.86,     kl: 12.02, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1355, step:33900 (TRAIN, VALID): total: 2041.88, 2046.73      recon: 2027.32, 2032.44,     kl: 12.03, 11.76,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1356, step:33925 (TRAIN, VALID): total: 2041.91, 2046.76      recon: 2027.36, 2032.46,     kl: 12.02, 11.77,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1357, step:33950 (TRAIN, VALID): total: 2041.97, 2046.76      recon: 2027.44, 2032.46,     kl: 12.01, 11.77,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1358, step:33975 (TRAIN, VALID): total: 2041.93, 2045.86      recon: 2027.38, 2031.56,     kl: 12.02, 11.77,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1359, step:34000 (TRAIN, VALID): total: 2041.93, 2046.95      recon: 2027.39, 2032.63,     kl: 12.01, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1360, step:34025 (TRAIN, VALID): total: 2041.80, 2047.12      recon: 2027.26, 2032.82,     kl: 12.02, 11.78,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1361, step:34050 (TRAIN, VALID): total: 2041.93, 2046.10      recon: 2027.38, 2031.82,     kl: 12.02, 11.75,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1362, step:34075 (TRAIN, VALID): total: 2041.90, 2046.46      recon: 2027.37, 2032.12,     kl: 12.01, 11.82,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1363, step:34100 (TRAIN, VALID): total: 2041.99, 2046.30      recon: 2027.45, 2032.01,     kl: 12.01, 11.77,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000035.\n",
      "Epoch:1364, step:34125 (TRAIN, VALID): total: 2041.87, 2046.13      recon: 2027.33, 2031.83,     kl: 12.01, 11.77,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1365, step:34150 (TRAIN, VALID): total: 2041.78, 2047.61      recon: 2027.24, 2033.28,     kl: 12.01, 11.81,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1366, step:34175 (TRAIN, VALID): total: 2041.95, 2047.81      recon: 2027.40, 2033.48,     kl: 12.03, 11.80,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1367, step:34200 (TRAIN, VALID): total: 2041.88, 2046.25      recon: 2027.33, 2031.91,     kl: 12.03, 11.81,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1368, step:34225 (TRAIN, VALID): total: 2041.89, 2046.13      recon: 2027.32, 2031.82,     kl: 12.04, 11.79,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1369, step:34250 (TRAIN, VALID): total: 2041.89, 2045.94      recon: 2027.32, 2031.57,     kl: 12.04, 11.84,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1370, step:34275 (TRAIN, VALID): total: 2042.04, 2046.67      recon: 2027.47, 2032.32,     kl: 12.05, 11.82,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000034.\n",
      "Epoch:1371, step:34300 (TRAIN, VALID): total: 2042.12, 2045.29      recon: 2027.55, 2030.95,     kl: 12.04, 11.81,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1372, step:34325 (TRAIN, VALID): total: 2041.92, 2046.24      recon: 2027.36, 2031.92,     kl: 12.04, 11.80,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1373, step:34350 (TRAIN, VALID): total: 2041.89, 2047.17      recon: 2027.33, 2032.86,     kl: 12.04, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1374, step:34375 (TRAIN, VALID): total: 2041.91, 2046.48      recon: 2027.36, 2032.17,     kl: 12.02, 11.79,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1375, step:34400 (TRAIN, VALID): total: 2041.93, 2047.86      recon: 2027.39, 2033.55,     kl: 12.02, 11.79,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1376, step:34425 (TRAIN, VALID): total: 2042.00, 2047.00      recon: 2027.46, 2032.67,     kl: 12.02, 11.80,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1377, step:34450 (TRAIN, VALID): total: 2042.00, 2046.43      recon: 2027.43, 2032.09,     kl: 12.05, 11.82,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1378, step:34475 (TRAIN, VALID): total: 2041.89, 2048.02      recon: 2027.34, 2033.69,     kl: 12.03, 11.80,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1379, step:34500 (TRAIN, VALID): total: 2041.92, 2046.47      recon: 2027.36, 2032.13,     kl: 12.04, 11.81,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1380, step:34525 (TRAIN, VALID): total: 2041.78, 2046.73      recon: 2027.23, 2032.43,     kl: 12.03, 11.78,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1381, step:34550 (TRAIN, VALID): total: 2041.86, 2047.00      recon: 2027.31, 2032.64,     kl: 12.03, 11.83,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1382, step:34575 (TRAIN, VALID): total: 2041.92, 2046.37      recon: 2027.39, 2032.05,     kl: 12.00, 11.79,     l2: 2.52487,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1383, step:34600 (TRAIN, VALID): total: 2041.89, 2048.62      recon: 2027.36, 2034.29,     kl: 12.01, 11.80,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1384, step:34625 (TRAIN, VALID): total: 2041.87, 2047.26      recon: 2027.32, 2032.95,     kl: 12.03, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1385, step:34650 (TRAIN, VALID): total: 2041.84, 2047.13      recon: 2027.31, 2032.83,     kl: 12.00, 11.77,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1386, step:34675 (TRAIN, VALID): total: 2042.09, 2046.98      recon: 2027.57, 2032.68,     kl: 11.99, 11.78,     l2: 2.52485,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000032.\n",
      "Epoch:1387, step:34700 (TRAIN, VALID): total: 2041.83, 2046.59      recon: 2027.32, 2032.29,     kl: 11.98, 11.77,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1388, step:34725 (TRAIN, VALID): total: 2041.86, 2045.89      recon: 2027.32, 2031.61,     kl: 12.02, 11.76,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1389, step:34750 (TRAIN, VALID): total: 2041.88, 2045.09      recon: 2027.35, 2030.82,     kl: 12.01, 11.74,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1390, step:34775 (TRAIN, VALID): total: 2041.99, 2047.45      recon: 2027.46, 2033.13,     kl: 12.01, 11.80,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1391, step:34800 (TRAIN, VALID): total: 2041.79, 2047.37      recon: 2027.27, 2033.06,     kl: 12.00, 11.78,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1392, step:34825 (TRAIN, VALID): total: 2041.98, 2047.56      recon: 2027.46, 2033.22,     kl: 12.00, 11.81,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1393, step:34850 (TRAIN, VALID): total: 2041.84, 2046.27      recon: 2027.28, 2031.97,     kl: 12.03, 11.78,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1394, step:34875 (TRAIN, VALID): total: 2041.90, 2047.32      recon: 2027.36, 2033.00,     kl: 12.01, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1395, step:34900 (TRAIN, VALID): total: 2041.90, 2046.06      recon: 2027.35, 2031.77,     kl: 12.03, 11.76,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1396, step:34925 (TRAIN, VALID): total: 2042.00, 2047.09      recon: 2027.45, 2032.78,     kl: 12.03, 11.78,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000030.\n",
      "Epoch:1397, step:34950 (TRAIN, VALID): total: 2041.87, 2046.42      recon: 2027.33, 2032.10,     kl: 12.02, 11.80,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1398, step:34975 (TRAIN, VALID): total: 2041.74, 2046.71      recon: 2027.21, 2032.40,     kl: 12.01, 11.78,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1399, step:35000 (TRAIN, VALID): total: 2041.93, 2046.59      recon: 2027.38, 2032.29,     kl: 12.02, 11.77,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1400, step:35025 (TRAIN, VALID): total: 2041.91, 2045.80      recon: 2027.36, 2031.49,     kl: 12.02, 11.79,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1401, step:35050 (TRAIN, VALID): total: 2041.85, 2048.98      recon: 2027.31, 2034.66,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1402, step:35075 (TRAIN, VALID): total: 2041.96, 2046.21      recon: 2027.41, 2031.89,     kl: 12.03, 11.80,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1403, step:35100 (TRAIN, VALID): total: 2041.89, 2045.53      recon: 2027.35, 2031.23,     kl: 12.01, 11.78,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1404, step:35125 (TRAIN, VALID): total: 2041.81, 2046.80      recon: 2027.30, 2032.48,     kl: 11.99, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1405, step:35150 (TRAIN, VALID): total: 2041.93, 2047.20      recon: 2027.40, 2032.91,     kl: 12.00, 11.77,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1406, step:35175 (TRAIN, VALID): total: 2041.88, 2045.81      recon: 2027.34, 2031.50,     kl: 12.01, 11.79,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1407, step:35200 (TRAIN, VALID): total: 2041.88, 2046.15      recon: 2027.34, 2031.85,     kl: 12.02, 11.77,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1408, step:35225 (TRAIN, VALID): total: 2041.93, 2047.20      recon: 2027.41, 2032.90,     kl: 12.00, 11.77,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1409, step:35250 (TRAIN, VALID): total: 2041.88, 2046.44      recon: 2027.34, 2032.14,     kl: 12.01, 11.78,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1410, step:35275 (TRAIN, VALID): total: 2042.16, 2046.79      recon: 2027.61, 2032.44,     kl: 12.02, 11.82,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000029.\n",
      "Epoch:1411, step:35300 (TRAIN, VALID): total: 2041.88, 2045.91      recon: 2027.35, 2031.58,     kl: 12.01, 11.80,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1412, step:35325 (TRAIN, VALID): total: 2041.82, 2046.24      recon: 2027.28, 2031.93,     kl: 12.01, 11.79,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1413, step:35350 (TRAIN, VALID): total: 2041.93, 2046.10      recon: 2027.38, 2031.76,     kl: 12.03, 11.82,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1414, step:35375 (TRAIN, VALID): total: 2041.86, 2046.30      recon: 2027.31, 2031.96,     kl: 12.03, 11.82,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1415, step:35400 (TRAIN, VALID): total: 2041.92, 2046.05      recon: 2027.38, 2031.72,     kl: 12.02, 11.80,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1416, step:35425 (TRAIN, VALID): total: 2041.88, 2046.18      recon: 2027.33, 2031.89,     kl: 12.02, 11.76,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1417, step:35450 (TRAIN, VALID): total: 2041.89, 2046.18      recon: 2027.36, 2031.87,     kl: 12.00, 11.78,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1418, step:35475 (TRAIN, VALID): total: 2041.81, 2047.49      recon: 2027.28, 2033.20,     kl: 12.00, 11.77,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1419, step:35500 (TRAIN, VALID): total: 2041.85, 2048.15      recon: 2027.33, 2033.85,     kl: 12.00, 11.78,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1420, step:35525 (TRAIN, VALID): total: 2041.83, 2046.70      recon: 2027.33, 2032.39,     kl: 11.98, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1421, step:35550 (TRAIN, VALID): total: 2042.11, 2046.72      recon: 2027.58, 2032.43,     kl: 12.01, 11.77,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000027.\n",
      "Epoch:1422, step:35575 (TRAIN, VALID): total: 2041.86, 2047.80      recon: 2027.35, 2033.49,     kl: 11.99, 11.79,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1423, step:35600 (TRAIN, VALID): total: 2041.95, 2046.57      recon: 2027.41, 2032.27,     kl: 12.02, 11.78,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1424, step:35625 (TRAIN, VALID): total: 2041.91, 2047.89      recon: 2027.39, 2033.57,     kl: 12.00, 11.80,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1425, step:35650 (TRAIN, VALID): total: 2041.90, 2046.91      recon: 2027.35, 2032.57,     kl: 12.03, 11.82,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1426, step:35675 (TRAIN, VALID): total: 2041.88, 2046.50      recon: 2027.33, 2032.18,     kl: 12.03, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1427, step:35700 (TRAIN, VALID): total: 2041.82, 2046.51      recon: 2027.29, 2032.25,     kl: 12.00, 11.74,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1428, step:35725 (TRAIN, VALID): total: 2041.96, 2046.35      recon: 2027.44, 2032.05,     kl: 12.00, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000026.\n",
      "Epoch:1429, step:35750 (TRAIN, VALID): total: 2041.84, 2047.13      recon: 2027.30, 2032.82,     kl: 12.02, 11.79,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1430, step:35775 (TRAIN, VALID): total: 2041.94, 2046.66      recon: 2027.42, 2032.37,     kl: 12.00, 11.77,     l2: 2.52458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1431, step:35800 (TRAIN, VALID): total: 2041.81, 2046.44      recon: 2027.27, 2032.12,     kl: 12.02, 11.79,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1432, step:35825 (TRAIN, VALID): total: 2042.25, 2046.91      recon: 2027.72, 2032.59,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1433, step:35850 (TRAIN, VALID): total: 2041.90, 2047.67      recon: 2027.34, 2033.36,     kl: 12.03, 11.79,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1434, step:35875 (TRAIN, VALID): total: 2041.80, 2047.41      recon: 2027.25, 2033.11,     kl: 12.02, 11.77,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1435, step:35900 (TRAIN, VALID): total: 2042.05, 2046.06      recon: 2027.51, 2031.74,     kl: 12.02, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1436, step:35925 (TRAIN, VALID): total: 2041.91, 2046.49      recon: 2027.35, 2032.19,     kl: 12.03, 11.77,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1437, step:35950 (TRAIN, VALID): total: 2041.89, 2045.06      recon: 2027.35, 2030.77,     kl: 12.01, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1438, step:35975 (TRAIN, VALID): total: 2042.12, 2046.76      recon: 2027.60, 2032.45,     kl: 12.00, 11.79,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1439, step:36000 (TRAIN, VALID): total: 2041.80, 2047.59      recon: 2027.27, 2033.27,     kl: 12.01, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1440, step:36025 (TRAIN, VALID): total: 2041.78, 2045.80      recon: 2027.25, 2031.51,     kl: 12.01, 11.77,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1441, step:36050 (TRAIN, VALID): total: 2041.94, 2046.23      recon: 2027.41, 2031.92,     kl: 12.01, 11.78,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1442, step:36075 (TRAIN, VALID): total: 2041.86, 2046.68      recon: 2027.33, 2032.34,     kl: 12.00, 11.82,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1443, step:36100 (TRAIN, VALID): total: 2041.98, 2046.74      recon: 2027.45, 2032.41,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1444, step:36125 (TRAIN, VALID): total: 2041.81, 2045.97      recon: 2027.25, 2031.68,     kl: 12.03, 11.76,     l2: 2.52454,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1445, step:36150 (TRAIN, VALID): total: 2041.93, 2047.03      recon: 2027.41, 2032.71,     kl: 12.00, 11.80,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1446, step:36175 (TRAIN, VALID): total: 2041.92, 2046.09      recon: 2027.39, 2031.76,     kl: 12.01, 11.81,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1447, step:36200 (TRAIN, VALID): total: 2041.85, 2046.84      recon: 2027.33, 2032.52,     kl: 12.00, 11.79,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1448, step:36225 (TRAIN, VALID): total: 2041.98, 2046.48      recon: 2027.45, 2032.15,     kl: 12.01, 11.81,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000025.\n",
      "Epoch:1449, step:36250 (TRAIN, VALID): total: 2041.82, 2047.28      recon: 2027.26, 2032.95,     kl: 12.03, 11.81,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1450, step:36275 (TRAIN, VALID): total: 2041.82, 2046.74      recon: 2027.27, 2032.41,     kl: 12.02, 11.80,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1451, step:36300 (TRAIN, VALID): total: 2041.90, 2046.57      recon: 2027.35, 2032.24,     kl: 12.02, 11.80,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1452, step:36325 (TRAIN, VALID): total: 2041.89, 2046.72      recon: 2027.34, 2032.42,     kl: 12.03, 11.77,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1453, step:36350 (TRAIN, VALID): total: 2041.95, 2048.11      recon: 2027.41, 2033.81,     kl: 12.01, 11.78,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1454, step:36375 (TRAIN, VALID): total: 2041.76, 2046.86      recon: 2027.22, 2032.57,     kl: 12.02, 11.77,     l2: 2.52457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1455, step:36400 (TRAIN, VALID): total: 2041.92, 2047.24      recon: 2027.38, 2032.91,     kl: 12.01, 11.81,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1456, step:36425 (TRAIN, VALID): total: 2041.87, 2047.08      recon: 2027.36, 2032.78,     kl: 11.99, 11.77,     l2: 2.52455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1457, step:36450 (TRAIN, VALID): total: 2041.87, 2044.97      recon: 2027.33, 2030.69,     kl: 12.01, 11.76,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1458, step:36475 (TRAIN, VALID): total: 2042.03, 2046.92      recon: 2027.49, 2032.61,     kl: 12.02, 11.79,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000024.\n",
      "Epoch:1459, step:36500 (TRAIN, VALID): total: 2041.86, 2047.04      recon: 2027.30, 2032.71,     kl: 12.03, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1460, step:36525 (TRAIN, VALID): total: 2041.93, 2047.77      recon: 2027.38, 2033.41,     kl: 12.03, 11.84,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1461, step:36550 (TRAIN, VALID): total: 2041.84, 2046.18      recon: 2027.29, 2031.87,     kl: 12.03, 11.79,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1462, step:36575 (TRAIN, VALID): total: 2041.90, 2045.40      recon: 2027.34, 2031.11,     kl: 12.03, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1463, step:36600 (TRAIN, VALID): total: 2042.07, 2046.29      recon: 2027.54, 2031.98,     kl: 12.01, 11.78,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1464, step:36625 (TRAIN, VALID): total: 2041.77, 2046.17      recon: 2027.23, 2031.88,     kl: 12.02, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1465, step:36650 (TRAIN, VALID): total: 2041.81, 2045.76      recon: 2027.27, 2031.44,     kl: 12.01, 11.80,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1466, step:36675 (TRAIN, VALID): total: 2041.88, 2045.86      recon: 2027.33, 2031.55,     kl: 12.03, 11.78,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1467, step:36700 (TRAIN, VALID): total: 2041.92, 2046.29      recon: 2027.38, 2031.96,     kl: 12.02, 11.81,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1468, step:36725 (TRAIN, VALID): total: 2041.89, 2046.51      recon: 2027.34, 2032.15,     kl: 12.03, 11.83,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1469, step:36750 (TRAIN, VALID): total: 2041.94, 2048.17      recon: 2027.41, 2033.82,     kl: 12.01, 11.82,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1470, step:36775 (TRAIN, VALID): total: 2041.80, 2045.89      recon: 2027.25, 2031.55,     kl: 12.03, 11.81,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1471, step:36800 (TRAIN, VALID): total: 2041.87, 2047.62      recon: 2027.34, 2033.26,     kl: 12.00, 11.83,     l2: 2.52458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1472, step:36825 (TRAIN, VALID): total: 2041.92, 2046.37      recon: 2027.38, 2032.08,     kl: 12.02, 11.76,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1473, step:36850 (TRAIN, VALID): total: 2042.06, 2047.37      recon: 2027.52, 2033.06,     kl: 12.02, 11.78,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000022.\n",
      "Epoch:1474, step:36875 (TRAIN, VALID): total: 2041.87, 2046.36      recon: 2027.30, 2032.06,     kl: 12.04, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1475, step:36900 (TRAIN, VALID): total: 2041.92, 2046.82      recon: 2027.37, 2032.52,     kl: 12.03, 11.78,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1476, step:36925 (TRAIN, VALID): total: 2041.89, 2046.79      recon: 2027.34, 2032.51,     kl: 12.02, 11.76,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1477, step:36950 (TRAIN, VALID): total: 2041.84, 2045.83      recon: 2027.30, 2031.52,     kl: 12.02, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1478, step:36975 (TRAIN, VALID): total: 2041.90, 2046.40      recon: 2027.34, 2032.09,     kl: 12.03, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1479, step:37000 (TRAIN, VALID): total: 2041.86, 2046.02      recon: 2027.32, 2031.71,     kl: 12.02, 11.78,     l2: 2.52454,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1480, step:37025 (TRAIN, VALID): total: 2041.90, 2046.56      recon: 2027.36, 2032.24,     kl: 12.02, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1481, step:37050 (TRAIN, VALID): total: 2041.83, 2046.98      recon: 2027.28, 2032.68,     kl: 12.02, 11.77,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1482, step:37075 (TRAIN, VALID): total: 2041.86, 2046.83      recon: 2027.29, 2032.50,     kl: 12.04, 11.80,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1483, step:37100 (TRAIN, VALID): total: 2041.78, 2046.54      recon: 2027.24, 2032.24,     kl: 12.01, 11.78,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1484, step:37125 (TRAIN, VALID): total: 2041.89, 2046.40      recon: 2027.36, 2032.11,     kl: 12.01, 11.76,     l2: 2.52455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1485, step:37150 (TRAIN, VALID): total: 2041.83, 2046.50      recon: 2027.29, 2032.19,     kl: 12.02, 11.79,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1486, step:37175 (TRAIN, VALID): total: 2041.89, 2047.31      recon: 2027.35, 2033.01,     kl: 12.02, 11.78,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1487, step:37200 (TRAIN, VALID): total: 2041.82, 2047.38      recon: 2027.27, 2033.07,     kl: 12.02, 11.79,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1488, step:37225 (TRAIN, VALID): total: 2041.75, 2046.65      recon: 2027.20, 2032.33,     kl: 12.02, 11.79,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1489, step:37250 (TRAIN, VALID): total: 2041.87, 2047.58      recon: 2027.33, 2033.25,     kl: 12.02, 11.80,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1490, step:37275 (TRAIN, VALID): total: 2041.86, 2047.16      recon: 2027.34, 2032.83,     kl: 12.00, 11.81,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1491, step:37300 (TRAIN, VALID): total: 2041.90, 2046.29      recon: 2027.36, 2032.00,     kl: 12.02, 11.77,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000021.\n",
      "Epoch:1492, step:37325 (TRAIN, VALID): total: 2042.03, 2048.00      recon: 2027.50, 2033.69,     kl: 12.01, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1493, step:37350 (TRAIN, VALID): total: 2042.08, 2046.88      recon: 2027.51, 2032.57,     kl: 12.05, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1494, step:37375 (TRAIN, VALID): total: 2041.90, 2047.25      recon: 2027.35, 2032.90,     kl: 12.03, 11.82,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1495, step:37400 (TRAIN, VALID): total: 2041.86, 2046.14      recon: 2027.32, 2031.84,     kl: 12.02, 11.78,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1496, step:37425 (TRAIN, VALID): total: 2042.03, 2047.58      recon: 2027.49, 2033.24,     kl: 12.02, 11.82,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1497, step:37450 (TRAIN, VALID): total: 2041.88, 2045.92      recon: 2027.32, 2031.61,     kl: 12.04, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1498, step:37475 (TRAIN, VALID): total: 2042.16, 2046.64      recon: 2027.61, 2032.33,     kl: 12.03, 11.78,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000020.\n",
      "Epoch:1499, step:37500 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.48, 2032.14,     kl: 12.04, 11.82,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1500, step:37525 (TRAIN, VALID): total: 2041.88, 2046.20      recon: 2027.31, 2031.89,     kl: 12.04, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1501, step:37550 (TRAIN, VALID): total: 2042.00, 2047.11      recon: 2027.43, 2032.79,     kl: 12.05, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1502, step:37575 (TRAIN, VALID): total: 2042.14, 2046.55      recon: 2027.60, 2032.21,     kl: 12.02, 11.82,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1503, step:37600 (TRAIN, VALID): total: 2041.88, 2046.29      recon: 2027.30, 2031.96,     kl: 12.05, 11.81,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1504, step:37625 (TRAIN, VALID): total: 2041.86, 2047.11      recon: 2027.31, 2032.77,     kl: 12.02, 11.82,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1505, step:37650 (TRAIN, VALID): total: 2041.87, 2046.85      recon: 2027.32, 2032.53,     kl: 12.03, 11.80,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1506, step:37675 (TRAIN, VALID): total: 2041.87, 2046.87      recon: 2027.33, 2032.54,     kl: 12.01, 11.81,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1507, step:37700 (TRAIN, VALID): total: 2041.76, 2046.90      recon: 2027.20, 2032.58,     kl: 12.04, 11.80,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1508, step:37725 (TRAIN, VALID): total: 2041.82, 2047.46      recon: 2027.26, 2033.16,     kl: 12.03, 11.78,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1509, step:37750 (TRAIN, VALID): total: 2042.05, 2046.42      recon: 2027.50, 2032.11,     kl: 12.03, 11.79,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000019.\n",
      "Epoch:1510, step:37775 (TRAIN, VALID): total: 2041.97, 2046.66      recon: 2027.44, 2032.28,     kl: 12.01, 11.85,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1511, step:37800 (TRAIN, VALID): total: 2041.91, 2047.70      recon: 2027.38, 2033.39,     kl: 12.00, 11.79,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1512, step:37825 (TRAIN, VALID): total: 2041.83, 2047.14      recon: 2027.29, 2032.83,     kl: 12.01, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1513, step:37850 (TRAIN, VALID): total: 2041.76, 2047.22      recon: 2027.21, 2032.89,     kl: 12.03, 11.81,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1514, step:37875 (TRAIN, VALID): total: 2042.01, 2045.34      recon: 2027.46, 2031.00,     kl: 12.03, 11.81,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1515, step:37900 (TRAIN, VALID): total: 2041.99, 2047.57      recon: 2027.46, 2033.25,     kl: 12.01, 11.80,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1516, step:37925 (TRAIN, VALID): total: 2041.87, 2046.63      recon: 2027.32, 2032.28,     kl: 12.03, 11.83,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1517, step:37950 (TRAIN, VALID): total: 2041.80, 2046.82      recon: 2027.25, 2032.50,     kl: 12.02, 11.80,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1518, step:37975 (TRAIN, VALID): total: 2041.88, 2046.84      recon: 2027.32, 2032.51,     kl: 12.03, 11.81,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1519, step:38000 (TRAIN, VALID): total: 2041.87, 2046.24      recon: 2027.32, 2031.93,     kl: 12.02, 11.79,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1520, step:38025 (TRAIN, VALID): total: 2041.86, 2046.55      recon: 2027.32, 2032.25,     kl: 12.02, 11.78,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1521, step:38050 (TRAIN, VALID): total: 2041.86, 2047.05      recon: 2027.31, 2032.73,     kl: 12.02, 11.79,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1522, step:38075 (TRAIN, VALID): total: 2041.79, 2046.76      recon: 2027.25, 2032.48,     kl: 12.01, 11.76,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1523, step:38100 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.49, 2032.18,     kl: 12.03, 11.78,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000018.\n",
      "Epoch:1524, step:38125 (TRAIN, VALID): total: 2041.93, 2046.23      recon: 2027.40, 2031.90,     kl: 12.01, 11.81,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1525, step:38150 (TRAIN, VALID): total: 2041.83, 2046.23      recon: 2027.30, 2031.89,     kl: 12.01, 11.81,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1526, step:38175 (TRAIN, VALID): total: 2041.91, 2046.45      recon: 2027.38, 2032.12,     kl: 12.00, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1527, step:38200 (TRAIN, VALID): total: 2041.93, 2046.13      recon: 2027.38, 2031.82,     kl: 12.03, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1528, step:38225 (TRAIN, VALID): total: 2041.88, 2045.70      recon: 2027.32, 2031.38,     kl: 12.03, 11.79,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1529, step:38250 (TRAIN, VALID): total: 2041.83, 2046.91      recon: 2027.30, 2032.54,     kl: 12.01, 11.85,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1530, step:38275 (TRAIN, VALID): total: 2041.89, 2046.19      recon: 2027.33, 2031.87,     kl: 12.04, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1531, step:38300 (TRAIN, VALID): total: 2041.91, 2047.03      recon: 2027.36, 2032.68,     kl: 12.03, 11.83,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1532, step:38325 (TRAIN, VALID): total: 2041.79, 2046.41      recon: 2027.24, 2032.09,     kl: 12.03, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1533, step:38350 (TRAIN, VALID): total: 2041.72, 2047.08      recon: 2027.16, 2032.77,     kl: 12.03, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1534, step:38375 (TRAIN, VALID): total: 2041.84, 2045.73      recon: 2027.30, 2031.41,     kl: 12.01, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1535, step:38400 (TRAIN, VALID): total: 2041.92, 2046.25      recon: 2027.39, 2031.92,     kl: 12.01, 11.80,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000017.\n",
      "Epoch:1536, step:38425 (TRAIN, VALID): total: 2041.86, 2047.58      recon: 2027.31, 2033.29,     kl: 12.02, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1537, step:38450 (TRAIN, VALID): total: 2041.87, 2045.43      recon: 2027.33, 2031.12,     kl: 12.02, 11.78,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1538, step:38475 (TRAIN, VALID): total: 2041.78, 2045.79      recon: 2027.24, 2031.48,     kl: 12.02, 11.79,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1539, step:38500 (TRAIN, VALID): total: 2041.82, 2047.21      recon: 2027.29, 2032.87,     kl: 12.00, 11.81,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1540, step:38525 (TRAIN, VALID): total: 2041.77, 2045.57      recon: 2027.24, 2031.25,     kl: 12.01, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1541, step:38550 (TRAIN, VALID): total: 2041.81, 2046.64      recon: 2027.27, 2032.32,     kl: 12.02, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1542, step:38575 (TRAIN, VALID): total: 2041.76, 2046.60      recon: 2027.22, 2032.28,     kl: 12.02, 11.79,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1543, step:38600 (TRAIN, VALID): total: 2041.81, 2046.18      recon: 2027.27, 2031.87,     kl: 12.02, 11.78,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1544, step:38625 (TRAIN, VALID): total: 2041.89, 2046.50      recon: 2027.38, 2032.19,     kl: 11.98, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000016.\n",
      "Epoch:1545, step:38650 (TRAIN, VALID): total: 2041.85, 2044.65      recon: 2027.31, 2030.35,     kl: 12.02, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1546, step:38675 (TRAIN, VALID): total: 2041.87, 2047.73      recon: 2027.34, 2033.42,     kl: 12.00, 11.79,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1547, step:38700 (TRAIN, VALID): total: 2041.79, 2048.15      recon: 2027.27, 2033.82,     kl: 12.00, 11.80,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1548, step:38725 (TRAIN, VALID): total: 2041.86, 2046.80      recon: 2027.34, 2032.50,     kl: 11.99, 11.78,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1549, step:38750 (TRAIN, VALID): total: 2041.83, 2046.20      recon: 2027.29, 2031.89,     kl: 12.02, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1550, step:38775 (TRAIN, VALID): total: 2041.86, 2047.19      recon: 2027.33, 2032.87,     kl: 12.01, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1551, step:38800 (TRAIN, VALID): total: 2041.84, 2045.81      recon: 2027.32, 2031.51,     kl: 12.00, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1552, step:38825 (TRAIN, VALID): total: 2042.30, 2047.48      recon: 2027.75, 2033.16,     kl: 12.03, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000016.\n",
      "Epoch:1553, step:38850 (TRAIN, VALID): total: 2041.76, 2045.94      recon: 2027.20, 2031.65,     kl: 12.03, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1554, step:38875 (TRAIN, VALID): total: 2041.82, 2047.96      recon: 2027.29, 2033.66,     kl: 12.01, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1555, step:38900 (TRAIN, VALID): total: 2041.82, 2047.30      recon: 2027.27, 2033.02,     kl: 12.03, 11.75,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1556, step:38925 (TRAIN, VALID): total: 2041.82, 2046.89      recon: 2027.27, 2032.59,     kl: 12.02, 11.78,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1557, step:38950 (TRAIN, VALID): total: 2041.87, 2046.23      recon: 2027.34, 2031.94,     kl: 12.01, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1558, step:38975 (TRAIN, VALID): total: 2041.77, 2045.67      recon: 2027.23, 2031.40,     kl: 12.01, 11.74,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1559, step:39000 (TRAIN, VALID): total: 2041.84, 2047.24      recon: 2027.32, 2032.91,     kl: 11.99, 11.81,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1560, step:39025 (TRAIN, VALID): total: 2041.86, 2045.78      recon: 2027.34, 2031.46,     kl: 12.00, 11.80,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1561, step:39050 (TRAIN, VALID): total: 2041.91, 2047.16      recon: 2027.39, 2032.88,     kl: 12.00, 11.76,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000015.\n",
      "Epoch:1562, step:39075 (TRAIN, VALID): total: 2041.82, 2046.99      recon: 2027.29, 2032.69,     kl: 12.01, 11.78,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1563, step:39100 (TRAIN, VALID): total: 2041.75, 2046.76      recon: 2027.23, 2032.46,     kl: 12.00, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1564, step:39125 (TRAIN, VALID): total: 2041.97, 2045.56      recon: 2027.43, 2031.25,     kl: 12.02, 11.78,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1565, step:39150 (TRAIN, VALID): total: 2041.75, 2046.66      recon: 2027.22, 2032.33,     kl: 12.00, 11.81,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1566, step:39175 (TRAIN, VALID): total: 2041.80, 2046.00      recon: 2027.30, 2031.74,     kl: 11.98, 11.74,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1567, step:39200 (TRAIN, VALID): total: 2041.84, 2046.49      recon: 2027.33, 2032.18,     kl: 11.98, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1568, step:39225 (TRAIN, VALID): total: 2041.81, 2046.39      recon: 2027.30, 2032.11,     kl: 11.99, 11.76,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1569, step:39250 (TRAIN, VALID): total: 2041.82, 2048.37      recon: 2027.30, 2034.05,     kl: 12.00, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1570, step:39275 (TRAIN, VALID): total: 2041.87, 2045.81      recon: 2027.35, 2031.51,     kl: 11.99, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1571, step:39300 (TRAIN, VALID): total: 2041.80, 2046.89      recon: 2027.30, 2032.61,     kl: 11.98, 11.76,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1572, step:39325 (TRAIN, VALID): total: 2041.73, 2046.71      recon: 2027.23, 2032.40,     kl: 11.98, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1573, step:39350 (TRAIN, VALID): total: 2041.83, 2046.74      recon: 2027.30, 2032.45,     kl: 12.01, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1574, step:39375 (TRAIN, VALID): total: 2041.93, 2047.27      recon: 2027.41, 2032.98,     kl: 12.00, 11.77,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000014.\n",
      "Epoch:1575, step:39400 (TRAIN, VALID): total: 2041.86, 2046.70      recon: 2027.35, 2032.40,     kl: 11.99, 11.77,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1576, step:39425 (TRAIN, VALID): total: 2041.89, 2048.37      recon: 2027.37, 2034.04,     kl: 12.00, 11.80,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1577, step:39450 (TRAIN, VALID): total: 2041.74, 2046.14      recon: 2027.21, 2031.86,     kl: 12.01, 11.75,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1578, step:39475 (TRAIN, VALID): total: 2041.79, 2046.93      recon: 2027.25, 2032.61,     kl: 12.01, 11.80,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1579, step:39500 (TRAIN, VALID): total: 2041.88, 2046.27      recon: 2027.35, 2031.98,     kl: 12.00, 11.77,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1580, step:39525 (TRAIN, VALID): total: 2042.10, 2045.85      recon: 2027.56, 2031.58,     kl: 12.01, 11.75,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1581, step:39550 (TRAIN, VALID): total: 2042.14, 2047.35      recon: 2027.61, 2033.07,     kl: 12.00, 11.76,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000013.\n",
      "Epoch:1582, step:39575 (TRAIN, VALID): total: 2041.83, 2046.59      recon: 2027.29, 2032.27,     kl: 12.02, 11.79,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1583, step:39600 (TRAIN, VALID): total: 2041.85, 2047.09      recon: 2027.30, 2032.76,     kl: 12.03, 11.81,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1584, step:39625 (TRAIN, VALID): total: 2041.86, 2047.73      recon: 2027.30, 2033.40,     kl: 12.03, 11.80,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1585, step:39650 (TRAIN, VALID): total: 2041.91, 2047.11      recon: 2027.37, 2032.79,     kl: 12.02, 11.79,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1586, step:39675 (TRAIN, VALID): total: 2041.83, 2045.82      recon: 2027.28, 2031.51,     kl: 12.02, 11.78,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1587, step:39700 (TRAIN, VALID): total: 2041.84, 2046.95      recon: 2027.31, 2032.62,     kl: 12.00, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1588, step:39725 (TRAIN, VALID): total: 2041.83, 2046.08      recon: 2027.30, 2031.73,     kl: 12.01, 11.83,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1589, step:39750 (TRAIN, VALID): total: 2041.79, 2047.32      recon: 2027.25, 2033.02,     kl: 12.01, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1590, step:39775 (TRAIN, VALID): total: 2041.86, 2046.09      recon: 2027.34, 2031.83,     kl: 12.00, 11.74,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1591, step:39800 (TRAIN, VALID): total: 2041.78, 2047.51      recon: 2027.24, 2033.22,     kl: 12.02, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1592, step:39825 (TRAIN, VALID): total: 2041.70, 2046.70      recon: 2027.17, 2032.41,     kl: 12.01, 11.76,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1593, step:39850 (TRAIN, VALID): total: 2042.09, 2046.09      recon: 2027.56, 2031.81,     kl: 12.00, 11.76,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000013.\n",
      "Epoch:1594, step:39875 (TRAIN, VALID): total: 2041.86, 2046.96      recon: 2027.33, 2032.66,     kl: 12.01, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1595, step:39900 (TRAIN, VALID): total: 2041.85, 2046.58      recon: 2027.32, 2032.28,     kl: 12.01, 11.77,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1596, step:39925 (TRAIN, VALID): total: 2041.91, 2047.33      recon: 2027.36, 2033.02,     kl: 12.02, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1597, step:39950 (TRAIN, VALID): total: 2041.83, 2047.07      recon: 2027.28, 2032.76,     kl: 12.03, 11.78,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1598, step:39975 (TRAIN, VALID): total: 2041.89, 2047.43      recon: 2027.36, 2033.10,     kl: 12.00, 11.81,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1599, step:40000 (TRAIN, VALID): total: 2041.86, 2045.07      recon: 2027.31, 2030.78,     kl: 12.03, 11.76,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1600, step:40025 (TRAIN, VALID): total: 2041.88, 2046.07      recon: 2027.34, 2031.77,     kl: 12.01, 11.78,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1601, step:40050 (TRAIN, VALID): total: 2041.92, 2046.90      recon: 2027.39, 2032.60,     kl: 12.00, 11.78,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000012.\n",
      "Epoch:1602, step:40075 (TRAIN, VALID): total: 2042.11, 2046.33      recon: 2027.57, 2032.00,     kl: 12.01, 11.80,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1603, step:40100 (TRAIN, VALID): total: 2041.88, 2046.54      recon: 2027.35, 2032.21,     kl: 12.01, 11.80,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1604, step:40125 (TRAIN, VALID): total: 2042.01, 2046.67      recon: 2027.45, 2032.36,     kl: 12.04, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1605, step:40150 (TRAIN, VALID): total: 2041.88, 2045.35      recon: 2027.33, 2031.03,     kl: 12.02, 11.79,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1606, step:40175 (TRAIN, VALID): total: 2041.95, 2047.56      recon: 2027.40, 2033.24,     kl: 12.03, 11.80,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1607, step:40200 (TRAIN, VALID): total: 2042.04, 2047.06      recon: 2027.49, 2032.74,     kl: 12.03, 11.80,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1608, step:40225 (TRAIN, VALID): total: 2041.79, 2047.60      recon: 2027.25, 2033.27,     kl: 12.02, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1609, step:40250 (TRAIN, VALID): total: 2041.79, 2047.44      recon: 2027.23, 2033.12,     kl: 12.03, 11.80,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1610, step:40275 (TRAIN, VALID): total: 2041.78, 2047.23      recon: 2027.22, 2032.87,     kl: 12.03, 11.84,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1611, step:40300 (TRAIN, VALID): total: 2041.91, 2047.33      recon: 2027.37, 2033.00,     kl: 12.02, 11.81,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1612, step:40325 (TRAIN, VALID): total: 2042.06, 2047.03      recon: 2027.51, 2032.69,     kl: 12.03, 11.81,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1613, step:40350 (TRAIN, VALID): total: 2041.89, 2046.10      recon: 2027.34, 2031.78,     kl: 12.02, 11.80,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1614, step:40375 (TRAIN, VALID): total: 2041.90, 2046.73      recon: 2027.36, 2032.38,     kl: 12.02, 11.82,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1615, step:40400 (TRAIN, VALID): total: 2041.90, 2046.65      recon: 2027.35, 2032.32,     kl: 12.02, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1616, step:40425 (TRAIN, VALID): total: 2041.80, 2045.93      recon: 2027.26, 2031.62,     kl: 12.02, 11.79,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1617, step:40450 (TRAIN, VALID): total: 2041.74, 2047.72      recon: 2027.18, 2033.38,     kl: 12.04, 11.81,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1618, step:40475 (TRAIN, VALID): total: 2041.82, 2046.42      recon: 2027.27, 2032.09,     kl: 12.02, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1619, step:40500 (TRAIN, VALID): total: 2041.88, 2046.33      recon: 2027.32, 2032.06,     kl: 12.03, 11.75,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1620, step:40525 (TRAIN, VALID): total: 2041.84, 2045.79      recon: 2027.30, 2031.52,     kl: 12.01, 11.75,     l2: 2.52433,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1621, step:40550 (TRAIN, VALID): total: 2041.75, 2046.16      recon: 2027.20, 2031.86,     kl: 12.03, 11.78,     l2: 2.52432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1622, step:40575 (TRAIN, VALID): total: 2041.85, 2046.73      recon: 2027.31, 2032.40,     kl: 12.02, 11.81,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1623, step:40600 (TRAIN, VALID): total: 2041.71, 2045.93      recon: 2027.17, 2031.64,     kl: 12.02, 11.77,     l2: 2.52432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1624, step:40625 (TRAIN, VALID): total: 2041.92, 2046.28      recon: 2027.37, 2031.98,     kl: 12.03, 11.78,     l2: 2.52431,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000011.\n",
      "Epoch:1625, step:40650 (TRAIN, VALID): total: 2041.81, 2046.36      recon: 2027.29, 2032.04,     kl: 11.99, 11.80,     l2: 2.52429,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1626, step:40675 (TRAIN, VALID): total: 2041.75, 2046.50      recon: 2027.21, 2032.20,     kl: 12.01, 11.78,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1627, step:40700 (TRAIN, VALID): total: 2041.86, 2046.78      recon: 2027.32, 2032.47,     kl: 12.01, 11.78,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1628, step:40725 (TRAIN, VALID): total: 2041.77, 2045.76      recon: 2027.23, 2031.45,     kl: 12.02, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1629, step:40750 (TRAIN, VALID): total: 2041.87, 2047.64      recon: 2027.32, 2033.33,     kl: 12.03, 11.78,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1630, step:40775 (TRAIN, VALID): total: 2041.79, 2046.35      recon: 2027.27, 2032.02,     kl: 11.99, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1631, step:40800 (TRAIN, VALID): total: 2041.88, 2046.20      recon: 2027.35, 2031.91,     kl: 12.00, 11.76,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000010.\n",
      "Epoch:1632, step:40825 (TRAIN, VALID): total: 2042.04, 2046.65      recon: 2027.49, 2032.32,     kl: 12.03, 11.81,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1633, step:40850 (TRAIN, VALID): total: 2042.04, 2046.22      recon: 2027.49, 2031.92,     kl: 12.03, 11.78,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1634, step:40875 (TRAIN, VALID): total: 2042.02, 2047.05      recon: 2027.46, 2032.74,     kl: 12.03, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1635, step:40900 (TRAIN, VALID): total: 2041.79, 2047.49      recon: 2027.23, 2033.16,     kl: 12.04, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1636, step:40925 (TRAIN, VALID): total: 2041.83, 2047.53      recon: 2027.25, 2033.20,     kl: 12.05, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1637, step:40950 (TRAIN, VALID): total: 2041.86, 2047.12      recon: 2027.31, 2032.81,     kl: 12.03, 11.79,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1638, step:40975 (TRAIN, VALID): total: 2041.83, 2047.02      recon: 2027.28, 2032.73,     kl: 12.02, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1639, step:41000 (TRAIN, VALID): total: 2042.13, 2046.17      recon: 2027.59, 2031.86,     kl: 12.02, 11.78,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000010.\n",
      "Stopping optimization based on learning rate criteria.\n"
     ]
    }
   ],
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=chaotic_rnn_no_inputs \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_no_inputs \\\n",
    "--co_dim=0 \\\n",
    "--factors_dim=20 \\\n",
    "--ext_input_dim=0 \\\n",
    "--controller_input_lag=1 \\\n",
    "--output_dist=poisson \\\n",
    "--do_causal_controller=false \\\n",
    "--batch_size=128 \\\n",
    "--learning_rate_init=0.01 \\\n",
    "--learning_rate_stop=1e-05 \\\n",
    "--learning_rate_decay_factor=0.95 \\\n",
    "--learning_rate_n_to_compare=6 \\\n",
    "--do_reset_learning_rate=false \\\n",
    "--keep_prob=0.95 \\\n",
    "--con_dim=128 \\\n",
    "--gen_dim=200 \\\n",
    "--ci_enc_dim=128 \\\n",
    "--ic_dim=64 \\\n",
    "--ic_enc_dim=128 \\\n",
    "--ic_prior_var_min=0.1 \\\n",
    "--gen_cell_input_weight_scale=1.0 \\\n",
    "--cell_weight_scale=1.0 \\\n",
    "--do_feed_factors_to_controller=true \\\n",
    "--kl_start_step=0 \\\n",
    "--kl_increase_steps=2000 \\\n",
    "--kl_ic_weight=1.0 \\\n",
    "--l2_con_scale=0.0 \\\n",
    "--l2_gen_scale=2000.0 \\\n",
    "--l2_start_step=0 \\\n",
    "--l2_increase_steps=2000 \\\n",
    "--ic_prior_var_scale=0.1 \\\n",
    "--ic_post_var_min=0.0001 \\\n",
    "--kl_co_weight=1.0 \\\n",
    "--prior_ar_nvar=0.1 \\\n",
    "--cell_clip_value=5.0 \\\n",
    "--max_ckpt_to_keep_lve=5 \\\n",
    "--do_train_prior_ar_atau=true \\\n",
    "--co_prior_var_scale=0.1 \\\n",
    "--csv_log=fitlog \\\n",
    "--feedback_factors_or_rates=factors \\\n",
    "--do_train_prior_ar_nvar=true \\\n",
    "--max_grad_norm=200.0 \\\n",
    "--device=gpu:0 \\\n",
    "--num_steps_for_gen_ic=100000000 \\\n",
    "--ps_nexamples_to_process=100000000 \\\n",
    "--checkpoint_name=lfads_vae \\\n",
    "--temporal_spike_jitter_width=0 \\\n",
    "--checkpoint_pb_load_name=checkpoint \\\n",
    "--inject_ext_input_to_gen=false \\\n",
    "--co_mean_corr_scale=0.0 \\\n",
    "--gen_cell_rec_weight_scale=1.0 \\\n",
    "--max_ckpt_to_keep=5 \\\n",
    "--output_filename_stem=\"\" \\\n",
    "--ic_prior_var_max=0.1 \\\n",
    "--prior_ar_atau=10.0 \\\n",
    "--do_train_io_only=false \\\n",
    "--do_train_encoder_only=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=gaussian_chaotic_rnn_no_inputs \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_inputs_g2p5 \\\n",
    "--co_dim=1 \\\n",
    "--factors_dim=20 \\\n",
    "--output_dist=gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=chaotic_rnn_inputs_g2p5 \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_inputs_g2p5 \\\n",
    "--co_dim=1 \\\n",
    "--factors_dim=20 \\\n",
    "--output_dist=poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
